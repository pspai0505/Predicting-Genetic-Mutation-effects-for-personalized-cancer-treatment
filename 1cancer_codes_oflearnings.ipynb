{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "\n",
        "def load_and_preprocess_data(dataset_path):\n",
        "    train_variants = pd.read_csv(os.path.join(dataset_path, \"training_variants/training_variants\"))\n",
        "    train_text = pd.read_csv(os.path.join(dataset_path, \"training_text/training_text\"), sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1)\n",
        "\n",
        "    df = pd.merge(train_variants, train_text, on=\"ID\")\n",
        "    df.drop(columns=[\"ID\"], inplace=True)\n",
        "    df.fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    df[\"Class\"] = label_encoder.fit_transform(df[\"Class\"])\n",
        "    num_classes = len(label_encoder.classes_)\n",
        "\n",
        "    gene_ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False).fit_transform(df[[\"Gene\"]])\n",
        "    variation_ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False).fit_transform(df[[\"Variation\"]])\n",
        "\n",
        "    return df, gene_ohe, variation_ohe, label_encoder, num_classes\n",
        "\n",
        "def extract_tfidf(df):\n",
        "    tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
        "    return tfidf_vectorizer.fit_transform(df[\"Text\"])\n",
        "\n",
        "def extract_biobert_embeddings(text_list):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
        "    model = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    embeddings = []\n",
        "    for text in tqdm(text_list, desc=\"BioBERT\"):\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=256)\n",
        "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "        with torch.no_grad():\n",
        "            output = model(**inputs)\n",
        "        cls_embedding = output.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "        embeddings.append(cls_embedding.squeeze())\n",
        "    return np.array(embeddings)\n",
        "\n",
        "def apply_imbalance_strategy(X, y, strategy):\n",
        "    if strategy == 'a':\n",
        "        return SMOTE(random_state=42).fit_resample(X, y)\n",
        "    elif strategy == 'b':\n",
        "        return RandomOverSampler(random_state=42).fit_resample(X, y)\n",
        "    else:\n",
        "        return X, y\n",
        "\n",
        "def focal_loss(gamma=2., alpha=.25):\n",
        "    def loss(y_true, y_pred):\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
        "        cross_entropy = -y_true * K.log(y_pred)\n",
        "        weight = alpha * K.pow(1 - y_pred, gamma)\n",
        "        loss = weight * cross_entropy\n",
        "        return K.mean(K.sum(loss, axis=-1))\n",
        "    return loss\n",
        "\n",
        "def train_xgboost(X_train, y_train, X_test, y_test, use_weights=False):\n",
        "    sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train) if use_weights else None\n",
        "    model = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", num_class=9, objective=\"multi:softmax\")\n",
        "    model.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "    preds = model.predict(X_test)\n",
        "    print(\"XGBoost Accuracy:\", accuracy_score(y_test, preds))\n",
        "    print(classification_report(y_test, preds))\n",
        "\n",
        "def train_keras_nn(X_train, y_train, X_test, y_test, use_focal=False):\n",
        "    y_train_cat = to_categorical(y_train, num_classes=9)\n",
        "    y_test_cat = to_categorical(y_test, num_classes=9)\n",
        "\n",
        "    model = Sequential([\n",
        "        Dense(512, activation='relu', input_dim=X_train.shape[1]),\n",
        "        Dropout(0.3),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(9, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=focal_loss() if use_focal else 'categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X_train, y_train_cat, epochs=10, batch_size=32, validation_data=(X_test, y_test_cat))\n",
        "    preds = np.argmax(model.predict(X_test), axis=1)\n",
        "    print(\"Keras NN Accuracy:\", accuracy_score(y_test, preds))\n",
        "    print(classification_report(y_test, preds))\n",
        "\n",
        "def train_stacked_ensemble(X_train, y_train, X_test, y_test):\n",
        "    base_models = [\n",
        "        ('xgb', xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\")),\n",
        "        ('rf', RandomForestClassifier()),\n",
        "        ('et', ExtraTreesClassifier())\n",
        "    ]\n",
        "    ensemble = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
        "    ensemble.fit(X_train, y_train)\n",
        "    preds = ensemble.predict(X_test)\n",
        "    print(\"Stacked Ensemble Accuracy:\", accuracy_score(y_test, preds))\n",
        "    print(classification_report(y_test, preds))\n",
        "\n",
        "def train_lightgbm(X_train, y_train, X_test, y_test):\n",
        "    model = LGBMClassifier()\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    print(\"LightGBM Accuracy:\", accuracy_score(y_test, preds))\n",
        "    print(classification_report(y_test, preds))\n",
        "\n",
        "# === Driver ===\n",
        "if __name__ == \"__main__\":\n",
        "    dataset_path = \"/content/drive/MyDrive/msk-redefining-cancer-treatment\"\n",
        "    df, gene_ohe, variation_ohe, label_encoder, num_classes = load_and_preprocess_data(dataset_path)\n",
        "\n",
        "    text_mode = input(\"Choose text feature method (a: TF-IDF, b: BioBERT): \")\n",
        "    imbalance_mode = input(\"Choose imbalance handling (a: SMOTE, b: RandomOverSampler, c: Class Weights, d: Focal Loss): \")\n",
        "    model_type = input(\"Choose model (a: XGBoost, b: Keras NN, c: Stacked Ensemble, d: LightGBM): \")\n",
        "\n",
        "    text_features = extract_tfidf(df) if text_mode == 'a' else extract_biobert_embeddings(df[\"Text\"])\n",
        "    from scipy.sparse import hstack\n",
        "    X_all = hstack((gene_ohe, variation_ohe, text_features)) if text_mode == 'a' else np.hstack((gene_ohe, variation_ohe, text_features))\n",
        "    y_all = df[\"Class\"].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, stratify=y_all, random_state=42)\n",
        "    X_train, y_train = apply_imbalance_strategy(X_train, y_train, imbalance_mode)\n",
        "\n",
        "    if model_type == 'a':\n",
        "        train_xgboost(X_train, y_train, X_test, y_test, use_weights=(imbalance_mode == 'c'))\n",
        "    elif model_type == 'b':\n",
        "        train_keras_nn(X_train, y_train, X_test, y_test, use_focal=(imbalance_mode == 'd'))\n",
        "    elif model_type == 'c':\n",
        "        train_stacked_ensemble(X_train, y_train, X_test, y_test)\n",
        "    elif model_type == 'd':\n",
        "        train_lightgbm(X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ap1nb4Z2xKg",
        "outputId": "ca3b6f86-d252-44c1-a872-6e4f8dfc6091"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose text feature method (a: TF-IDF, b: BioBERT): a\n",
            "Choose imbalance handling (a: SMOTE, b: RandomOverSampler, c: Class Weights, d: Focal Loss): a\n",
            "Choose model (a: XGBoost, b: Keras NN, c: Stacked Ensemble, d: LightGBM): a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [19:43:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Accuracy: 0.6421052631578947\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.64      0.60       114\n",
            "           1       0.61      0.54      0.57        91\n",
            "           2       0.62      0.28      0.38        18\n",
            "           3       0.68      0.65      0.67       137\n",
            "           4       0.29      0.25      0.27        48\n",
            "           5       0.80      0.58      0.67        55\n",
            "           6       0.71      0.85      0.77       191\n",
            "           7       0.00      0.00      0.00         4\n",
            "           8       0.83      0.71      0.77         7\n",
            "\n",
            "    accuracy                           0.64       665\n",
            "   macro avg       0.57      0.50      0.52       665\n",
            "weighted avg       0.64      0.64      0.63       665\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP1mVNRTQlw_",
        "outputId": "32e5ed65-46d4-4f62-8156-d1c03690f222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Shape (after SMOTE): (6858, 7644), Labels: (6858,)\n",
            "Test Shape: (665, 7644), Labels: (665,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [23:32:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy: 0.6271\n",
            "\n",
            "Classification Report on Test Data:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.58      0.58       114\n",
            "           1       0.55      0.53      0.54        91\n",
            "           2       0.33      0.39      0.36        18\n",
            "           3       0.68      0.64      0.66       137\n",
            "           4       0.34      0.44      0.39        48\n",
            "           5       0.80      0.58      0.67        55\n",
            "           6       0.73      0.79      0.76       191\n",
            "           7       0.00      0.00      0.00         4\n",
            "           8       0.62      0.71      0.67         7\n",
            "\n",
            "    accuracy                           0.63       665\n",
            "   macro avg       0.52      0.52      0.51       665\n",
            "weighted avg       0.63      0.63      0.63       665\n",
            "\n",
            "Predictions saved to xgboost_predictions.csv!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os\n",
        "\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/msk-redefining-cancer-treatment\"\n",
        "\n",
        "train_variants = pd.read_csv(os.path.join(dataset_path, \"training_variants/training_variants\"))\n",
        "train_text = pd.read_csv(os.path.join(dataset_path, \"training_text/training_text\"), sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1)\n",
        "\n",
        "train_df = pd.merge(train_variants, train_text, on=\"ID\")\n",
        "\n",
        "train_df.drop(columns=[\"ID\"], inplace=True)\n",
        "\n",
        "train_df.fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_df[\"Class\"] = label_encoder.fit_transform(train_df[\"Class\"])\n",
        "\n",
        "X, y = train_df.drop(\"Class\", axis=1), train_df[\"Class\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "gene_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "variation_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "gene_encoded_train = gene_encoder.fit_transform(X_train[[\"Gene\"]])\n",
        "variation_encoded_train = variation_encoder.fit_transform(X_train[[\"Variation\"]])\n",
        "\n",
        "gene_encoded_test = gene_encoder.transform(X_test[[\"Gene\"]])\n",
        "variation_encoded_test = variation_encoder.transform(X_test[[\"Variation\"]])\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train[\"Text\"])\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test[\"Text\"])\n",
        "\n",
        "X_train_ml = hstack((gene_encoded_train, variation_encoded_train, X_train_tfidf))\n",
        "X_test_ml = hstack((gene_encoded_test, variation_encoded_test, X_test_tfidf))\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_ml_resampled, y_train_ml_resampled = smote.fit_resample(X_train_ml, y_train)\n",
        "\n",
        "\n",
        "print(f\"Train Shape (after SMOTE): {X_train_ml_resampled.shape}, Labels: {y_train_ml_resampled.shape}\")\n",
        "print(f\"Test Shape: {X_test_ml.shape}, Labels: {y_test.shape}\")\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier(**{\n",
        "    'subsample': 0.7, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.8,\n",
        "    'objective': \"multi:softmax\", 'num_class': 9, 'eval_metric': \"mlogloss\", 'use_label_encoder': False\n",
        "})\n",
        "\n",
        "xgb_clf.fit(X_train_ml_resampled, y_train_ml_resampled)\n",
        "\n",
        "y_pred_test = xgb_clf.predict(X_test_ml)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_test)\n",
        "print(f\"Final Test Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report on Test Data:\\n\", classification_report(y_test, y_pred_test))\n",
        "\n",
        "y_pred_test_labels = label_encoder.inverse_transform(y_pred_test)\n",
        "predictions_df = pd.DataFrame({\"Predicted_Class\": y_pred_test_labels})\n",
        "predictions_df.to_csv(\"xgboost_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to xgboost_predictions.csv!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GGZVBp2M7lZ",
        "outputId": "58f92904-5d3f-4c23-b52f-37323db77d42"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:41:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Test Accuracy: 0.6406\n",
            "\n",
            "Classification Report on Test Data:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.62      0.62       114\n",
            "           1       0.68      0.47      0.56        91\n",
            "           2       0.35      0.33      0.34        18\n",
            "           3       0.65      0.64      0.64       137\n",
            "           4       0.33      0.33      0.33        48\n",
            "           5       0.85      0.60      0.70        55\n",
            "           6       0.69      0.87      0.77       191\n",
            "           7       0.00      0.00      0.00         4\n",
            "           8       0.57      0.57      0.57         7\n",
            "\n",
            "    accuracy                           0.64       665\n",
            "   macro avg       0.53      0.49      0.50       665\n",
            "weighted avg       0.64      0.64      0.63       665\n",
            "\n",
            "✅ Predictions saved to xgboost_predictions.csv!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/msk-redefining-cancer-treatment\"\n",
        "\n",
        "train_variants = pd.read_csv(os.path.join(dataset_path, \"training_variants/training_variants\"))\n",
        "train_text = pd.read_csv(os.path.join(dataset_path, \"training_text/training_text\"), sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1)\n",
        "\n",
        "train_df = pd.merge(train_variants, train_text, on=\"ID\")\n",
        "train_df.drop(columns=[\"ID\"], inplace=True)\n",
        "train_df.fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_df[\"Class\"] = label_encoder.fit_transform(train_df[\"Class\"])  # Classes 1–9 → 0–8\n",
        "\n",
        "gene_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "variation_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "gene_encoded = gene_encoder.fit_transform(train_df[[\"Gene\"]])\n",
        "variation_encoded = variation_encoder.fit_transform(train_df[[\"Variation\"]])\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(train_df[\"Text\"])\n",
        "\n",
        "X_ml = hstack((gene_encoded, variation_encoded, X_tfidf))\n",
        "y_ml = train_df[\"Class\"]\n",
        "\n",
        "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(\n",
        "    X_ml, y_ml, test_size=0.2, random_state=42, stratify=y_ml\n",
        ")\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    subsample=0.7,\n",
        "    n_estimators=200,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.1,\n",
        "    gamma=0.1,\n",
        "    colsample_bytree=0.8,\n",
        "    objective=\"multi:softmax\",\n",
        "    num_class=9,\n",
        "    eval_metric=\"mlogloss\",\n",
        "    use_label_encoder=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_clf.fit(X_train_ml, y_train_ml)\n",
        "\n",
        "y_pred_test = xgb_clf.predict(X_test_ml)\n",
        "\n",
        "accuracy = accuracy_score(y_test_ml, y_pred_test)\n",
        "print(f\"Final Test Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report on Test Data:\\n\", classification_report(y_test_ml, y_pred_test))\n",
        "\n",
        "y_pred_test_labels = label_encoder.inverse_transform(y_pred_test)\n",
        "predictions_df = pd.DataFrame({\"Predicted_Class\": y_pred_test_labels})\n",
        "predictions_df.to_csv(\"xgboost_predictions.csv\", index=False)\n",
        "\n",
        "print(\" Predictions saved to xgboost_predictions.csv!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "96CznJ01huRD",
        "outputId": "67c1beb8-49a9-4904-b6b2-6029e09ee03c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-5-b76229203f64>\", line 37, in <cell line: 0>\n",
            "    X_tfidf = tfidf_vectorizer.fit_transform(train_df[\"Text\"])\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py\", line 2104, in fit_transform\n",
            "    X = super().fit_transform(raw_documents)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py\", line 1376, in fit_transform\n",
            "    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py\", line None, in _count_vocab\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1686, in getframeinfo\n",
            "    start = lineno - 1 - context//2\n",
            "            ~~~~~~~^~~\n",
            "TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-5-b76229203f64>\", line 37, in <cell line: 0>\n",
            "    X_tfidf = tfidf_vectorizer.fit_transform(train_df[\"Text\"])\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py\", line 2104, in fit_transform\n",
            "    X = super().fit_transform(raw_documents)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py\", line 1376, in fit_transform\n",
            "    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py\", line None, in _count_vocab\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "           ^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1686, in getframeinfo\n",
            "    start = lineno - 1 - context//2\n",
            "            ~~~~~~~^~~\n",
            "TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-5-b76229203f64>\", line 37, in <cell line: 0>\n",
            "    X_tfidf = tfidf_vectorizer.fit_transform(train_df[\"Text\"])\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py\", line 2104, in fit_transform\n",
            "    X = super().fit_transform(raw_documents)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py\", line 1376, in fit_transform\n",
            "    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py\", line None, in _count_vocab\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "           ^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "           ^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1686, in getframeinfo\n",
            "    start = lineno - 1 - context//2\n",
            "            ~~~~~~~^~~\n",
            "TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/msk-redefining-cancer-treatment\"\n",
        "\n",
        "train_variants = pd.read_csv(os.path.join(dataset_path, \"training_variants/training_variants\"))\n",
        "train_text = pd.read_csv(os.path.join(dataset_path, \"training_text/training_text\"), sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1)\n",
        "\n",
        "train_df = pd.merge(train_variants, train_text, on=\"ID\")\n",
        "train_df.drop(columns=[\"ID\"], inplace=True)\n",
        "train_df.fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_df[\"Class\"] = label_encoder.fit_transform(train_df[\"Class\"])\n",
        "\n",
        "gene_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "variation_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "gene_encoded = gene_encoder.fit_transform(train_df[[\"Gene\"]])\n",
        "variation_encoded = variation_encoder.fit_transform(train_df[[\"Variation\"]])\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(train_df[\"Text\"])\n",
        "\n",
        "from scipy.sparse import hstack\n",
        "X_all = hstack((gene_encoded, variation_encoded, X_tfidf))\n",
        "y_all = train_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6hntIugfsYD",
        "outputId": "8a19e2e8-4671-4d52-b4a3-ddfa31fde0f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After SMOTE → X_train: (6858, 3560)  y_train: (6858,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:06:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🎯 Final Test Accuracy: 0.6451\n",
            "\n",
            "📄 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.61      0.62       114\n",
            "           1       0.65      0.60      0.62        91\n",
            "           2       0.25      0.39      0.30        18\n",
            "           3       0.69      0.67      0.68       137\n",
            "           4       0.35      0.48      0.41        48\n",
            "           5       0.77      0.55      0.64        55\n",
            "           6       0.75      0.77      0.76       191\n",
            "           7       0.00      0.00      0.00         4\n",
            "           8       0.62      0.71      0.67         7\n",
            "\n",
            "    accuracy                           0.65       665\n",
            "   macro avg       0.52      0.53      0.52       665\n",
            "weighted avg       0.66      0.65      0.65       665\n",
            "\n",
            "✅ Saved to xgboost_svd_smote_predictions.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import xgboost as xgb\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/msk-redefining-cancer-treatment\"\n",
        "\n",
        "train_variants = pd.read_csv(os.path.join(dataset_path, \"training_variants/training_variants\"))\n",
        "train_text = pd.read_csv(os.path.join(dataset_path, \"training_text/training_text\"), sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1)\n",
        "\n",
        "train_df = pd.merge(train_variants, train_text, on=\"ID\")\n",
        "train_df.drop(columns=[\"ID\"], inplace=True)\n",
        "train_df.fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_df[\"Class\"] = label_encoder.fit_transform(train_df[\"Class\"])\n",
        "\n",
        "gene_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "variation_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "gene_encoded = gene_encoder.fit_transform(train_df[[\"Gene\"]])\n",
        "variation_encoded = variation_encoder.fit_transform(train_df[[\"Variation\"]])\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(train_df[\"Text\"])\n",
        "\n",
        "svd = TruncatedSVD(n_components=300, random_state=42)\n",
        "X_tfidf_reduced = svd.fit_transform(X_tfidf)\n",
        "\n",
        "X_all = np.hstack([gene_encoded, variation_encoded, X_tfidf_reduced])\n",
        "y_all = train_df[\"Class\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_all, y_all, test_size=0.2, stratify=y_all, random_state=42\n",
        ")\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"After SMOTE → X_train:\", X_train_resampled.shape, \" y_train:\", y_train_resampled.shape)\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    subsample=0.7,\n",
        "    n_estimators=200,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.1,\n",
        "    gamma=0.1,\n",
        "    colsample_bytree=0.8,\n",
        "    objective=\"multi:softmax\",\n",
        "    num_class=9,\n",
        "    eval_metric=\"mlogloss\",\n",
        "    use_label_encoder=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_clf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\n🎯 Final Test Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\n📄 Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
        "predictions_df = pd.DataFrame({\"Predicted_Class\": y_pred_labels})\n",
        "predictions_df.to_csv(\"xgboost_svd_smote_predictions.csv\", index=False)\n",
        "print(\"✅ Saved to xgboost_svd_smote_predictions.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYZeMLIudhNs",
        "outputId": "ba4d38d7-63e4-445e-ced2-8e05d3462085"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [19:54:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Test Accuracy: 0.6195\n",
            "\n",
            "Classification Report on Test Data:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.61      0.61       114\n",
            "           1       0.57      0.59      0.58        91\n",
            "           2       0.29      0.44      0.35        18\n",
            "           3       0.65      0.56      0.60       137\n",
            "           4       0.34      0.48      0.40        48\n",
            "           5       0.82      0.56      0.67        55\n",
            "           6       0.73      0.76      0.74       191\n",
            "           7       0.00      0.00      0.00         4\n",
            "           8       0.62      0.71      0.67         7\n",
            "\n",
            "    accuracy                           0.62       665\n",
            "   macro avg       0.52      0.52      0.51       665\n",
            "weighted avg       0.63      0.62      0.62       665\n",
            "\n",
            "Predictions saved to xgboost_weighted_predictions.csv!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/msk-redefining-cancer-treatment\"\n",
        "\n",
        "train_variants = pd.read_csv(os.path.join(dataset_path, \"training_variants/training_variants\"))\n",
        "train_text = pd.read_csv(os.path.join(dataset_path, \"training_text/training_text\"), sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1)\n",
        "\n",
        "train_df = pd.merge(train_variants, train_text, on=\"ID\")\n",
        "\n",
        "# Drop ID column\n",
        "train_df.drop(columns=[\"ID\"], inplace=True)\n",
        "\n",
        "# Handle Missing Values\n",
        "train_df.fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_df[\"Class\"] = label_encoder.fit_transform(train_df[\"Class\"])  # Convert to integers 0–8\n",
        "\n",
        "\n",
        "gene_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "variation_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "gene_encoded = gene_encoder.fit_transform(train_df[[\"Gene\"]])\n",
        "variation_encoded = variation_encoder.fit_transform(train_df[[\"Variation\"]])\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(train_df[\"Text\"])\n",
        "\n",
        "X_ml = hstack((gene_encoded, variation_encoded, X_tfidf))\n",
        "y_ml = train_df[\"Class\"]\n",
        "\n",
        "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(\n",
        "    X_ml, y_ml, test_size=0.2, random_state=42, stratify=y_ml\n",
        ")\n",
        "\n",
        "sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train_ml)\n",
        "\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    subsample=0.7,\n",
        "    n_estimators=200,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.1,\n",
        "    gamma=0.1,\n",
        "    colsample_bytree=0.8,\n",
        "    objective=\"multi:softmax\",\n",
        "    num_class=9,\n",
        "    eval_metric=\"mlogloss\",\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "xgb_clf.fit(X_train_ml, y_train_ml, sample_weight=sample_weights)\n",
        "\n",
        "\n",
        "y_pred_test = xgb_clf.predict(X_test_ml)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test_ml, y_pred_test)\n",
        "print(f\"Final Test Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report on Test Data:\\n\", classification_report(y_test_ml, y_pred_test))\n",
        "\n",
        "-\n",
        "y_pred_test_labels = label_encoder.inverse_transform(y_pred_test)\n",
        "predictions_df = pd.DataFrame({\"Predicted_Class\": y_pred_test_labels})\n",
        "predictions_df.to_csv(\"xgboost_weighted_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to xgboost_weighted_predictions.csv!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5542ae823aae4621937fbb18a6c480fc",
            "7814706326ba4e08be46ac2bce6a1ba9",
            "b103eb82067b446ba01e68c3d4b5c707",
            "ccb9867b625c466fa7b7ab86e2232e34",
            "048d6a67f1cc4445a64f1e0e6e7b8e78",
            "86f9121d5ad7406eb3e5c0e2eb83c80d",
            "12784b56e13e453896568a5c0d07e009",
            "1f5f114c9c6d4bf48b5bcbb5c5ba0bd8",
            "c0d9ff06680f4405b035283ee290dae2",
            "3b7fdcc242d646df99fc88bc82c48a74",
            "a8939a894b7348ecbdd239f3084f1ea2",
            "abec15d950004abb8d64e9e42770f747",
            "062a32a2dee1422f830cd3f1dd2e0219",
            "cc3e319dadd048a78acdcab9ae0dbfc7",
            "bbe1d6e9db2944c18bf080c86611a2e8",
            "8b1e830094ed4849955fe448a3ae880e",
            "cf039c1cc03b4a0db3896df0c5db3020",
            "66ace486599b4596a85a1b6ae2dfc7c3",
            "24ae0638ff2546fcb8d00b4c6a9e5016",
            "4432c69129644a859e414b63d0439e1f",
            "70df5d4e61694593a8f8e6ee1f9947d5",
            "c588b526352b4f9baa9358dc0230e595",
            "c5e423e9d54e49fa84b8403197da5cea",
            "f8d8fc86d75a4280b31f45f2c2be0096",
            "468f879041734b0283afe6e8da05c9b1",
            "396e0f61f94345b8a61021c792b6cbe7",
            "2c9809bcd8d549f38d4e952b955d9798",
            "339d98fbafc1493aa7e51d21570f536a",
            "14ccdff704bd4f9f840260f52fc2ccac",
            "3b3ac5e2f4c44d2eaa1af9e3517420cb",
            "e82cedbbda104e4c83c438d01982c93e",
            "d792fe3d56e04a609cca2814cd4af95b",
            "744ff37c0f18482ab67cda877ad9c676",
            "0592974f930543a58854cc5ea8d6600f",
            "338ab666d6294a0aa716bf80f4985159",
            "35402a30152a4aebb68f61d6f8d98639",
            "5873ad72b64b417ebfce0d94d3b14ede",
            "06d048447a9d440bbf58d3167611fb92",
            "9b8fef0a51a04027999f5071cdb586b8",
            "ecf4f83dcda949a8a8d7d49f5d7f4cf8",
            "2d4e73f1916c4116b3fbd2ba72019612",
            "118efbad7c404420a7ae018a1de21f9e",
            "075f470455e24caea12c16d3eb6246ac",
            "78ea49656e444cc28cf5447d97177a70",
            "6bd6d6eb13ba4a7ea528e8d72fa2e3b2",
            "f767103326594cd3a4bf5a7413dff1ff",
            "140ba05043a54b8f9afc9566cae9540f",
            "89492fa780234b918496dfc096abaef3",
            "c2a0e1b2c12e42c89c67595407019982",
            "6fb30998687947429910cc787a81ddb6",
            "d9f2fdcc3825498cab8e69604f842f1c",
            "3b3172d7238d41e1b233ba5a8a707375",
            "5ca6acbb0502477a9f80d8bd8d439588",
            "2ec4837692534769be63d6878427b233",
            "3ba91fb3ab0543c1b9c36a5e70725ac6"
          ]
        },
        "id": "Qe4mXNh1Ddgr",
        "outputId": "3fed2aa4-c64d-4411-9958-742d8884b2da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==4.30.2 in /usr/local/lib/python3.11/dist-packages (4.30.2)\n",
            "Requirement already satisfied: datasets==2.12.0 in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.12.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.12.0) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.12.0) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.12.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.12.0) (0.70.14)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets==2.12.0) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.12.0) (3.11.15)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.11/dist-packages (from datasets==2.12.0) (0.18.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.12.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.12.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.12.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.12.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.12.0) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.12.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.12.0) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.12.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.12.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.12.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.12.0) (1.17.0)\n",
            "Collecting torch\n",
            "  Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting filelock (from torch)\n",
            "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch)\n",
            "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting networkx (from torch)\n",
            "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
            "  Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch)\n",
            "  Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch)\n",
            "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.0.0\n",
            "    Uninstalling triton-2.0.0:\n",
            "      Successfully uninstalled triton-2.0.0\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.1\n",
            "    Uninstalling typing_extensions-4.13.1:\n",
            "      Successfully uninstalled typing_extensions-4.13.1\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0\n",
            "    Uninstalling torch-2.0.0:\n",
            "      Successfully uninstalled torch-2.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.30.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.3.2 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0 triton-3.2.0 typing-extensions-4.13.2\n",
            "\u001b[33mWARNING: Skipping peft as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.30.2)\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Using cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.13.3\n",
            "    Uninstalling tokenizers-0.13.3:\n",
            "      Successfully uninstalled tokenizers-0.13.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.30.2\n",
            "    Uninstalling transformers-4.30.2:\n",
            "      Successfully uninstalled transformers-4.30.2\n",
            "Successfully installed tokenizers-0.21.1 transformers-4.51.3\n",
            "     Gene             Variation  Class  \\\n",
            "0  FAM58A  Truncating Mutations      0   \n",
            "1     CBL                 W802*      1   \n",
            "2     CBL                 Q249E      1   \n",
            "\n",
            "                                                Text  \\\n",
            "0  Cyclin-dependent kinases (CDKs) regulate a var...   \n",
            "1   Abstract Background  Non-small cell lung canc...   \n",
            "2   Abstract Background  Non-small cell lung canc...   \n",
            "\n",
            "                                       combined_text  \n",
            "0  Gene: FAM58A | Variation: Truncating Mutations...  \n",
            "1  Gene: CBL | Variation: W802* |  Abstract Backg...  \n",
            "2  Gene: CBL | Variation: Q249E |  Abstract Backg...  \n",
            "Unique classes (mapped): [0 1 2 3 4 5 6 7 8]\n",
            "Train size: 2324\n",
            "Val size: 332\n",
            "Test size: 665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5542ae823aae4621937fbb18a6c480fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abec15d950004abb8d64e9e42770f747",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/462 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5e423e9d54e49fa84b8403197da5cea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0592974f930543a58854cc5ea8d6600f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bd6d6eb13ba4a7ea528e8d72fa2e3b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'device' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dd0af8fbc396>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m  \u001b[0;31m# classes [0..8]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m ).to(device)\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m training_args = TrainingArguments(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.30.2 datasets==2.12.0 evaluate sentencepiece\n",
        "!pip install torch --upgrade --force-reinstall  # or a compatible version\n",
        "!pip uninstall peft\n",
        "!pip install --upgrade transformers\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "\n",
        "import evaluate  # huggingface evaluate library\n",
        "from sklearn.model_selection import train_test_split\n",
        "dataset_path = \"/content/drive/MyDrive/msk-redefining-cancer-treatment\"\n",
        "\n",
        "train_variants = pd.read_csv(os.path.join(dataset_path, \"training_variants/training_variants\"))\n",
        "train_text = pd.read_csv(\n",
        "    os.path.join(dataset_path, \"training_text/training_text\"),\n",
        "    sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1\n",
        ")\n",
        "\n",
        "df = pd.merge(train_variants, train_text, on=\"ID\").drop(columns=[\"ID\"])\n",
        "df.fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "# Class mapping from [1..9] -> [0..8]\n",
        "class_mapping = {c: c-1 for c in sorted(df[\"Class\"].unique())}\n",
        "inverse_class_mapping = {v: k for k, v in class_mapping.items()}\n",
        "df[\"Class\"] = df[\"Class\"].map(class_mapping)\n",
        "\n",
        "# Combine textual fields (Gene, Variation, and the large Text)\n",
        "df[\"combined_text\"] = (\n",
        "    \"Gene: \" + df[\"Gene\"].astype(str) +\n",
        "    \" | Variation: \" + df[\"Variation\"].astype(str) +\n",
        "    \" | \" + df[\"Text\"].astype(str)\n",
        ")\n",
        "\n",
        "print(df.head(3))\n",
        "print(\"Unique classes (mapped):\", df[\"Class\"].unique())\n",
        "X = df[\"combined_text\"].values\n",
        "y = df[\"Class\"].values\n",
        "\n",
        "# 70/30\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# from that 30%, take 2/3 as test and 1/3 as val\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=(2/3), random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(\"Train size:\", len(X_train))\n",
        "print(\"Val size:\", len(X_val))\n",
        "print(\"Test size:\", len(X_test))\n",
        "class CancerTextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = int(self.labels[idx])\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Flatten because tokenizer returns batch dimension\n",
        "        item = {k: v.squeeze() for k, v in encoding.items()}\n",
        "        item[\"labels\"] = torch.tensor(label, dtype=torch.long)\n",
        "        return item\n",
        "MODEL_NAME = \"dmis-lab/biobert-v1.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "train_dataset = CancerTextDataset(X_train, y_train, tokenizer, max_length=256)\n",
        "val_dataset   = CancerTextDataset(X_val,   y_val,   tokenizer, max_length=256)\n",
        "test_dataset  = CancerTextDataset(X_test,  y_test,  tokenizer, max_length=256)\n",
        "class_counts = np.bincount(y_train)\n",
        "class_weights = 1.0 / class_counts\n",
        "\n",
        "# For each sample in y_train, assign a weight\n",
        "sample_weights = [class_weights[label] for label in y_train]\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=9  # classes [0..8]\n",
        ").to(device)\n",
        "batch_size = 8\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"bioBERT-checkpoints\",\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=5,  # try 3..5..10\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    save_total_limit=2,\n",
        "    seed=42\n",
        ")\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    acc = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    f1_micro = f1_metric.compute(predictions=predictions, references=labels, average=\"micro\")\n",
        "    f1_macro = f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
        "    return {\n",
        "        \"accuracy\": acc[\"accuracy\"],\n",
        "        \"f1_micro\": f1_micro[\"f1\"],\n",
        "        \"f1_macro\": f1_macro[\"f1\"]\n",
        "    }\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    # We'll override get_train_dataloader to inject WeightedRandomSampler\n",
        ")\n",
        "\n",
        "# We'll override how Trainer creates the train dataloader\n",
        "def get_train_dataloader():\n",
        "    return DataLoader(\n",
        "        train_dataset,\n",
        "        sampler=sampler,  # Weighted sampler\n",
        "        batch_size=training_args.per_device_train_batch_size,\n",
        "        collate_fn=trainer.data_collator\n",
        "    )\n",
        "\n",
        "trainer.get_train_dataloader = get_train_dataloader\n",
        "trainer.train()\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "print(\"Test Results:\", test_results)\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predictions_logits, labels, _ = trainer.predict(test_dataset)\n",
        "preds = np.argmax(predictions_logits, axis=1)\n",
        "\n",
        "print(\"Classification Report (Test):\\n\", classification_report(labels, preds))\n",
        "preds_original = [inverse_class_mapping[p] for p in preds]\n",
        "labels_original = [inverse_class_mapping[l] for l in labels]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7_Y_E1yRqxp",
        "outputId": "c214bd90-d3ec-437b-f2a0-29f3f98d14ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==4.30.2 in /usr/local/lib/python3.11/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (2025.1.31)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.14.1)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.14.1)\n",
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.11/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (from imblearn) (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (3.6.0)\n",
            "     Gene             Variation  Class  \\\n",
            "0  FAM58A  Truncating Mutations      0   \n",
            "1     CBL                 W802*      1   \n",
            "2     CBL                 Q249E      1   \n",
            "3     CBL                 N454D      2   \n",
            "4     CBL                 L399V      3   \n",
            "\n",
            "                                                Text  \n",
            "0  Cyclin-dependent kinases (CDKs) regulate a var...  \n",
            "1   Abstract Background  Non-small cell lung canc...  \n",
            "2   Abstract Background  Non-small cell lung canc...  \n",
            "3  Recent evidence has demonstrated that acquired...  \n",
            "4  Oncogenic mutations in the monomeric Casitas B...  \n",
            "Class\n",
            "6    953\n",
            "3    686\n",
            "0    568\n",
            "1    452\n",
            "5    275\n",
            "4    242\n",
            "2     89\n",
            "8     37\n",
            "7     19\n",
            "Name: count, dtype: int64\n",
            "Gene OHE Shape: (3321, 264)\n",
            "Variation OHE Shape: (3321, 2996)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT Embeddings Shape: (3321, 768)\n",
            "Combined Feature Shape: (3321, 4028)\n",
            "Train: (2324, 4028) (2324,)\n",
            "Val:   (332, 4028) (332,)\n",
            "Test:  (665, 4028) (665,)\n",
            "Train after SMOTE: (6003, 4028) (6003,)\n",
            "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.988042\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.162344\n",
            "[LightGBM] [Debug] init for col-wise cost 0.005802 seconds, init for row-wise cost 0.138446 seconds\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.159873 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 198375\n",
            "[LightGBM] [Info] Number of data points in the train set: 6003, number of used features: 919\n",
            "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
            "[LightGBM] [Info] Start training from score -2.197225\n",
            "[LightGBM] [Info] Start training from score -2.197225\n",
            "[LightGBM] [Info] Start training from score -2.197225\n",
            "[LightGBM] [Info] Start training from score -2.197225\n",
            "[LightGBM] [Info] Start training from score -2.197225\n",
            "[LightGBM] [Info] Start training from score -2.197225\n",
            "[LightGBM] [Info] Start training from score -2.197225\n",
            "[LightGBM] [Info] Start training from score -2.197225\n",
            "[LightGBM] [Info] Start training from score -2.197225\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 22 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 19 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 9\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 23 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 18 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 20 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 19 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 20 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 22 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 20 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 21 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 24 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 24 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 18 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 24 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 22 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 16 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 22 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
            "Early stopping, best iteration is:\n",
            "[56]\tvalid_0's multi_logloss: 1.28801\n",
            "Validation Accuracy: 0.5753\n",
            "Test Accuracy:       0.6241\n",
            "\n",
            "Classification Report (Val):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.56      0.58        57\n",
            "           1       0.45      0.47      0.46        45\n",
            "           2       0.18      0.22      0.20         9\n",
            "           3       0.65      0.54      0.59        69\n",
            "           4       0.43      0.54      0.48        24\n",
            "           5       0.62      0.56      0.59        27\n",
            "           6       0.65      0.71      0.68        95\n",
            "           7       0.50      0.50      0.50         2\n",
            "           8       0.75      0.75      0.75         4\n",
            "\n",
            "    accuracy                           0.58       332\n",
            "   macro avg       0.54      0.54      0.54       332\n",
            "weighted avg       0.58      0.58      0.58       332\n",
            "\n",
            "Classification Report (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.59      0.65       113\n",
            "           1       0.56      0.60      0.58        91\n",
            "           2       0.29      0.33      0.31        18\n",
            "           3       0.72      0.64      0.67       137\n",
            "           4       0.33      0.53      0.41        49\n",
            "           5       0.65      0.55      0.59        55\n",
            "           6       0.70      0.73      0.71       191\n",
            "           7       0.00      0.00      0.00         4\n",
            "           8       0.71      0.71      0.71         7\n",
            "\n",
            "    accuracy                           0.62       665\n",
            "   macro avg       0.52      0.52      0.52       665\n",
            "weighted avg       0.64      0.62      0.63       665\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.30.2\n",
        "!pip install sentencepiece  # sometimes needed for tokenizers\n",
        "!pip install lightgbm\n",
        "!pip install --upgrade lightgbm\n",
        "!pip install imblearn\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# For text encoding (Hugging Face)\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# For model training\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "# Example paths (adjust to your environment)\n",
        "dataset_path = \"/content/drive/MyDrive/msk-redefining-cancer-treatment\"\n",
        "\n",
        "train_variants = pd.read_csv(os.path.join(dataset_path, \"training_variants/training_variants\"))\n",
        "train_text = pd.read_csv(\n",
        "    os.path.join(dataset_path, \"training_text/training_text\"),\n",
        "    sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1\n",
        ")\n",
        "\n",
        "# Merge\n",
        "train_df = pd.merge(train_variants, train_text, on=\"ID\")\n",
        "train_df.drop(columns=[\"ID\"], inplace=True)\n",
        "\n",
        "# Fill missing\n",
        "train_df.fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "# Map Classes from [1-9] → [0-8]\n",
        "class_mapping = {label: label-1 for label in sorted(train_df[\"Class\"].unique())}\n",
        "inverse_class_mapping = {v: k for k, v in class_mapping.items()}\n",
        "train_df[\"Class\"] = train_df[\"Class\"].map(class_mapping)\n",
        "\n",
        "print(train_df.head())\n",
        "print(train_df[\"Class\"].value_counts())\n",
        "gene_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "variation_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "gene_ohe = gene_encoder.fit_transform(train_df[[\"Gene\"]])\n",
        "variation_ohe = variation_encoder.fit_transform(train_df[[\"Variation\"]])\n",
        "\n",
        "print(\"Gene OHE Shape:\", gene_ohe.shape)\n",
        "print(\"Variation OHE Shape:\", variation_ohe.shape)\n",
        "\n",
        "MODEL_NAME = \"dmis-lab/biobert-v1.1\"\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "transformer_model = AutoModel.from_pretrained(MODEL_NAME)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "transformer_model.to(device)\n",
        "\n",
        "def get_bert_embedding(text, max_length=256):\n",
        "    \"\"\"\n",
        "    Returns a single pooled embedding (CLS) for the input text.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "    # Move to GPU if available\n",
        "    for k, v in inputs.items():\n",
        "        inputs[k] = v.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = transformer_model(**inputs)\n",
        "        # outputs.last_hidden_state.shape = (batch_size=1, seq_len=256, hidden_size=768)\n",
        "        # We can take the CLS token embedding: outputs.last_hidden_state[:,0,:]\n",
        "        cls_embedding = outputs.last_hidden_state[:,0,:].squeeze()\n",
        "\n",
        "    # Return as CPU numpy array\n",
        "    return cls_embedding.cpu().numpy()\n",
        "\n",
        "#%%time\n",
        "\n",
        "all_texts = train_df[\"Text\"].values\n",
        "bert_embeddings = []\n",
        "\n",
        "for i, txt in enumerate(all_texts):\n",
        "    emb = get_bert_embedding(str(txt))\n",
        "    bert_embeddings.append(emb)\n",
        "\n",
        "bert_embeddings = np.stack(bert_embeddings)\n",
        "print(\"BERT Embeddings Shape:\", bert_embeddings.shape)  # (N, 768)\n",
        "\n",
        "X_full = np.concatenate([gene_ohe, variation_ohe, bert_embeddings], axis=1)\n",
        "y_full = train_df[\"Class\"].values  # shape (N,)\n",
        "\n",
        "print(\"Combined Feature Shape:\", X_full.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_full, y_full, test_size=0.3, random_state=42, stratify=y_full\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_test, y_test, test_size=2/3, random_state=42, stratify=y_test\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, y_train.shape)\n",
        "print(\"Val:  \", X_val.shape, y_val.shape)\n",
        "print(\"Test: \", X_test.shape, y_test.shape)\n",
        "\n",
        "# SMOTE on train only\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Train after SMOTE:\", X_train_res.shape, y_train_res.shape)\n",
        "\n",
        "lgb_clf = LGBMClassifier(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=10,\n",
        "    class_weight='balanced',  # extra handle for imbalance\n",
        "    random_state=42,\n",
        "    early_stopping_rounds=50,\n",
        "    verbose=50,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgb_clf.fit(\n",
        "    X_train_res, y_train_res,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    eval_metric=\"multi_logloss\",\n",
        "\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "val_preds = lgb_clf.predict(X_val)\n",
        "test_preds = lgb_clf.predict(X_test)\n",
        "\n",
        "val_acc = accuracy_score(y_val, val_preds)\n",
        "test_acc = accuracy_score(y_test, test_preds)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "print(f\"Test Accuracy:       {test_acc:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report (Val):\")\n",
        "print(classification_report(y_val, val_preds))\n",
        "print(\"Classification Report (Test):\")\n",
        "print(classification_report(y_test, test_preds))\n",
        "\n",
        "# Convert back to 1-9 if desired\n",
        "val_preds_original = [inverse_class_mapping[p] for p in val_preds]\n",
        "test_preds_original = [inverse_class_mapping[p] for p in test_preds]\n",
        "\n",
        "pd.DataFrame({\"Predicted_Class\": val_preds_original}).to_csv(\"lgb_val_predictions.csv\", index=False)\n",
        "pd.DataFrame({\"Predicted_Class\": test_preds_original}).to_csv(\"lgb_test_predictions.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6oIgJ0WOhgN",
        "outputId": "71675475-1b9b-4ab7-b6b7-694fd789db5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Shape: (2324, 8260), Labels: (2324,)\n",
            "Validation Shape: (332, 8260), Labels: (332,)\n",
            "Test Shape: (665, 8260), Labels: (665,)\n",
            "Train Shape after SMOTE: (6003, 8260), Labels: (6003,)\n",
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "Best Hyperparameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 15, 'class_weight': None}\n",
            "Best CV Score (Accuracy): 0.8592370481425954\n",
            "Tuned Model Validation Accuracy: 0.6265\n",
            "\n",
            "Tuned Validation Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.49      0.61      0.54        57\n",
            "           2       0.67      0.53      0.59        45\n",
            "           3       0.40      0.22      0.29         9\n",
            "           4       0.63      0.58      0.61        69\n",
            "           5       0.50      0.46      0.48        24\n",
            "           6       0.87      0.48      0.62        27\n",
            "           7       0.70      0.84      0.76        95\n",
            "           8       0.00      0.00      0.00         2\n",
            "           9       0.75      0.75      0.75         4\n",
            "\n",
            "    accuracy                           0.63       332\n",
            "   macro avg       0.56      0.50      0.52       332\n",
            "weighted avg       0.63      0.63      0.62       332\n",
            "\n",
            "Tuned Model Test Accuracy: 0.6211\n",
            "\n",
            "Tuned Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.58      0.56      0.57       113\n",
            "           2       0.54      0.46      0.50        91\n",
            "           3       0.44      0.39      0.41        18\n",
            "           4       0.65      0.68      0.66       137\n",
            "           5       0.40      0.47      0.43        49\n",
            "           6       0.82      0.56      0.67        55\n",
            "           7       0.69      0.78      0.73       191\n",
            "           8       0.00      0.00      0.00         4\n",
            "           9       0.83      0.71      0.77         7\n",
            "\n",
            "    accuracy                           0.62       665\n",
            "   macro avg       0.55      0.51      0.53       665\n",
            "weighted avg       0.62      0.62      0.62       665\n",
            "\n",
            "Tuned RF Validation & Test Predictions saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Sklearn & Imblearn\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/msk-redefining-cancer-treatment\"\n",
        "\n",
        "train_variants = pd.read_csv(os.path.join(dataset_path, \"training_variants/training_variants\"))\n",
        "train_text = pd.read_csv(os.path.join(dataset_path, \"training_text/training_text\"), sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1)\n",
        "\n",
        "# --- 📌 Merge Variants and Text Data ---\n",
        "train_df = pd.merge(train_variants, train_text, on=\"ID\")\n",
        "\n",
        "# Drop ID column (not useful for modeling)\n",
        "train_df.drop(columns=[\"ID\"], inplace=True)\n",
        "\n",
        "# Handle Missing Values\n",
        "train_df.fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "class_mapping = {label: idx - 1 for idx, label in enumerate(sorted(train_df[\"Class\"].unique()), start=1)}\n",
        "inverse_class_mapping = {v: k for k, v in class_mapping.items()}\n",
        "train_df[\"Class\"] = train_df[\"Class\"].map(class_mapping)\n",
        "\n",
        "gene_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "variation_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "gene_encoded = gene_encoder.fit_transform(train_df[[\"Gene\"]])\n",
        "variation_encoded = variation_encoder.fit_transform(train_df[[\"Variation\"]])\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\", ngram_range=(1,2))\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(train_df[\"Text\"])\n",
        "\n",
        "X_ml = hstack((gene_encoded, variation_encoded, X_tfidf))\n",
        "y_ml = train_df[\"Class\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_ml, y_ml, test_size=0.3, random_state=42, stratify=y_ml)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=2/3, random_state=42, stratify=y_test)\n",
        "\n",
        "print(f\"Train Shape: {X_train.shape}, Labels: {y_train.shape}\")\n",
        "print(f\"Validation Shape: {X_val.shape}, Labels: {y_val.shape}\")\n",
        "print(f\"Test Shape: {X_test.shape}, Labels: {y_test.shape}\")\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"Train Shape after SMOTE: {X_train_resampled.shape}, Labels: {y_train_resampled.shape}\")\n",
        "\n",
        "X_train_resampled = X_train_resampled.toarray()\n",
        "X_val_dense = X_val.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "param_dist = {\n",
        "    \"n_estimators\": [100, 300, 500, 700],\n",
        "    \"max_depth\": [5, 10, 15, None],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4],\n",
        "    \"max_features\": [\"sqrt\", \"log2\"],\n",
        "    \"class_weight\": [\"balanced\", \"balanced_subsample\", None]\n",
        "}\n",
        "\n",
        "rf_clf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "\n",
        "random_search_rf = RandomizedSearchCV(\n",
        "    estimator=rf_clf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,         # Number of random parameter combos\n",
        "    scoring=\"accuracy\",\n",
        "    cv=3,              # 3-fold CV\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "random_search_rf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "print(\"Best Hyperparameters:\", random_search_rf.best_params_)\n",
        "print(\"Best CV Score (Accuracy):\", random_search_rf.best_score_)\n",
        "\n",
        "best_rf = random_search_rf.best_estimator_\n",
        "\n",
        "y_pred_val = best_rf.predict(X_val_dense)\n",
        "y_pred_test = best_rf.predict(X_test_dense)\n",
        "\n",
        "# Convert Predictions (0-8) Back to (1-9)\n",
        "y_pred_val_original = [inverse_class_mapping[label] for label in y_pred_val]\n",
        "y_val_original = [inverse_class_mapping[label] for label in y_val]\n",
        "y_pred_test_original = [inverse_class_mapping[label] for label in y_pred_test]\n",
        "y_test_original = [inverse_class_mapping[label] for label in y_test]\n",
        "\n",
        "val_accuracy = accuracy_score(y_val_original, y_pred_val_original)\n",
        "print(f\"Tuned Model Validation Accuracy: {val_accuracy:.4f}\")\n",
        "print(\"\\nTuned Validation Classification Report:\\n\",\n",
        "      classification_report(y_val_original, y_pred_val_original))\n",
        "\n",
        "test_accuracy = accuracy_score(y_test_original, y_pred_test_original)\n",
        "print(f\"Tuned Model Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(\"\\nTuned Test Classification Report:\\n\",\n",
        "      classification_report(y_test_original, y_pred_test_original))\n",
        "\n",
        "val_predictions_df = pd.DataFrame({\"Predicted_Class\": y_pred_val_original})\n",
        "test_predictions_df = pd.DataFrame({\"Predicted_Class\": y_pred_test_original})\n",
        "\n",
        "val_predictions_df.to_csv(\"tuned_rf_validation_predictions.csv\", index=False)\n",
        "test_predictions_df.to_csv(\"tuned_rf_test_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Tuned RF Validation & Test Predictions saved!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwtRIUIHRBam",
        "outputId": "bdf04f8d-44b9-4b4f-f66d-c4f38be210dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Shape: (2324, 8260), Labels: (2324,)\n",
            "Validation Shape: (332, 8260), Labels: (332,)\n",
            "Test Shape: (665, 8260), Labels: (665,)\n",
            "Train Shape after SMOTE: (6003, 8260), Labels: (6003,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:24:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:2.13083\n",
            "[1]\tvalidation_0-mlogloss:2.07294\n",
            "[2]\tvalidation_0-mlogloss:2.02262\n",
            "[3]\tvalidation_0-mlogloss:1.97417\n",
            "[4]\tvalidation_0-mlogloss:1.93053\n",
            "[5]\tvalidation_0-mlogloss:1.89185\n",
            "[6]\tvalidation_0-mlogloss:1.85514\n",
            "[7]\tvalidation_0-mlogloss:1.82082\n",
            "[8]\tvalidation_0-mlogloss:1.78782\n",
            "[9]\tvalidation_0-mlogloss:1.75946\n",
            "[10]\tvalidation_0-mlogloss:1.73203\n",
            "[11]\tvalidation_0-mlogloss:1.70435\n",
            "[12]\tvalidation_0-mlogloss:1.67994\n",
            "[13]\tvalidation_0-mlogloss:1.65563\n",
            "[14]\tvalidation_0-mlogloss:1.63426\n",
            "[15]\tvalidation_0-mlogloss:1.61273\n",
            "[16]\tvalidation_0-mlogloss:1.59302\n",
            "[17]\tvalidation_0-mlogloss:1.57421\n",
            "[18]\tvalidation_0-mlogloss:1.55440\n",
            "[19]\tvalidation_0-mlogloss:1.53642\n",
            "[20]\tvalidation_0-mlogloss:1.51976\n",
            "[21]\tvalidation_0-mlogloss:1.50414\n",
            "[22]\tvalidation_0-mlogloss:1.49075\n",
            "[23]\tvalidation_0-mlogloss:1.47679\n",
            "[24]\tvalidation_0-mlogloss:1.46255\n",
            "[25]\tvalidation_0-mlogloss:1.45055\n",
            "[26]\tvalidation_0-mlogloss:1.43890\n",
            "[27]\tvalidation_0-mlogloss:1.42694\n",
            "[28]\tvalidation_0-mlogloss:1.41520\n",
            "[29]\tvalidation_0-mlogloss:1.40476\n",
            "[30]\tvalidation_0-mlogloss:1.39401\n",
            "[31]\tvalidation_0-mlogloss:1.38317\n",
            "[32]\tvalidation_0-mlogloss:1.37104\n",
            "[33]\tvalidation_0-mlogloss:1.35922\n",
            "[34]\tvalidation_0-mlogloss:1.35046\n",
            "[35]\tvalidation_0-mlogloss:1.34002\n",
            "[36]\tvalidation_0-mlogloss:1.33089\n",
            "[37]\tvalidation_0-mlogloss:1.32280\n",
            "[38]\tvalidation_0-mlogloss:1.31569\n",
            "[39]\tvalidation_0-mlogloss:1.30900\n",
            "[40]\tvalidation_0-mlogloss:1.30209\n",
            "[41]\tvalidation_0-mlogloss:1.29342\n",
            "[42]\tvalidation_0-mlogloss:1.28588\n",
            "[43]\tvalidation_0-mlogloss:1.27766\n",
            "[44]\tvalidation_0-mlogloss:1.27078\n",
            "[45]\tvalidation_0-mlogloss:1.26426\n",
            "[46]\tvalidation_0-mlogloss:1.25791\n",
            "[47]\tvalidation_0-mlogloss:1.25205\n",
            "[48]\tvalidation_0-mlogloss:1.24558\n",
            "[49]\tvalidation_0-mlogloss:1.24041\n",
            "[50]\tvalidation_0-mlogloss:1.23422\n",
            "[51]\tvalidation_0-mlogloss:1.22896\n",
            "[52]\tvalidation_0-mlogloss:1.22361\n",
            "[53]\tvalidation_0-mlogloss:1.21878\n",
            "[54]\tvalidation_0-mlogloss:1.21418\n",
            "[55]\tvalidation_0-mlogloss:1.20928\n",
            "[56]\tvalidation_0-mlogloss:1.20587\n",
            "[57]\tvalidation_0-mlogloss:1.20203\n",
            "[58]\tvalidation_0-mlogloss:1.19785\n",
            "[59]\tvalidation_0-mlogloss:1.19424\n",
            "[60]\tvalidation_0-mlogloss:1.19117\n",
            "[61]\tvalidation_0-mlogloss:1.18761\n",
            "[62]\tvalidation_0-mlogloss:1.18388\n",
            "[63]\tvalidation_0-mlogloss:1.18104\n",
            "[64]\tvalidation_0-mlogloss:1.17781\n",
            "[65]\tvalidation_0-mlogloss:1.17454\n",
            "[66]\tvalidation_0-mlogloss:1.17174\n",
            "[67]\tvalidation_0-mlogloss:1.16879\n",
            "[68]\tvalidation_0-mlogloss:1.16633\n",
            "[69]\tvalidation_0-mlogloss:1.16293\n",
            "[70]\tvalidation_0-mlogloss:1.15979\n",
            "[71]\tvalidation_0-mlogloss:1.15705\n",
            "[72]\tvalidation_0-mlogloss:1.15455\n",
            "[73]\tvalidation_0-mlogloss:1.15211\n",
            "[74]\tvalidation_0-mlogloss:1.14936\n",
            "[75]\tvalidation_0-mlogloss:1.14755\n",
            "[76]\tvalidation_0-mlogloss:1.14502\n",
            "[77]\tvalidation_0-mlogloss:1.14279\n",
            "[78]\tvalidation_0-mlogloss:1.14000\n",
            "[79]\tvalidation_0-mlogloss:1.13871\n",
            "[80]\tvalidation_0-mlogloss:1.13661\n",
            "[81]\tvalidation_0-mlogloss:1.13444\n",
            "[82]\tvalidation_0-mlogloss:1.13239\n",
            "[83]\tvalidation_0-mlogloss:1.13023\n",
            "[84]\tvalidation_0-mlogloss:1.12814\n",
            "[85]\tvalidation_0-mlogloss:1.12664\n",
            "[86]\tvalidation_0-mlogloss:1.12491\n",
            "[87]\tvalidation_0-mlogloss:1.12276\n",
            "[88]\tvalidation_0-mlogloss:1.12123\n",
            "[89]\tvalidation_0-mlogloss:1.12030\n",
            "[90]\tvalidation_0-mlogloss:1.11963\n",
            "[91]\tvalidation_0-mlogloss:1.11852\n",
            "[92]\tvalidation_0-mlogloss:1.11736\n",
            "[93]\tvalidation_0-mlogloss:1.11640\n",
            "[94]\tvalidation_0-mlogloss:1.11506\n",
            "[95]\tvalidation_0-mlogloss:1.11476\n",
            "[96]\tvalidation_0-mlogloss:1.11401\n",
            "[97]\tvalidation_0-mlogloss:1.11335\n",
            "[98]\tvalidation_0-mlogloss:1.11306\n",
            "[99]\tvalidation_0-mlogloss:1.11150\n",
            "Validation Accuracy: 0.6084\n",
            "\n",
            "Validation Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.54      0.68      0.60        57\n",
            "           2       0.49      0.49      0.49        45\n",
            "           3       0.25      0.22      0.24         9\n",
            "           4       0.66      0.57      0.61        69\n",
            "           5       0.48      0.46      0.47        24\n",
            "           6       0.82      0.52      0.64        27\n",
            "           7       0.69      0.76      0.72        95\n",
            "           8       1.00      0.50      0.67         2\n",
            "           9       0.67      0.50      0.57         4\n",
            "\n",
            "    accuracy                           0.61       332\n",
            "   macro avg       0.62      0.52      0.56       332\n",
            "weighted avg       0.62      0.61      0.61       332\n",
            "\n",
            "Final Test Accuracy: 0.6316\n",
            "\n",
            "Final Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.63      0.62      0.62       113\n",
            "           2       0.56      0.52      0.54        91\n",
            "           3       0.42      0.44      0.43        18\n",
            "           4       0.66      0.64      0.65       137\n",
            "           5       0.37      0.51      0.43        49\n",
            "           6       0.86      0.58      0.70        55\n",
            "           7       0.70      0.76      0.73       191\n",
            "           8       0.00      0.00      0.00         4\n",
            "           9       0.67      0.57      0.62         7\n",
            "\n",
            "    accuracy                           0.63       665\n",
            "   macro avg       0.54      0.52      0.52       665\n",
            "weighted avg       0.64      0.63      0.63       665\n",
            "\n",
            "Validation & Test Predictions saved to CSV files!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os\n",
        "\n",
        "# --- 📌 Load Train Data Only ---\n",
        "dataset_path = \"/content/drive/MyDrive/msk-redefining-cancer-treatment\"\n",
        "\n",
        "train_variants = pd.read_csv(os.path.join(dataset_path, \"training_variants/training_variants\"))\n",
        "train_text = pd.read_csv(os.path.join(dataset_path, \"training_text/training_text\"), sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1)\n",
        "\n",
        "# --- 📌 Merge Variants and Text Data ---\n",
        "train_df = pd.merge(train_variants, train_text, on=\"ID\")\n",
        "\n",
        "# Drop ID column (not useful for modeling)\n",
        "train_df.drop(columns=[\"ID\"], inplace=True)\n",
        "\n",
        "# Handle Missing Values\n",
        "train_df.fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "# --- 📌 Encode Class Labels (1-9) and Shift for XGBoost (0-8) ---\n",
        "class_mapping = {label: idx - 1 for idx, label in enumerate(sorted(train_df[\"Class\"].unique()), start=1)}\n",
        "inverse_class_mapping = {v: k for k, v in class_mapping.items()}\n",
        "train_df[\"Class\"] = train_df[\"Class\"].map(class_mapping)\n",
        "\n",
        "# --- 📌 Encode Gene and Variation (One-Hot Encoding) ---\n",
        "gene_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "variation_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "gene_encoded = gene_encoder.fit_transform(train_df[[\"Gene\"]])\n",
        "variation_encoded = variation_encoder.fit_transform(train_df[[\"Variation\"]])\n",
        "\n",
        "# --- 📌 Apply TF-IDF to Text Data ---\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\", ngram_range=(1, 2))\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df[\"Text\"])\n",
        "\n",
        "# --- 📌 Concatenate Features for XGBoost ---\n",
        "X_ml = hstack((gene_encoded, variation_encoded, X_train_tfidf))\n",
        "y_ml = train_df[\"Class\"]\n",
        "\n",
        "# --- 📌 Split Data (Train 70%, Test 20%, Validation 10%) ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_ml, y_ml, test_size=0.3, random_state=42, stratify=y_ml)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=2/3, random_state=42, stratify=y_test)\n",
        "\n",
        "print(f\"Train Shape: {X_train.shape}, Labels: {y_train.shape}\")\n",
        "print(f\"Validation Shape: {X_val.shape}, Labels: {y_val.shape}\")\n",
        "print(f\"Test Shape: {X_test.shape}, Labels: {y_test.shape}\")\n",
        "\n",
        "# --- 📌 Apply SMOTE (Only on Train Data) ---\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"Train Shape after SMOTE: {X_train_resampled.shape}, Labels: {y_train_resampled.shape}\")\n",
        "\n",
        "# --- 📌 Convert Sparse Matrices to NumPy Arrays ---\n",
        "X_train_resampled = X_train_resampled.toarray()\n",
        "X_val = X_val.toarray()\n",
        "X_test = X_test.toarray()\n",
        "\n",
        "# --- 📌 Train XGBoost Model ---\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    n_estimators=100, max_depth=5, learning_rate=0.05, gamma=0.2,\n",
        "    objective=\"multi:softmax\", num_class=9, eval_metric=\"mlogloss\", use_label_encoder=False\n",
        ")\n",
        "\n",
        "xgb_clf.fit(\n",
        "    X_train_resampled, y_train_resampled,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# --- 📌 Predict on Validation & Test Data ---\n",
        "y_pred_val = xgb_clf.predict(X_val)\n",
        "y_pred_test = xgb_clf.predict(X_test)\n",
        "\n",
        "# Convert Predictions Back to Original Labels\n",
        "y_pred_val_original = np.array([inverse_class_mapping[label] for label in y_pred_val])\n",
        "y_pred_test_original = np.array([inverse_class_mapping[label] for label in y_pred_test])\n",
        "y_val_original = np.array([inverse_class_mapping[label] for label in y_val])\n",
        "y_test_original = np.array([inverse_class_mapping[label] for label in y_test])\n",
        "\n",
        "# --- 📌 Evaluate on Validation Data ---\n",
        "val_accuracy = accuracy_score(y_val_original, y_pred_val_original)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "print(\"\\nValidation Classification Report:\\n\", classification_report(y_val_original, y_pred_val_original))\n",
        "\n",
        "# --- 📌 Evaluate on Test Data ---\n",
        "test_accuracy = accuracy_score(y_test_original, y_pred_test_original)\n",
        "print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(\"\\nFinal Classification Report:\\n\", classification_report(y_test_original, y_pred_test_original))\n",
        "\n",
        "# --- 📌 Save Predictions ---\n",
        "val_predictions_df = pd.DataFrame({\"Predicted_Class\": y_pred_val_original})\n",
        "test_predictions_df = pd.DataFrame({\"Predicted_Class\": y_pred_test_original})\n",
        "\n",
        "val_predictions_df.to_csv(\"xgboost_validation_predictions.csv\", index=False)\n",
        "test_predictions_df.to_csv(\"xgboost_test_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Validation & Test Predictions saved to CSV files!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3NjR9o-hw7E",
        "outputId": "3b692357-9cea-4774-af94-b7dfcc8b570b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "\n",
        "# --- 📌 Define Parameter Grid ---\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 300, 500, 700],  # Number of trees\n",
        "    'max_depth': [3, 5, 7, 9],  # Depth of trees\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # Step size\n",
        "    'gamma': [0, 0.1, 0.2, 0.3],  # Regularization parameter\n",
        "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9],  # Feature sampling\n",
        "    'subsample': [0.7, 0.8, 0.9, 1.0],  # Row sampling\n",
        "    'min_child_weight': [1, 3, 5],  # Minimum weight for new leaves\n",
        "    'reg_lambda': [0.01, 0.1, 1],  # L2 Regularization\n",
        "    'reg_alpha': [0, 0.01, 0.1]  # L1 Regularization\n",
        "}\n",
        "\n",
        "# --- 📌 Initialize XGBoost Classifier ---\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective=\"multi:softmax\",\n",
        "    num_class=9,  # Ensuring it knows there are 9 classes (0-8)\n",
        "    eval_metric=\"mlogloss\",\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "# --- 📌 Randomized Search (Faster Hyperparameter Tuning) ---\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_clf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,  # Number of random combinations to test (much faster than GridSearch)\n",
        "    scoring=\"accuracy\",  # Optimize for accuracy\n",
        "    cv=3,  # 3-fold Cross-validation (faster than 5-fold)\n",
        "    verbose=2,  # Show training progress\n",
        "    n_jobs=-1,  # Use all CPU cores\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# --- 📌 Run Hyperparameter Tuning ---\n",
        "random_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# --- 📌 Print Best Hyperparameters ---\n",
        "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
        "print(\"Best Validation Accuracy:\", random_search.best_score_)\n",
        "\n",
        "# --- 📌 Train Final Model Using Best Hyperparameters ---\n",
        "best_xgb = random_search.best_estimator_\n",
        "\n",
        "# --- 📌 Predict on Validation & Test Data ---\n",
        "y_pred_val = best_xgb.predict(X_val)\n",
        "y_pred_test = best_xgb.predict(X_test)\n",
        "\n",
        "# --- 📌 Convert Predictions Back to Original Class Labels ---\n",
        "y_pred_val_original = np.array([inverse_class_mapping[label] for label in y_pred_val])\n",
        "y_pred_test_original = np.array([inverse_class_mapping[label] for label in y_pred_test])\n",
        "y_val_original = np.array([inverse_class_mapping[label] for label in y_val])\n",
        "y_test_original = np.array([inverse_class_mapping[label] for label in y_test])\n",
        "\n",
        "# --- 📌 Evaluate on Validation Data ---\n",
        "val_accuracy = accuracy_score(y_val_original, y_pred_val_original)\n",
        "print(f\"Tuned Model Validation Accuracy: {val_accuracy:.4f}\")\n",
        "print(\"\\nTuned Validation Classification Report:\\n\", classification_report(y_val_original, y_pred_val_original))\n",
        "\n",
        "# --- 📌 Evaluate on Test Data ---\n",
        "test_accuracy = accuracy_score(y_test_original, y_pred_test_original)\n",
        "print(f\"Tuned Model Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(\"\\nTuned Test Classification Report:\\n\", classification_report(y_test_original, y_pred_test_original))\n",
        "\n",
        "# --- 📌 Save Predictions ---\n",
        "val_predictions_df = pd.DataFrame({\"Predicted_Class\": y_pred_val_original})\n",
        "test_predictions_df = pd.DataFrame({\"Predicted_Class\": y_pred_test_original})\n",
        "\n",
        "val_predictions_df.to_csv(\"tuned_xgboost_validation_predictions.csv\", index=False)\n",
        "test_predictions_df.to_csv(\"tuned_xgboost_test_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Tuned Validation & Test Predictions saved to CSV files!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOfSAwAyYUIO",
        "outputId": "607d0f12-e517-44cd-a05c-2bbf85ae06ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:46:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.2656 - loss: 1.9473 - val_accuracy: 0.2970 - val_loss: 1.8446\n",
            "Epoch 2/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2885 - loss: 1.8120 - val_accuracy: 0.4868 - val_loss: 1.5402\n",
            "Epoch 3/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5578 - loss: 1.3422 - val_accuracy: 0.5113 - val_loss: 1.2962\n",
            "Epoch 4/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6754 - loss: 0.9937 - val_accuracy: 0.5977 - val_loss: 1.2342\n",
            "Epoch 5/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7292 - loss: 0.8074 - val_accuracy: 0.5620 - val_loss: 1.3390\n",
            "Epoch 6/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7565 - loss: 0.7319 - val_accuracy: 0.5395 - val_loss: 1.3666\n",
            "Epoch 7/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7803 - loss: 0.6144 - val_accuracy: 0.5564 - val_loss: 1.3885\n",
            "Epoch 8/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7859 - loss: 0.5588 - val_accuracy: 0.5489 - val_loss: 1.4329\n",
            "Epoch 9/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7989 - loss: 0.5420 - val_accuracy: 0.5564 - val_loss: 1.4298\n",
            "Epoch 10/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8131 - loss: 0.4715 - val_accuracy: 0.5564 - val_loss: 1.4611\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Hybrid XGBoost + LSTM Accuracy: 0.6030\n",
            "\n",
            "Hybrid Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.56      0.65      0.60       114\n",
            "           2       0.55      0.44      0.49        91\n",
            "           3       0.27      0.17      0.21        18\n",
            "           4       0.72      0.59      0.65       137\n",
            "           5       0.31      0.40      0.35        48\n",
            "           6       0.86      0.55      0.67        55\n",
            "           7       0.65      0.78      0.71       191\n",
            "           8       0.00      0.00      0.00         4\n",
            "           9       0.56      0.71      0.62         7\n",
            "\n",
            "    accuracy                           0.60       665\n",
            "   macro avg       0.50      0.48      0.48       665\n",
            "weighted avg       0.61      0.60      0.60       665\n",
            "\n",
            "Predictions saved to hybrid_xgboost_lstm_predictions.csv!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os\n",
        "\n",
        "# --- 📌 Load Train Data Only ---\n",
        "dataset_path = \"/content/drive/MyDrive/msk-redefining-cancer-treatment\"\n",
        "\n",
        "train_variants = pd.read_csv(os.path.join(dataset_path, \"training_variants/training_variants\"))\n",
        "train_text = pd.read_csv(os.path.join(dataset_path, \"training_text/training_text\"), sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1)\n",
        "\n",
        "# --- 📌 Merge Variants and Text Data ---\n",
        "train_df = pd.merge(train_variants, train_text, on=\"ID\")\n",
        "\n",
        "# Drop ID column (not useful for modeling)\n",
        "train_df.drop(columns=[\"ID\"], inplace=True)\n",
        "\n",
        "# Handle Missing Values\n",
        "train_df.fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "# --- 📌 Encode Class Labels (1-9) and Shift for XGBoost (0-8) ---\n",
        "class_mapping = {label: idx - 1 for idx, label in enumerate(sorted(train_df[\"Class\"].unique()), start=1)}\n",
        "inverse_class_mapping = {v: k for k, v in class_mapping.items()}\n",
        "train_df[\"Class\"] = train_df[\"Class\"].map(class_mapping)\n",
        "\n",
        "# --- 📌 Encode Gene and Variation (One-Hot Encoding) ---\n",
        "gene_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "variation_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "gene_encoded = gene_encoder.fit_transform(train_df[[\"Gene\"]])\n",
        "variation_encoded = variation_encoder.fit_transform(train_df[[\"Variation\"]])\n",
        "\n",
        "# --- 📌 Apply TF-IDF to Text Data ---\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\", ngram_range=(1, 2))\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df[\"Text\"])\n",
        "\n",
        "# --- 📌 Prepare Data for LSTM ---\n",
        "MAX_NUM_WORDS = 5000\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "EMBEDDING_DIM = 128\n",
        "\n",
        "# Tokenize Text Data\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(train_df[\"Text\"])\n",
        "X_train_sequences = tokenizer.texts_to_sequences(train_df[\"Text\"])\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "# Convert Labels to Categorical for LSTM\n",
        "y_train_lstm = to_categorical(train_df[\"Class\"])\n",
        "\n",
        "# --- 📌 Concatenate Features for XGBoost ---\n",
        "X_ml = hstack((gene_encoded, variation_encoded, X_train_tfidf))\n",
        "y_ml = train_df[\"Class\"]\n",
        "\n",
        "# --- 📌 Split Train & Test (80-20) ---\n",
        "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(\n",
        "    X_ml, y_ml, test_size=0.2, random_state=42, stratify=y_ml\n",
        ")\n",
        "\n",
        "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(\n",
        "    X_train_padded, y_train_lstm, test_size=0.2, random_state=42, stratify=y_train_lstm.argmax(axis=1)\n",
        ")\n",
        "\n",
        "# --- 📌 Train XGBoost Model on Structured Data ---\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    n_estimators=500, max_depth=5, learning_rate=0.05, gamma=0.2,\n",
        "    objective=\"multi:softmax\", num_class=9, eval_metric=\"mlogloss\", use_label_encoder=False\n",
        ")\n",
        "\n",
        "xgb_clf.fit(X_train_ml, y_train_ml)\n",
        "xgb_preds = xgb_clf.predict_proba(X_test_ml)\n",
        "\n",
        "# --- 📌 Train LSTM Model on Text Data ---\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding\n",
        "\n",
        "lstm_model = Sequential([\n",
        "    Embedding(input_dim=MAX_NUM_WORDS, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(9, activation=\"softmax\")  # 9 classes (0-8)\n",
        "])\n",
        "\n",
        "lstm_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "lstm_model.fit(X_train_lstm, y_train_lstm, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Predict on Test Data\n",
        "lstm_preds = lstm_model.predict(X_test_lstm)\n",
        "\n",
        "# --- 📌 Combine XGBoost & LSTM Predictions ---\n",
        "final_preds = (xgb_preds + lstm_preds) / 2  # Averaging Predictions\n",
        "final_labels = np.argmax(final_preds, axis=1)\n",
        "\n",
        "# Convert Predictions Back to Original Labels\n",
        "y_pred_test_original = np.array([inverse_class_mapping[label] for label in final_labels])\n",
        "y_test_ml_original = np.array([inverse_class_mapping[label] for label in y_test_ml])\n",
        "\n",
        "# --- 📌 Evaluate Hybrid Model ---\n",
        "accuracy = accuracy_score(y_test_ml_original, y_pred_test_original)\n",
        "print(f\"Hybrid XGBoost + LSTM Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nHybrid Classification Report:\\n\", classification_report(y_test_ml_original, y_pred_test_original))\n",
        "\n",
        "# --- 📌 Save Predictions ---\n",
        "predictions_df = pd.DataFrame({\"Predicted_Class\": y_pred_test_original})\n",
        "predictions_df.to_csv(\"hybrid_xgboost_lstm_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to hybrid_xgboost_lstm_predictions.csv!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "id": "PqADdpdhk2oo",
        "outputId": "02fef3c8-c18f-4d7e-fa56-f2028d4b00ea"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Shape (after Oversampling): (2840, 6260), Labels: (2840,)\n",
            "Test Shape: (665, 6260), Labels: (665,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:15:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Improved Test Accuracy: 0.6436\n",
            "\n",
            "Improved Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.61      0.59      0.60       114\n",
            "           2       0.71      0.46      0.56        91\n",
            "           3       0.33      0.33      0.33        18\n",
            "           4       0.69      0.69      0.69       137\n",
            "           5       0.37      0.44      0.40        48\n",
            "           6       0.81      0.53      0.64        55\n",
            "           7       0.69      0.86      0.76       191\n",
            "           8       0.00      0.00      0.00         4\n",
            "           9       0.56      0.71      0.62         7\n",
            "\n",
            "    accuracy                           0.64       665\n",
            "   macro avg       0.53      0.51      0.51       665\n",
            "weighted avg       0.65      0.64      0.64       665\n",
            "\n",
            "Predictions saved to improved_xgboost_predictions.csv!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- 📌 Load Train Data Only ---\n",
        "dataset_path = \"/content/drive/MyDrive/msk-redefining-cancer-treatment\"\n",
        "\n",
        "train_variants = pd.read_csv(os.path.join(dataset_path, \"training_variants/training_variants\"))\n",
        "train_text = pd.read_csv(os.path.join(dataset_path, \"training_text/training_text\"), sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1)\n",
        "\n",
        "# --- 📌 Merge Variants and Text Data ---\n",
        "train_df = pd.merge(train_variants, train_text, on=\"ID\")\n",
        "\n",
        "# Drop ID column (not useful for modeling)\n",
        "train_df.drop(columns=[\"ID\"], inplace=True)\n",
        "\n",
        "# Handle Missing Values\n",
        "train_df.fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "# --- 📌 Manually Map Class Labels (Keeping Them as 1 to 9) ---\n",
        "class_labels = sorted(train_df[\"Class\"].unique())  # Get sorted class labels (1-9)\n",
        "class_mapping = {label: idx - 1 for idx, label in enumerate(class_labels, start=1)}  # Map 1-9 to 0-8\n",
        "inverse_class_mapping = {v: k for k, v in class_mapping.items()}  # Reverse Mapping\n",
        "\n",
        "# Apply Mapping to Train Data\n",
        "train_df[\"Class\"] = train_df[\"Class\"].map(class_mapping)  # Shift labels from 1-9 → 0-8\n",
        "\n",
        "# --- 📌 Plot Class Distribution Before Oversampling ---\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.countplot(x=train_df[\"Class\"])\n",
        "plt.title(\"Distribution of Classes in Training Data\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "# --- 📌 Encode Gene and Variation (One-Hot Encoding) ---\n",
        "gene_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "variation_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "gene_encoded = gene_encoder.fit_transform(train_df[[\"Gene\"]])\n",
        "variation_encoded = variation_encoder.fit_transform(train_df[[\"Variation\"]])\n",
        "\n",
        "# --- 📌 Apply TF-IDF to Text Data (With Bigrams) ---\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=3000, stop_words=\"english\", ngram_range=(1, 2))\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df[\"Text\"])\n",
        "\n",
        "# Concatenate Features for ML models\n",
        "X_ml = hstack((gene_encoded, variation_encoded, X_train_tfidf))\n",
        "y_ml = train_df[\"Class\"]\n",
        "\n",
        "# --- 📌 Split Train & Test (80-20) BEFORE Oversampling ---\n",
        "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(\n",
        "    X_ml, y_ml, test_size=0.2, random_state=42, stratify=y_ml\n",
        ")\n",
        "\n",
        "# --- 📌 Apply Smarter Oversampling (Only on Actual Rare Classes: 3, 8, 9) ---\n",
        "oversampler = RandomOverSampler(sampling_strategy={2: 100, 7: 100, 8: 100}, random_state=42)\n",
        "X_train_ml_resampled, y_train_ml_resampled = oversampler.fit_resample(X_train_ml, y_train_ml)\n",
        "\n",
        "# Print Data Shapes\n",
        "print(f\"Train Shape (after Oversampling): {X_train_ml_resampled.shape}, Labels: {y_train_ml_resampled.shape}\")\n",
        "print(f\"Test Shape: {X_test_ml.shape}, Labels: {y_test_ml.shape}\")\n",
        "\n",
        "# --- 📌 Define Improved XGBoost Model ---\n",
        "xgb_clf = xgb.XGBClassifier(**{\n",
        "    'subsample': 0.8,\n",
        "    'n_estimators': 500,  # More estimators for better learning\n",
        "    'max_depth': 5,  # Slightly deeper trees\n",
        "    'learning_rate': 0.05,  # Smaller learning rate for stability\n",
        "    'gamma': 0.2,  # More regularization\n",
        "    'colsample_bytree': 0.9,\n",
        "    'scale_pos_weight': \"balanced\",  # Handle class imbalance\n",
        "    'objective': \"multi:softmax\",\n",
        "    'num_class': 9,  # Ensure XGBoost knows there are 9 classes (0-8)\n",
        "    'eval_metric': \"mlogloss\",\n",
        "    'use_label_encoder': False\n",
        "})\n",
        "\n",
        "# --- 📌 Train XGBoost Model on Train Set ---\n",
        "xgb_clf.fit(X_train_ml_resampled, y_train_ml_resampled)\n",
        "\n",
        "# --- 📌 Predict on True Test Set ---\n",
        "y_pred_test = xgb_clf.predict(X_test_ml)\n",
        "\n",
        "# --- 📌 Convert Predictions Back to Original Class Labels ---\n",
        "y_pred_test_original = np.array([inverse_class_mapping[label] for label in y_pred_test])\n",
        "y_test_ml_original = np.array([inverse_class_mapping[label] for label in y_test_ml])\n",
        "\n",
        "# --- 📌 Evaluate on Test Data ---\n",
        "accuracy = accuracy_score(y_test_ml_original, y_pred_test_original)\n",
        "print(f\"Improved Test Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nImproved Classification Report:\\n\", classification_report(y_test_ml_original, y_pred_test_original))\n",
        "\n",
        "# --- 📌 Save Predictions ---\n",
        "predictions_df = pd.DataFrame({\"Predicted_Class\": y_pred_test_original})\n",
        "predictions_df.to_csv(\"improved_xgboost_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to improved_xgboost_predictions.csv!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtlaz7eU7VkK",
        "outputId": "25732e9c-2cee-4c4a-e434-74ddcf6e6538"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:12:32] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Hyperparameters: {'subsample': 0.7, 'reg_lambda': 1, 'reg_alpha': 0.1, 'n_estimators': 700, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.01, 'gamma': 0, 'colsample_bytree': 0.6}\n",
            "Best Validation Accuracy: 0.6940150008222993\n",
            "Tuned Model Test Accuracy: 0.6301\n",
            "\n",
            "Tuned Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.59      0.58      0.59       114\n",
            "           2       0.67      0.46      0.55        91\n",
            "           3       0.38      0.33      0.35        18\n",
            "           4       0.67      0.66      0.66       137\n",
            "           5       0.33      0.31      0.32        48\n",
            "           6       0.86      0.55      0.67        55\n",
            "           7       0.66      0.86      0.75       191\n",
            "           8       0.00      0.00      0.00         4\n",
            "           9       0.45      0.71      0.56         7\n",
            "\n",
            "    accuracy                           0.63       665\n",
            "   macro avg       0.51      0.50      0.49       665\n",
            "weighted avg       0.63      0.63      0.62       665\n",
            "\n",
            "Predictions saved to random_tuned_xgboost_predictions.csv!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "\n",
        "# --- 📌 Define Parameter Grid ---\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 300, 500, 700],  # Number of trees\n",
        "    'max_depth': [3, 5, 7, 9],  # Depth of trees\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # Step size\n",
        "    'gamma': [0, 0.1, 0.2, 0.3],  # Regularization parameter\n",
        "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9],  # Feature sampling\n",
        "    'subsample': [0.7, 0.8, 0.9, 1.0],  # Row sampling\n",
        "    'min_child_weight': [1, 3, 5],  # Minimum weight for new leaves\n",
        "    'reg_lambda': [0.01, 0.1, 1],  # L2 Regularization\n",
        "    'reg_alpha': [0, 0.01, 0.1]  # L1 Regularization\n",
        "}\n",
        "\n",
        "# --- 📌 Initialize XGBoost Classifier ---\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective=\"multi:softmax\",\n",
        "    num_class=9,  # Ensuring it knows there are 9 classes (0-8)\n",
        "    eval_metric=\"mlogloss\",\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "# --- 📌 Randomized Search (Faster Hyperparameter Tuning) ---\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_clf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,  # Number of random combinations to test (much faster than GridSearch)\n",
        "    scoring=\"accuracy\",  # Optimize for accuracy\n",
        "    cv=3,  # 3-fold Cross-validation (faster than 5-fold)\n",
        "    verbose=2,  # Show training progress\n",
        "    n_jobs=-1,  # Use all CPU cores\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# --- 📌 Run Hyperparameter Tuning ---\n",
        "random_search.fit(X_train_ml_resampled, y_train_ml_resampled)\n",
        "\n",
        "# --- 📌 Print Best Hyperparameters ---\n",
        "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
        "print(\"Best Validation Accuracy:\", random_search.best_score_)\n",
        "\n",
        "# --- 📌 Train Final Model Using Best Hyperparameters ---\n",
        "best_xgb = random_search.best_estimator_\n",
        "\n",
        "# --- 📌 Predict on Test Data ---\n",
        "y_pred_test = best_xgb.predict(X_test_ml)\n",
        "\n",
        "# --- 📌 Convert Predictions Back to Original Class Labels ---\n",
        "y_pred_test_original = np.array([inverse_class_mapping[label] for label in y_pred_test])\n",
        "y_test_ml_original = np.array([inverse_class_mapping[label] for label in y_test_ml])\n",
        "\n",
        "# --- 📌 Evaluate on Test Data ---\n",
        "accuracy = accuracy_score(y_test_ml_original, y_pred_test_original)\n",
        "print(f\"Tuned Model Test Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nTuned Classification Report:\\n\", classification_report(y_test_ml_original, y_pred_test_original))\n",
        "\n",
        "# --- 📌 Save Predictions ---\n",
        "predictions_df = pd.DataFrame({\"Predicted_Class\": y_pred_test_original})\n",
        "predictions_df.to_csv(\"random_tuned_xgboost_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to random_tuned_xgboost_predictions.csv!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3Wk7xUmc6RD",
        "outputId": "9d41dcd4-d65a-4797-cc63-42de91712679"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Shape (after SMOTE): (6858, 8260), Labels: (6858,)\n",
            "Test Shape: (665, 8260), Labels: (665,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:28:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Test Accuracy: 0.6421\n",
            "\n",
            "Classification Report on Test Data:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.62      0.62       114\n",
            "           1       0.59      0.56      0.57        91\n",
            "           2       0.32      0.39      0.35        18\n",
            "           3       0.70      0.63      0.66       137\n",
            "           4       0.34      0.44      0.39        48\n",
            "           5       0.80      0.58      0.67        55\n",
            "           6       0.74      0.81      0.77       191\n",
            "           7       0.00      0.00      0.00         4\n",
            "           8       0.62      0.71      0.67         7\n",
            "\n",
            "    accuracy                           0.64       665\n",
            "   macro avg       0.53      0.53      0.52       665\n",
            "weighted avg       0.65      0.64      0.64       665\n",
            "\n",
            "Predictions saved to xgboost_predictions.csv!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os\n",
        "\n",
        "# --- 📌 Load Train Data Only ---\n",
        "dataset_path = \"/content/drive/MyDrive/msk-redefining-cancer-treatment\"\n",
        "\n",
        "train_variants = pd.read_csv(os.path.join(dataset_path, \"training_variants/training_variants\"))\n",
        "train_text = pd.read_csv(os.path.join(dataset_path, \"training_text/training_text\"), sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1)\n",
        "\n",
        "# --- 📌 Merge Variants and Text Data ---\n",
        "train_df = pd.merge(train_variants, train_text, on=\"ID\")\n",
        "\n",
        "# Drop ID column (not useful for modeling)\n",
        "train_df.drop(columns=[\"ID\"], inplace=True)\n",
        "\n",
        "# Handle Missing Values\n",
        "train_df.fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "# --- 📌 Encode Class Labels ---\n",
        "label_encoder = LabelEncoder()\n",
        "train_df[\"Class\"] = label_encoder.fit_transform(train_df[\"Class\"])  # Convert to integers\n",
        "\n",
        "# --- 📌 Encode Gene and Variation (One-Hot Encoding) ---\n",
        "gene_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "variation_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "gene_encoded = gene_encoder.fit_transform(train_df[[\"Gene\"]])\n",
        "variation_encoded = variation_encoder.fit_transform(train_df[[\"Variation\"]])\n",
        "\n",
        "# --- 📌 Apply TF-IDF to Text Data ---\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df[\"Text\"])\n",
        "\n",
        "# Concatenate Features for ML models\n",
        "X_ml = hstack((gene_encoded, variation_encoded, X_train_tfidf))\n",
        "y_ml = train_df[\"Class\"]\n",
        "\n",
        "# --- 📌 Split Train & Test (80-20) BEFORE Applying SMOTE ---\n",
        "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(\n",
        "    X_ml, y_ml, test_size=0.2, random_state=42, stratify=y_ml\n",
        ")\n",
        "\n",
        "# --- 📌 Apply SMOTE on Training Data Only ---\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_ml_resampled, y_train_ml_resampled = smote.fit_resample(X_train_ml, y_train_ml)\n",
        "\n",
        "# Print Data Shapes\n",
        "print(f\"Train Shape (after SMOTE): {X_train_ml_resampled.shape}, Labels: {y_train_ml_resampled.shape}\")\n",
        "print(f\"Test Shape: {X_test_ml.shape}, Labels: {y_test_ml.shape}\")\n",
        "\n",
        "# --- 📌 Define XGBoost Model ---\n",
        "xgb_clf = xgb.XGBClassifier(**{\n",
        "    'subsample': 0.7, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.8,\n",
        "    'objective': \"multi:softmax\", 'num_class': 9, 'eval_metric': \"mlogloss\", 'use_label_encoder': False\n",
        "})\n",
        "\n",
        "# --- 📌 Train XGBoost Model on Train Set ---\n",
        "xgb_clf.fit(X_train_ml_resampled, y_train_ml_resampled)\n",
        "\n",
        "# --- 📌 Predict on True Test Set ---\n",
        "y_pred_test = xgb_clf.predict(X_test_ml)\n",
        "\n",
        "# --- 📌 Evaluate on Test Data ---\n",
        "accuracy = accuracy_score(y_test_ml, y_pred_test)\n",
        "print(f\"Final Test Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report on Test Data:\\n\", classification_report(y_test_ml, y_pred_test))\n",
        "\n",
        "# --- 📌 Save Predictions ---\n",
        "y_pred_test_labels = label_encoder.inverse_transform(y_pred_test)\n",
        "predictions_df = pd.DataFrame({\"Predicted_Class\": y_pred_test_labels})\n",
        "predictions_df.to_csv(\"xgboost_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to xgboost_predictions.csv!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-mTAnCqvZp4",
        "outputId": "aa4bc1a3-c104-4353-cd86-64ffa9176181"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Shape (after SMOTE): (6858, 8260), Labels: (6858,)\n",
            "Test Shape: (665, 8260), Labels: (665,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:26:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os\n",
        "\n",
        "# --- 📌 Load Train Data Only ---\n",
        "dataset_path = \"/content/drive/MyDrive/msk-redefining-cancer-treatment\"\n",
        "\n",
        "train_variants = pd.read_csv(os.path.join(dataset_path, \"training_variants/training_variants\"))\n",
        "train_text = pd.read_csv(os.path.join(dataset_path, \"training_text/training_text\"), sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1)\n",
        "\n",
        "# --- 📌 Merge Variants and Text Data ---\n",
        "train_df = pd.merge(train_variants, train_text, on=\"ID\")\n",
        "\n",
        "# Drop ID column (not useful for modeling)\n",
        "train_df.drop(columns=[\"ID\"], inplace=True)\n",
        "\n",
        "# Handle Missing Values\n",
        "train_df.fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "# --- 📌 Encode Class Labels ---\n",
        "label_encoder = LabelEncoder()\n",
        "train_df[\"Class\"] = label_encoder.fit_transform(train_df[\"Class\"])  # Convert to integers\n",
        "\n",
        "# --- 📌 Encode Gene and Variation (One-Hot Encoding) ---\n",
        "gene_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "variation_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "gene_encoded = gene_encoder.fit_transform(train_df[[\"Gene\"]])\n",
        "variation_encoded = variation_encoder.fit_transform(train_df[[\"Variation\"]])\n",
        "\n",
        "# --- 📌 Apply TF-IDF to Text Data ---\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df[\"Text\"])\n",
        "\n",
        "# Concatenate Features for ML models\n",
        "X_ml = hstack((gene_encoded, variation_encoded, X_train_tfidf))\n",
        "y_ml = train_df[\"Class\"]\n",
        "\n",
        "# --- 📌 Split Train & Test (80-20) BEFORE Applying SMOTE ---\n",
        "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(\n",
        "    X_ml, y_ml, test_size=0.2, random_state=42, stratify=y_ml\n",
        ")\n",
        "\n",
        "# --- 📌 Apply SMOTE on Training Data Only ---\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_ml_resampled, y_train_ml_resampled = smote.fit_resample(X_train_ml, y_train_ml)\n",
        "\n",
        "# Print Data Shapes\n",
        "print(f\"Train Shape (after SMOTE): {X_train_ml_resampled.shape}, Labels: {y_train_ml_resampled.shape}\")\n",
        "print(f\"Test Shape: {X_test_ml.shape}, Labels: {y_test_ml.shape}\")\n",
        "\n",
        "# --- 📌 Define Base Models for Stacking ---\n",
        "xgb_clf = xgb.XGBClassifier(**{\n",
        "    'subsample': 0.7, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.8,\n",
        "    'objective': \"multi:softmax\", 'num_class': 9, 'eval_metric': \"mlogloss\", 'use_label_encoder': False\n",
        "})\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_estimators=300, max_depth=5, random_state=42)\n",
        "extra_trees_clf = ExtraTreesClassifier(n_estimators=200, max_depth=5, random_state=42)\n",
        "\n",
        "# --- 📌 Create Stacking Model ---\n",
        "stacked_model = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_clf),\n",
        "        ('rf', rf_clf),\n",
        "        ('extra', extra_trees_clf)\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(max_iter=500, solver='lbfgs', multi_class='multinomial')\n",
        ")\n",
        "\n",
        "# --- 📌 Train Stacking Model on Train Set ---\n",
        "stacked_model.fit(X_train_ml_resampled, y_train_ml_resampled)\n",
        "\n",
        "# --- 📌 Predict on True Test Set ---\n",
        "y_pred_test = stacked_model.predict(X_test_ml)\n",
        "\n",
        "# --- 📌 Evaluate on Test Data ---\n",
        "accuracy = accuracy_score(y_test_ml, y_pred_test)\n",
        "print(f\"Final Test Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report on Test Data:\\n\", classification_report(y_test_ml, y_pred_test))\n",
        "\n",
        "# --- 📌 Save Predictions ---\n",
        "y_pred_test_labels = label_encoder.inverse_transform(y_pred_test)\n",
        "predictions_df = pd.DataFrame({\"Predicted_Class\": y_pred_test_labels})\n",
        "predictions_df.to_csv(\"stacked_model_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to stacked_model_predictions.csv!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yQwtKB9PCXdN",
        "outputId": "bf9528ac-2d9b-44dd-fce2-ccdb3c5a2ef8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Shape (after SMOTE): (6858, 8260), Labels: (6858,)\n",
            "Test Shape (Final Test Set): (665, 8260), Labels: (665,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [15:21:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [15:34:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [15:47:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:00:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:12:54] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:25:55] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Test Accuracy: 0.6496\n",
            "\n",
            "Classification Report on Test Data:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.60      0.60       114\n",
            "           1       0.59      0.56      0.57        91\n",
            "           2       0.39      0.39      0.39        18\n",
            "           3       0.69      0.64      0.67       137\n",
            "           4       0.35      0.44      0.39        48\n",
            "           5       0.82      0.60      0.69        55\n",
            "           6       0.75      0.83      0.79       191\n",
            "           7       0.00      0.00      0.00         4\n",
            "           8       0.83      0.71      0.77         7\n",
            "\n",
            "    accuracy                           0.65       665\n",
            "   macro avg       0.56      0.53      0.54       665\n",
            "weighted avg       0.65      0.65      0.65       665\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Length of values (665) does not match length of index (5668)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b8c121c5d84a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m# --- 📌 Save Predictions ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0my_pred_test_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Predicted_Class\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred_test_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stacked_model_predictions.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4311\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4522\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4523\u001b[0m         \"\"\"\n\u001b[0;32m-> 4524\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4526\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5266\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5267\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5268\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \"\"\"\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    574\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (665) does not match length of index (5668)"
          ]
        }
      ],
      "source": [
        " import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os\n",
        "\n",
        "# --- 📌 Load Data ---\n",
        "dataset_path = \"/content/drive/MyDrive/msk-redefining-cancer-treatment\"\n",
        "\n",
        "train_variants = pd.read_csv(os.path.join(dataset_path, \"training_variants/training_variants\"))\n",
        "test_variants = pd.read_csv(os.path.join(dataset_path, \"test_variants/test_variants\"))\n",
        "\n",
        "train_text = pd.read_csv(os.path.join(dataset_path, \"training_text/training_text\"), sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1)\n",
        "test_text = pd.read_csv(os.path.join(dataset_path, \"test_text/test_text\"), sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1)\n",
        "\n",
        "# --- 📌 Merge Variants and Text Data ---\n",
        "train_df = pd.merge(train_variants, train_text, on=\"ID\")\n",
        "test_df = pd.merge(test_variants, test_text, on=\"ID\")\n",
        "\n",
        "# Drop ID column (not useful for modeling)\n",
        "train_df.drop(columns=[\"ID\"], inplace=True)\n",
        "test_df.drop(columns=[\"ID\"], inplace=True)\n",
        "\n",
        "# Handle Missing Values\n",
        "train_df.fillna(\"Unknown\", inplace=True)\n",
        "test_df.fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "# --- 📌 Encode Class Labels ---\n",
        "label_encoder = LabelEncoder()\n",
        "train_df[\"Class\"] = label_encoder.fit_transform(train_df[\"Class\"])  # Convert to integers\n",
        "\n",
        "# --- 📌 Encode Gene and Variation (One-Hot Encoding) ---\n",
        "gene_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "variation_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "gene_encoded = gene_encoder.fit_transform(train_df[[\"Gene\"]])\n",
        "variation_encoded = variation_encoder.fit_transform(train_df[[\"Variation\"]])\n",
        "\n",
        "# Encode Test Data for ML Model\n",
        "gene_encoded_test = gene_encoder.transform(test_df[[\"Gene\"]])\n",
        "variation_encoded_test = variation_encoder.transform(test_df[[\"Variation\"]])\n",
        "\n",
        "# --- 📌 Apply TF-IDF to Text Data ---\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df[\"Text\"])\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_df[\"Text\"])\n",
        "\n",
        "# Concatenate Features for ML models\n",
        "X_ml = hstack((gene_encoded, variation_encoded, X_train_tfidf))\n",
        "X_test_ml = hstack((gene_encoded_test, variation_encoded_test, X_test_tfidf))\n",
        "y_ml = train_df[\"Class\"]\n",
        "\n",
        "# --- 📌 Split Train & Test (80-20) BEFORE Applying SMOTE ---\n",
        "X_train_ml, X_test_ml_final, y_train_ml, y_test_ml_final = train_test_split(\n",
        "    X_ml, y_ml, test_size=0.2, random_state=42, stratify=y_ml\n",
        ")\n",
        "\n",
        "# --- 📌 Apply SMOTE on Training Data Only ---\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_ml_resampled, y_train_ml_resampled = smote.fit_resample(X_train_ml, y_train_ml)\n",
        "\n",
        "# Print Data Shapes\n",
        "print(f\"Train Shape (after SMOTE): {X_train_ml_resampled.shape}, Labels: {y_train_ml_resampled.shape}\")\n",
        "print(f\"Test Shape (Final Test Set): {X_test_ml_final.shape}, Labels: {y_test_ml_final.shape}\")\n",
        "\n",
        "# --- 📌 Define Base Models for Stacking ---\n",
        "xgb_clf = xgb.XGBClassifier(**{\n",
        "    'subsample': 0.7, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.8,\n",
        "    'objective': \"multi:softmax\", 'num_class': 9, 'eval_metric': \"mlogloss\", 'use_label_encoder': False\n",
        "})\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_estimators=300, max_depth=5, random_state=42)\n",
        "extra_trees_clf = ExtraTreesClassifier(n_estimators=200, max_depth=5, random_state=42)\n",
        "\n",
        "# --- 📌 Create Stacking Model ---\n",
        "stacked_model = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_clf),\n",
        "        ('rf', rf_clf),\n",
        "        ('extra', extra_trees_clf)\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(max_iter=500, solver='lbfgs', multi_class='multinomial')\n",
        ")\n",
        "\n",
        "# --- 📌 Train Stacking Model on Train Set ---\n",
        "stacked_model.fit(X_train_ml_resampled, y_train_ml_resampled)\n",
        "\n",
        "# --- 📌 Predict on True Test Set ---\n",
        "y_pred_test = stacked_model.predict(X_test_ml_final)\n",
        "\n",
        "# --- 📌 Evaluate on Test Data ---\n",
        "accuracy = accuracy_score(y_test_ml_final, y_pred_test)\n",
        "print(f\"Final Test Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report on Test Data:\\n\", classification_report(y_test_ml_final, y_pred_test))\n",
        "\n",
        "# --- 📌 Save Predictions ---\n",
        "y_pred_test_labels = label_encoder.inverse_transform(y_pred_test)\n",
        "test_df[\"Predicted_Class\"] = y_pred_test_labels\n",
        "test_df.to_csv(\"stacked_model_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to stacked_model_predictions.csv!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HttlTAohMibF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import os\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/msk-redefining-cancer-treatment\"\n",
        "\n",
        "train_variants = pd.read_csv(os.path.join(dataset_path, \"training_variants/training_variants\"))\n",
        "test_variants = pd.read_csv(os.path.join(dataset_path, \"test_variants/test_variants\"))\n",
        "\n",
        "train_text = pd.read_csv(os.path.join(dataset_path, \"training_text/training_text\"), sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1)\n",
        "test_text = pd.read_csv(os.path.join(dataset_path, \"test_text/test_text\"), sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bty_g124t-Zi",
        "outputId": "2f4aae9c-009a-43a6-9a29-ae4ede77a3d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Preprocessing Completed!\n",
            "ML Training Data Shape: (8577, 8260), Labels: (8577,)\n",
            "DL Training Data Shape: (2656, 4), Validation Data Shape: (665, 4)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Merge Variants and Text Data\n",
        "train_df = pd.merge(train_variants, train_text, on=\"ID\")\n",
        "test_df = pd.merge(test_variants, test_text, on=\"ID\")\n",
        "\n",
        "# Drop ID column (not useful for modeling)\n",
        "train_df.drop(columns=[\"ID\"], inplace=True)\n",
        "test_df.drop(columns=[\"ID\"], inplace=True)\n",
        "\n",
        "# Handle Missing Values\n",
        "train_df.fillna(\"Unknown\", inplace=True)\n",
        "test_df.fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "# Encode Class Labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_df[\"Class\"] = label_encoder.fit_transform(train_df[\"Class\"])  # Convert classes to integers\n",
        "y_train = to_categorical(train_df[\"Class\"])  # Convert to one-hot encoding for DL models\n",
        "\n",
        "# Encode Gene and Variation (One-Hot Encoding)\n",
        "gene_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "variation_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "gene_encoded = gene_encoder.fit_transform(train_df[[\"Gene\"]])\n",
        "variation_encoded = variation_encoder.fit_transform(train_df[[\"Variation\"]])\n",
        "\n",
        "# Encode Test Data for ML Model\n",
        "gene_encoded_test = gene_encoder.transform(test_df[[\"Gene\"]])\n",
        "variation_encoded_test = variation_encoder.transform(test_df[[\"Variation\"]])\n",
        "\n",
        "# Apply TF-IDF to Text Data (for ML models)\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df[\"Text\"])\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_df[\"Text\"])\n",
        "\n",
        "# Concatenate Features for ML models\n",
        "X_train_ml = hstack((gene_encoded, variation_encoded, X_train_tfidf))\n",
        "X_test_ml = hstack((gene_encoded_test, variation_encoded_test, X_test_tfidf))\n",
        "\n",
        "# Apply SMOTE to Handle Class Imbalance (for ML model)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_ml_resampled, y_train_ml_resampled = smote.fit_resample(X_train_ml, train_df[\"Class\"])\n",
        "\n",
        "# Split Training Data for Deep Learning Model\n",
        "X_train, X_val, y_train_dl, y_val_dl = train_test_split(train_df, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Data Preprocessing Completed!\")\n",
        "print(f\"ML Training Data Shape: {X_train_ml_resampled.shape}, Labels: {y_train_ml_resampled.shape}\")\n",
        "print(f\"DL Training Data Shape: {X_train.shape}, Validation Data Shape: {X_val.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFnw1PddW0SS",
        "outputId": "369aefe6-ef1b-4e2a-eb1a-10aae97bdea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Data Shape: (6861, 8260), Validation Data Shape: (1716, 8260)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the resampled dataset into Training (80%) and Validation (20%)\n",
        "X_train_ml_train, X_train_ml_val, y_train_ml_train, y_train_ml_val = train_test_split(\n",
        "    X_train_ml_resampled, y_train_ml_resampled, test_size=0.2, random_state=42, stratify=y_train_ml_resampled\n",
        ")\n",
        "\n",
        "print(f\"Training Data Shape: {X_train_ml_train.shape}, Validation Data Shape: {X_train_ml_val.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DazMQfjcVTRw",
        "outputId": "dcdf5f86-dd0b-49ba-9abb-1413d7986bf2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [23:53:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [00:09:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [00:26:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [00:42:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [00:58:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:14:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stacked Model Validation Accuracy: 0.9435\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.86      0.89       191\n",
            "           1       1.00      0.90      0.95       190\n",
            "           2       0.93      0.98      0.95       191\n",
            "           3       0.90      0.93      0.92       191\n",
            "           4       0.91      0.92      0.92       191\n",
            "           5       0.94      0.98      0.96       190\n",
            "           6       0.89      0.91      0.90       191\n",
            "           7       1.00      1.00      1.00       190\n",
            "           8       1.00      1.00      1.00       191\n",
            "\n",
            "    accuracy                           0.94      1716\n",
            "   macro avg       0.94      0.94      0.94      1716\n",
            "weighted avg       0.94      0.94      0.94      1716\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingClassifier, VotingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Define Base Models\n",
        "xgb_clf = xgb.XGBClassifier(**{\n",
        "    'subsample': 0.7, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.8,\n",
        "    'objective': \"multi:softmax\", 'num_class': 9, 'eval_metric': \"mlogloss\", 'use_label_encoder': False\n",
        "})\n",
        "\n",
        "#lgb_clf = lgb.LGBMClassifier(n_estimators=300, learning_rate=0.1, max_depth=4, random_state=42)\n",
        "rf_clf = RandomForestClassifier(n_estimators=300, max_depth=5, random_state=42)\n",
        "extra_trees_clf = ExtraTreesClassifier(n_estimators=200, max_depth=5, random_state=42)\n",
        "\n",
        "# Create Stacking Model (Logistic Regression as meta-learner)\n",
        "stacked_model = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_clf),\n",
        "        ('rf', rf_clf),\n",
        "        ('extra', extra_trees_clf),\n",
        "        #('lgb', lgb_clf)\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(max_iter=500, solver='lbfgs', multi_class='multinomial')\n",
        ")\n",
        "\n",
        "# Train Stacking Model\n",
        "stacked_model.fit(X_train_ml_resampled, y_train_ml_resampled)\n",
        "\n",
        "# Predict on Validation Data\n",
        "y_pred_stacked = stacked_model.predict(X_train_ml_val)\n",
        "\n",
        "# Evaluate Model Performance\n",
        "accuracy = accuracy_score(y_train_ml_val, y_pred_stacked)\n",
        "print(f\"Stacked Model Validation Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_train_ml_val, y_pred_stacked))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fUkqWbgW-Xc",
        "outputId": "6646011b-50fb-4d56-cbe1-3f404cfa920c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:05:41] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Voting Model Validation Accuracy: 0.9359\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.80      0.85       191\n",
            "           1       0.98      0.93      0.95       190\n",
            "           2       0.90      0.98      0.94       191\n",
            "           3       0.92      0.91      0.91       191\n",
            "           4       0.84      0.94      0.88       191\n",
            "           5       0.95      0.97      0.96       190\n",
            "           6       0.95      0.90      0.92       191\n",
            "           7       1.00      1.00      1.00       190\n",
            "           8       1.00      1.00      1.00       191\n",
            "\n",
            "    accuracy                           0.94      1716\n",
            "   macro avg       0.94      0.94      0.94      1716\n",
            "weighted avg       0.94      0.94      0.94      1716\n",
            "\n"
          ]
        }
      ],
      "source": [
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_clf),\n",
        "        ('rf', rf_clf),\n",
        "        ('extra', extra_trees_clf),\n",
        "        #('lgb', lgb_clf)\n",
        "    ],\n",
        "    voting='soft'  # Soft Voting: Uses predicted probabilities for better performance\n",
        ")\n",
        "\n",
        "# Train Voting Model\n",
        "voting_clf.fit(X_train_ml_resampled, y_train_ml_resampled)\n",
        "\n",
        "# Predict on Validation Data\n",
        "y_pred_voting = voting_clf.predict(X_train_ml_val)\n",
        "\n",
        "# Evaluate Model Performance\n",
        "accuracy = accuracy_score(y_train_ml_val, y_pred_voting)\n",
        "print(f\"Voting Model Validation Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_train_ml_val, y_pred_voting))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbO9ITkCt-WJ",
        "outputId": "417799cb-8e3a-425a-cf20-8dde14551e7a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [18:02:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8712\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.74      0.76       201\n",
            "           1       0.83      0.81      0.82       186\n",
            "           2       0.97      0.97      0.97       193\n",
            "           3       0.79      0.78      0.79       194\n",
            "           4       0.82      0.86      0.84       177\n",
            "           5       0.98      0.91      0.94       206\n",
            "           6       0.70      0.79      0.74       194\n",
            "           7       1.00      1.00      1.00       182\n",
            "           8       1.00      0.99      0.99       183\n",
            "\n",
            "    accuracy                           0.87      1716\n",
            "   macro avg       0.88      0.87      0.87      1716\n",
            "weighted avg       0.87      0.87      0.87      1716\n",
            "\n",
            "Predictions saved to xgboost_predictions.csv!\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the resampled data for training and validation\n",
        "X_train_ml_train, X_train_ml_val, y_train_ml_train, y_train_ml_val = train_test_split(\n",
        "    X_train_ml_resampled, y_train_ml_resampled, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Define XGBoost Classifier\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective=\"multi:softmax\", num_class=9, eval_metric=\"mlogloss\", use_label_encoder=False\n",
        ")\n",
        "\n",
        "# Train Model\n",
        "xgb_model.fit(X_train_ml_train, y_train_ml_train)\n",
        "\n",
        "# Predict on Validation Set\n",
        "y_pred_val = xgb_model.predict(X_train_ml_val)\n",
        "\n",
        "# Evaluate Model Performance\n",
        "accuracy = accuracy_score(y_train_ml_val, y_pred_val)\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_train_ml_val, y_pred_val))\n",
        "\n",
        "# Predict on Test Set\n",
        "y_pred_test = xgb_model.predict(X_test_ml)\n",
        "\n",
        "# Convert Predictions Back to Original Labels\n",
        "y_pred_test_labels = label_encoder.inverse_transform(y_pred_test)\n",
        "\n",
        "# Save Predictions\n",
        "test_df[\"Predicted_Class\"] = y_pred_test_labels\n",
        "test_df.to_csv(\"xgboost_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to xgboost_predictions.csv!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "OaP500RiIkGw",
        "outputId": "474d5d58-22f1-4356-cb49-5b84a542dc51"
      },
      "outputs": [
        {
          "ename": "NotFittedError",
          "evalue": "need to call fit or load_model beforehand",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-18979c5b4657>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predict on Training Set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_ml_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Calculate Training Accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_ml_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1631\u001b[0m     ) -> ArrayLike:\n\u001b[1;32m   1632\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m             class_probs = super().predict(\n\u001b[0m\u001b[1;32m   1634\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m                 \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_use_inplace_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1248\u001b[0;31m                     predts = self.get_booster().inplace_predict(\n\u001b[0m\u001b[1;32m   1249\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                         \u001b[0miteration_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"need to call fit or load_model beforehand\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"
          ]
        }
      ],
      "source": [
        "# Predict on Training Set\n",
        "y_pred_train = xgb_model.predict(X_train_ml_train)\n",
        "\n",
        "# Calculate Training Accuracy\n",
        "train_accuracy = accuracy_score(y_train_ml_train, y_pred_train)\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJe0KjIYkG-Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v92Qs9k7Il4M",
        "outputId": "9d774039-13b9-4210-afab-3ce9263a6c23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n"
          ]
        }
      ],
      "source": [
        "pip install xgboost scikit-learn imbalanced-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bV5TxTrMuqu",
        "outputId": "666b2537-9890-4404-9bcd-7b188b788595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:19:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Hyperparameters: {'subsample': 0.7, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.8}\n",
            "Best Validation Accuracy: 0.8174\n",
            "Validation Accuracy (Tuned Model): 0.9429\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.83      0.87       201\n",
            "           1       0.97      0.94      0.96       186\n",
            "           2       0.96      0.99      0.98       193\n",
            "           3       0.91      0.92      0.92       194\n",
            "           4       0.82      0.95      0.88       177\n",
            "           5       0.98      0.97      0.97       206\n",
            "           6       0.93      0.90      0.91       194\n",
            "           7       1.00      1.00      1.00       182\n",
            "           8       1.00      1.00      1.00       183\n",
            "\n",
            "    accuracy                           0.94      1716\n",
            "   macro avg       0.94      0.94      0.94      1716\n",
            "weighted avg       0.94      0.94      0.94      1716\n",
            "\n",
            "Optimized XGBoost predictions saved to xgboost_tuned_predictions.csv!\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Define XGBoost model\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective=\"multi:softmax\", num_class=9, eval_metric=\"mlogloss\", use_label_encoder=False\n",
        ")\n",
        "\n",
        "# Reduce the hyperparameter search space for speed\n",
        "param_dist = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [3, 5],\n",
        "    \"learning_rate\": [0.05, 0.1],\n",
        "    \"subsample\": [0.7, 0.8],\n",
        "    \"colsample_bytree\": [0.7, 0.8],\n",
        "    \"gamma\": [0, 0.1]\n",
        "}\n",
        "\n",
        "# Use RandomizedSearchCV for faster tuning\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_model, param_distributions=param_dist,\n",
        "    n_iter=2, scoring=\"accuracy\", cv=3, verbose=1, n_jobs=-1, random_state=42\n",
        ")\n",
        "\n",
        "# Train with reduced search space\n",
        "random_search.fit(X_train_ml_resampled, y_train_ml_resampled)\n",
        "\n",
        "# Get the best model\n",
        "best_xgb = random_search.best_estimator_\n",
        "\n",
        "# Print best parameters and accuracy\n",
        "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
        "print(f\"Best Validation Accuracy: {random_search.best_score_:.4f}\")\n",
        "\n",
        "# Evaluate on validation set\n",
        "y_pred_val = best_xgb.predict(X_train_ml_val)\n",
        "accuracy = accuracy_score(y_train_ml_val, y_pred_val)\n",
        "print(f\"Validation Accuracy (Tuned Model): {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_train_ml_val, y_pred_val))\n",
        "\n",
        "# Predict on test data\n",
        "y_pred_test = best_xgb.predict(X_test_ml)\n",
        "\n",
        "# Convert predictions back to original labels\n",
        "y_pred_test_labels = label_encoder.inverse_transform(y_pred_test)\n",
        "\n",
        "# Save predictions\n",
        "test_df[\"Predicted_Class\"] = y_pred_test_labels\n",
        "test_df.to_csv(\"xgboost_tuned_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Optimized XGBoost predictions saved to xgboost_tuned_predictions.csv!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5kSYD5St-Q9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wcu4sT95t-ON"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wcd022Sht-Lt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgKVLPVlt-JE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XgoqZ0Jt-GQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4hTHORNt-DU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSxkFseyt9_7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-MxoGx7t973"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHZpmiest9rF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW0Xr-Hc7L0A",
        "outputId": "cd8d2309-78a3-45ad-afdb-28b7eb2d67d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting autoviz\n",
            "  Downloading autoviz-0.1.905-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.11/dist-packages (from autoviz) (2.0.1)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (from autoviz) (1.9.4)\n",
            "Collecting emoji (from autoviz)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting pyamg (from autoviz)\n",
            "  Downloading pyamg-5.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from autoviz) (1.6.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from autoviz) (0.14.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from autoviz) (3.9.1)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (from autoviz) (0.19.0)\n",
            "Collecting xgboost<1.7,>=0.82 (from autoviz)\n",
            "  Downloading xgboost-1.6.2-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: fsspec>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from autoviz) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from autoviz) (4.12.2)\n",
            "Collecting pandas-dq>=1.29 (from autoviz)\n",
            "  Downloading pandas_dq-1.29-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from autoviz) (1.26.4)\n",
            "Collecting hvplot>=0.9.2 (from autoviz)\n",
            "  Downloading hvplot-0.11.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: holoviews>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from autoviz) (1.20.0)\n",
            "Requirement already satisfied: panel>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from autoviz) (1.6.0)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.11/dist-packages (from autoviz) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>3.7.4 in /usr/local/lib/python3.11/dist-packages (from autoviz) (3.10.0)\n",
            "Requirement already satisfied: seaborn>0.12.2 in /usr/local/lib/python3.11/dist-packages (from autoviz) (0.13.2)\n",
            "Requirement already satisfied: bokeh>=3.1 in /usr/local/lib/python3.11/dist-packages (from holoviews>=1.16.0->autoviz) (3.6.3)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.11/dist-packages (from holoviews>=1.16.0->autoviz) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from holoviews>=1.16.0->autoviz) (24.2)\n",
            "Requirement already satisfied: param<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from holoviews>=1.16.0->autoviz) (2.2.0)\n",
            "Requirement already satisfied: pyviz-comms>=2.1 in /usr/local/lib/python3.11/dist-packages (from holoviews>=1.16.0->autoviz) (3.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.7.4->autoviz) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.7.4->autoviz) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.7.4->autoviz) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.7.4->autoviz) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.7.4->autoviz) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.7.4->autoviz) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.7.4->autoviz) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->autoviz) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->autoviz) (2025.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from panel>=1.4.0->autoviz) (6.2.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.11/dist-packages (from panel>=1.4.0->autoviz) (2.0.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from panel>=1.4.0->autoviz) (3.7)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.11/dist-packages (from panel>=1.4.0->autoviz) (3.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.11/dist-packages (from panel>=1.4.0->autoviz) (0.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from panel>=1.4.0->autoviz) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from panel>=1.4.0->autoviz) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->autoviz) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->autoviz) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->autoviz) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->autoviz) (8.1.8)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->autoviz) (2024.11.6)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->autoviz) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->holoviews>=1.16.0->autoviz) (3.1.5)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->holoviews>=1.16.0->autoviz) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->holoviews>=1.16.0->autoviz) (6.4.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->holoviews>=1.16.0->autoviz) (2025.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>3.7.4->autoviz) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->panel>=1.4.0->autoviz) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py->panel>=1.4.0->autoviz) (1.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py->panel>=1.4.0->autoviz) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->panel>=1.4.0->autoviz) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->panel>=1.4.0->autoviz) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->panel>=1.4.0->autoviz) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->panel>=1.4.0->autoviz) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=2.9->bokeh>=3.1->holoviews>=1.16.0->autoviz) (3.0.2)\n",
            "Downloading autoviz-0.1.905-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.5/67.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hvplot-0.11.2-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.9/161.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas_dq-1.29-py3-none-any.whl (29 kB)\n",
            "Downloading xgboost-1.6.2-py3-none-manylinux2014_x86_64.whl (255.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.9/255.9 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyamg-5.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji, xgboost, pyamg, pandas-dq, hvplot, autoviz\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.1.3\n",
            "    Uninstalling xgboost-2.1.3:\n",
            "      Successfully uninstalled xgboost-2.1.3\n",
            "Successfully installed autoviz-0.1.905 emoji-2.14.1 hvplot-0.11.2 pandas-dq-1.29 pyamg-5.2.1 xgboost-1.6.2\n"
          ]
        }
      ],
      "source": [
        "!pip install autoviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQk2boIW7QMD",
        "outputId": "8e121326-eb16-4173-af80-374e75ee8331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imported v0.1.905. Please call AutoViz in this sequence:\n",
            "    AV = AutoViz_Class()\n",
            "    %matplotlib inline\n",
            "    dfte = AV.AutoViz(filename, sep=',', depVar='', dfte=None, header=0, verbose=1, lowess=False,\n",
            "               chart_format='svg',max_rows_analyzed=150000,max_cols_analyzed=30, save_plot_dir=None)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from autoviz.AutoViz_Class import AutoViz_Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oWaAXMhfR6JK",
        "outputId": "d9c854d6-e5f9-4f18-8ee5-b5fa60105d77"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 3321,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 958,\n        \"min\": 0,\n        \"max\": 3320,\n        \"num_unique_values\": 3321,\n        \"samples\": [\n          1057,\n          812,\n          2658\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gene\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 264,\n        \"samples\": [\n          \"PDGFRA\",\n          \"KEAP1\",\n          \"ARID1A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Variation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2996,\n        \"samples\": [\n          \"E1384K\",\n          \"H597Y\",\n          \"V851A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 9,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          8,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1920,\n        \"samples\": [\n          \"The FLT3 receptor tyrosine kinase is constitutively activated by internal tandem duplication (ITD) in its juxtamembrane domain or tyrosine kinase domain in 30% of acute myeloid leukemia (AML) cases.1-3 Alternatively, FLT3 can also be activated by mutations in the kinase domain (such as the D835Y mutation, which are observed in 7% of AML cases.1,2 Both in vitro and in vivo data have demonstrated that FLT3-ITD and FLT3-D835Y encode constitutively activated kinases that drive the proliferation and survival of hematopoietic cells. Furthermore, FLT3-ITD mutations confer a bad prognosis in AML,1,4,5 and FLT3 inhibitors are expected to improve the outcome of AML patients in this subgroup. These data provide the rationale for the use of FLT3 kinase inhibitors for the treatment of AML.2  While pre-clinical experiments with cell-based assays and mouse models documented a potent effect of various FLT3 kinase inhibitors, first clinical trials showed only moderate efficacy.2 One complicating factor for the treatment of AML is the heterogeneity of the disease, with FLT3 mutations being only one of the many mutations present in human AML samples. Molecular data also suggest that FLT3 mutations tend to occur late in the multi-step development of AML, limiting the effect of FLT3 inhibitors to the subset of AML cells within the leukemia that harbor FLT3 mutations.  In an ongoing multinational phase II trial of the FLT3 inhibitor AC220 as monotherapy, a complete remission rate of 45% was reported at an interim report at the EHA meeting in 2011.6,7 Despite these promising results, patients treated with AC220 develop resistance to this inhibitor and Smith et al. have demonstrated that this is due to the acquisition of FLT3 kinase mutations.8 In that study, mutations at 3 different positions in the kinase domain of FLT3 were identified that confer resistance to AC220: F691, D835 and Y842.8 These mutations were identified by an in vitro resistance screen, and in AML samples obtained from patients who developed resistance to AC220 treatment. Although these mutations conferred resistance to AC220, defined by a clear shift in the IC50 values compared to FLT3-ITD and by their identification as acquired mutations in relapsed patients during AC220 treatment, they could still be inhibited by higher concentrations of the drug.  Eight years ago, we predicted resistance mutations in the FLT3 kinase domain using an in vitro mutagenesis technology in FLT3-ITD transformed Ba/F3 cells.9 In this way, we identified 3 positions in FLT3 (N676, F691 and G697) that upon mutation conferred high level resistance to PKC412. One of these mutations (N676D) was later also identified as a resistance mutation in an AML patient treated with PKC412, indicating the validity of the in vitro predictions.10 The F691L mutation in FLT3 was recently identified as a resistance mutation in AML patients treated with AC220.8  Here we show that also the G697R and N676D mutations confer resistance to AC220. Ba/F3 cells dependent on the expression of FLT3-ITD or FLT3-ITD with additional N676D, F691I, F691L or G697R mutation were treated with increasing concentrations of AC220. We measured the proliferation of these cells over a period of 24 h and we determined the level of autophosphorylation of FLT3 as a measurement of its activity after 90 min of inhibitor treatment. All mutations conferred resistance to AC220, with G697R and F691L/I mutations being the most resistant, and N676D conferring a lower level of resistance (Figure 1). In addition, we also used the Ba/F3 cells expressing FLT3-D835Y, and we observed that also these cells were highly resistant to AC220 (Figure 1).  Figure 1. Figure 1. Sensitivity of FLT3-ITD mutants to the AC220 inhibitor. Ba/F3 cells expressing FLT3-ITD (W51 mutation as described by Kelly et al.11), FLT3-D835Y and different FLT3-ITD mutants were treated with increasing concentrations of AC220 and their proliferation ... Our data show that there are additional mutations that confer resistance to AC220; in particular, the G697R mutation that confers resistance similar to the recently described F691L mutation. All these mutations can be easily acquired by a single nucleotide change in the FLT3 gene sequence. Notably, the F691L, G697R and N676D mutations that confer resistance to AC220 remain sensitive to ponatinib or sorafenib, other known FLT3 inhibitors currently being tested in clinical trials. These results point out that combinations of AC220 and ponatinib or sorafenib may be useful to overcome resistance to single agents.12,13\",\n          \"Bruton\\u2019s tyrosine kinase (BTK), a member of the TEC family of kinases, plays a crucial role in B-cell maturation and mast cell activation. Although the structures of the unphosphorylated mouse BTK kinase domain and the unphosphorylated and phosphorylated kinase domains of human ITK are known, understanding the kinase selectivity profiles of BTK inhibitors has been hampered by the lack of availability of a high resolution, ligand-bound BTK structure. Here, we report the crystal structures of the human BTK kinase domain bound to either Dasatinib (BMS-354825) at 1.9 A\\u02da resolution or to 4-amino-5-(4-phenoxyphenyl)-7H-pyrrolospyrimidin- 7-yl-cyclopentane at 1.6 A\\u02da resolution. This data provides information relevant to the development of small molecule inhibitors targeting BTK and the TEC family of nonreceptor tyrosine kinases. Analysis of the structural differences between the TEC and Src families of kinases near the Trp-Glu-Ile motif in the N-terminal region of the kinase domain suggests a mechanism of regulation of the TEC family members. Keywords: Bruton\\u2019s tyrosine kinase; BTK; Dasatinib; Celera compound; TEC-family; crystal structure Introduction Bruton\\u2019s tyrosine kinase (BTK) is a member of the TEC kinase family, nonreceptor tyrosine kinases that play important roles in T-cell receptor-, B-cell receptor-, and Fcc-receptor-mediated signaling. BTK participates in signal transduction from B-cell antigen receptors resulting in phospholipase C-c2-mediated calcium mobilization1 which, in turn, affects pre-B-cell functional maturation and expansion. Since BTK is required for B-cell function, it is an important target for the potential treatment of inflammatory diseases that involve B-cell activation. Mutations in the human BTK gene are responsible for Abbreviations: BTK, Bruton\\u2019s tyrosine kinase; BTK-KD, BTK kinase domain; ITK, interleukin-2 inducible T-cell kinase; PH, pleckstrin homology; SH, Src homology; TEC, tyrosine kinase expressed in hepatocellular carcinoma; XLA, X-linked agammaglobulinemia. Disclosure: All authors (with the exception of M. J. Romanowski) are employees of Biogen Idec and own company stock. Michael J. Romanowski\\u2019s current address is Novartis Institutes for Biomedical Research, Cambridge, MA 02139. *Correspondence to: Laura F. Silvian, Biogen Idec, Inc., 12 Cambridge Center, Cambridge, MA 02142. E-mail: laura.silvian@biogenidec.com Published by Wiley-Blackwell. VC 2010 The Protein Society PROTEIN SCIENCE 2010 VOL 19:429\\u2014439 429 X-linked agammaglobulinemia (XLA), a male immunodeficiency that results in a deficit of mature B cells and serum immunoglobulin.2,3 Several compounds that inhibit BTK kinase activity in biochemical assays have been described in the literature and differ in their kinase selectivity profiles. One weak compound, LFM-A13 (a-cyano-bhydroxy-b-methyl-N-(2,5-dibromophenyl)-propenamide) is a BTK inhibitor with an IC50 of 2.5 lM in a biochemical assay, but also inhibits PLK3 and JAK2.4\\u20136 However, it was found to be somewhat specific for BTK, exhibiting 100-fold higher IC50 values for related tyrosine kinases such as JAK1, HCK, EGFR, and insulin-receptor kinase (IRK).7 Another compound, Dasatinib ([N-(2-chloro-6-methylphenyl)- 2-(6-(4-(2-hydroxyethyl)piperazin-1-yl)-2-methylpyrimidin-4-ylamino)thiazole-5-carboxamide] or BMS- 354825) [Fig. 1(A)], originally used to target BCRAbl, has been shown to bind to BTK with an IC50 of 5 nM8 but also binds to other kinases such as SRC family members (HCK, SRC, and CSK), and ephrin receptors, FGR, PDGFRa, and YES.9 BTK was identified as a target of Dasatinib through pull-down experiments in the CML cell line K562.8 The reversible Celera compound, 3-cyclopentyl-1-(4-phenoxyphenyl)-1H-pyrazolo pyrimidin-7-amine,10 was recently described by Pan et al. 11 as a potent inhibitor of unphosphorylated BTK (8.2 nM IC50 in a biochemical assay). However, it also inhibits Lck and Src with IC50 values of 2 and 70 nM, respectively.10 It is chemically similar to the commercially available 4-amino-5-(4- phenoxyphenyl)-7H-pyrrolo[2,3-d]pyrimidin-7-yl-cyclopentane [B43; Fig. 2(A)] described as a potent inhibitor of Lck.12 Finally, an irreversible inhibitor from Pharmacyclics11 is currently in Phase I for B-cell lymphomas. It is expected to bind irreversibly to Cys481 in the BTK kinase domain active site (0.72 nM IC50 in a biochemical assay) and its selectivity profile is better than the reversible binder because it exhibits greater selectivity against Lck, which lacks this cysteine (>1000-fold selectivity in a biochemical assay). Future design of potent, specific BTK inhibitors would be facilitated by the structures of these compounds bound to BTK, to discern whether there are regions surrounding the ligand that are unique to this kinase. BTK is composed of several domains: an N-terminal pleckstrin homology (PH) domain, a prolinerich TEC homology domain, two SRC homology domains (SH3 followed by SH2), and a C-terminal kinase domain (BTK-KD). Mutations in all domains of human BTK have been found to lead to XLA and missense mutations have been found in all domains except for the SH3 domain.13 Structures have been Figure 1. BTK-KD Y551E/Dasatinib crystal structure. A: Chemical structure of Dasatinib. B: Electron density (2Fo-Fc map at 1 sigma) for Dasatinib within a surface representation of the BTK protein in the human BTK-KD-Y551E/Dasatinib complex. C: Overall view of the BTK kinase domain bound to Dasatinib. Inhibitor (magenta), amino-terminal lobe (green), carboxy-terminal lobe (gray), C-helix (red), hinge (blue), and activation loop (yellow). D: Close-up of the active site and residues within 5 A\\u02da of the bound Dasatinib. The surface is colored according to the convention of base (blue) and acid (red). 430 PROTEINSCIENCE.ORG Crystal Structures of Human BTK Kinase Domain solved for the kinase domains of apo-murine BTK7 and human ITK,14 but a high-resolution structure of a full-length protein with regulatory domains is not available. Low-resolution structures of BTK solved by small angle X-ray scattering have revealed an extended, linear arrangement of the SH3, SH2, and kinase domains, which contrasts with structures of autoinhibited full-length Src and Abl kinases in which a more compact arrangement of the SH2 and SH3 domains allows for the SH2 domain to bind near the C-terminal tail of the kinase domain.15 Structural studies of the Src family of tyrosine kinases have revealed that these proteins can adapt two conformations: an autoinhibitory state of the protein, referred to as an \\u2018\\u2018assembled regulatory domain\\u2019\\u2019 conformation, and an active, more open, structure, where the SH2 domain does not interact with the unphosphorylated C-terminal tail.16 Here, we describe the 1.94 A\\u02da resolution crystal structure of the human BTK-KD Y551E mutant bound to Dasatinib and a 1.6 A\\u02da resolution crystal structure of the unphosphorylated human BTK-KD bound to B43. We observe that the two structures differ in the orientation of the C-helix, similar to conformational changes observed in Src kinase family members that are locked into active or inactive states. Both BTK-KD structures reveal ordered density for the WEX motif at the N-terminus of the kinase domain, where X is a hydrophobic residue. The location of the tryptophan side chain at the base of the C-helix provides an explanation for how the WEX motif acts as an important regulatory element for the TEC family of kinases, similar to its role in regulation of the Src family of kinases, and suggests that the two families have a similar mechanism of regulation. Results Protein purification and characterization BTK-KD and BTK-KD Y551E were purified to  95% purity using a simple, three-step process utilizing two successive glutathione-Sepharose chromatography steps followed by size exclusion chromatography. Mass spectrometry indicated that the majority of the wild-type BTK-KD and BTK-KD Y551E was intact and unphosphorylated (wild-type calculated mass \\u00bc 32,641.6 Da, measured mass \\u00bc 32,643 Da; mutant calculated mass \\u00bc 32,607.5 Da, measured mass \\u00bc 32,609 Da), although 2 and 8%, respectively, were missing the first 4 N-terminal residues (wildtype calculated mass \\u00bc 32,317.2 Da, measured mass Figure 2. BTK-KD/B43 crystal structure. A: Chemical structure of B43. B: Electron density (2Fo-Fc map at 1 sigma) for B43 within a surface representation of the BTK protein in the human BTK-KD-B43 complex. C: Overall view of the BTK kinase domain bound to B43. Inhibitor (green), amino-terminal lobe (green), carboxy-terminal lobe (gray), C-helix (red), hinge (blue), and activation loop (yellow). D: Close-up of the active site and residues within 5 A\\u02da of the bound B43. The surface is colored according to the convention of base (blue) and acid (red). The active site cysteine is shown with a yellow surface. Marcotte et al. PROTEIN SCIENCE VOL 19:429\\u2014439 431 \\u00bc 32,319 Da and mutant calculated mass \\u00bc 32,283.2 Da, measured mass \\u00bc 32,285 Da). Crystal structures The crystal structures of BTK-KD Y551E/Dasatinib and BTK-KD/B43 complexes were determined using 1.94 A\\u02da diffraction data (Rfree \\u00bc 25.8%) and 1.6 A\\u02da diffraction data (Rfree \\u00bc 23.1%), respectively (Table I). The electron density maps clearly revealed the positions of the ligands. Figure 1(B) depicts the electron density for Dasatinib and Figure 2(B) reveals the electron density for B43. The human BTK-KD-Y551E/Dasatinib complex structure exhibits a \\u2018\\u2018C-helix in,\\u2019\\u2019 active conformation in which the catalytic lysine forms H-bonds to Glu445 of the C-helix [Fig. 1(C,D)]. The bilobal fold of the BTK KD is similar to that reported for other tyrosine kinase structures: the N-terminal lobe (residues 392\\u2013473) consists of five antiparallel b-sheets and two a-helices and contains the glycine-rich loop that covers the active site. The C-terminal lobe (residues 482\\u2013659) consists of nine a-helices and two b-strands and the activation loop. Finally, the hinge region (residues 474\\u2013481) connects the two lobes of the kinase and contains the active site cysteine (Cys481). The ordered region of the Dasatinib cocrystal structure encompasses residues 392\\u2013658 but electron density for parts of the activation loop (residues 542\\u2013558) and residues 435\\u2013441 is not visible. However, the DFG-portion of the activation loop is visible and is in the so-called \\u2018\\u2018DFG-in\\u2019\\u2019 conformation. The unphosphorylated BTK-KD/B43 cocrystal structure, in contrast, displays a \\u2018\\u2018C-helix-out\\u2019\\u2019 inactive conformation [Figs. 2(C) and 3(B)]. Most of the kinase is ordered except the tip of the glycine rich loop (residues 410\\u2013414). The activation loop displays a \\u2018\\u2018DFG-in\\u2019\\u2019 conformation and is completely ordered. It is composed of two alpha helices, in which Arg544 within the first helix of the activation loop forms a salt bridge to Glu445 of the C-helix. Dasatinib interactions Dasatinib makes several hydrogen bonds to the hinge and occupies a hydrophobic pocket behind the Thr474 gatekeeper residue [Fig. 1(B,D)]; similar to the previously reported structures of Dasatinibbound Abl (PDB ID: 2GQG),17 Lyn (PDB ID: 2ZVA),18 and cSrc (PDB ID: 3G5D).19 Its H-bond interactions to the hinge are described in Figure 1(D), including interactions with the backbone carbonyl and amide of 477, water-mediated interactions with the Tyr476 side chain, and an interaction between the Thr474 side chain and the compound amide nitrogen. The glycine-rich loop of BTK-KD curls toward Dasatinib to form a hydrophobic interaction with Phe413 [Fig. 1(D)]. The ortho-chloro, methyl phenyl substituent of Dasatinib is twisted to enter a hydrophobic pocket, composed of both hydrophobic and hydrophilic residues Met449, Val458, Leu460, Ile472, Lys430, Glu445, and Ser538. Finally, Glu445 of the C-helix forms a salt bridge with the catalytic Lys430; the epsilon amino group of this lysine is poised to make a pi-cation interaction with the Dasatinib ortho-chloro, methyl phenyl ring [Fig. 1(D)]. B43 interactions The B43 compound makes several hydrogen bonds to the hinge and occupies a hydrophobic pocket behind the Thr474 gatekeeper residue [Fig. 2(D)]. The 4-amino pyrrolopyrimidine of B43 occupies the position of the adenine ring of ATP and the cyclopentyl ring occupies the space generally occupied by the ATP ribose in typical protein kinase structures. The 4-amino pyrrolopyrimidine makes many interactions with the hinge; the exocyclic amine directly interacts Table I. Data Collection and Refinement Statistics BTK-KD/B43 complex BTK-KD Y551E/Dasatinib complex Data collection Space group P21212 P21212 Cell dimensions a (A\\u02da ) 72.5 73.4 b (A\\u02da ) 104.3 104.6 c (A\\u02da ) 38.0 38.1 Wavelength (A\\u02da ) 1.54 0.98 Resolution (A\\u02da ) 50\\u20131.6 50\\u20131.94 Rsym (%)a 8.0 (36.3)a 8.3 (61.9) I/r(I) a 18.5 (4.6)a 32.1 (3.3) Multiplicity 3.8 (4.1)a 6.8 (6.6) Total no. reflections/no. unique reflections 405,732/39,020 490,862/22,496 Completeness (%)a 98.1 (98.5)a 99.2 (99.2) Refinement Resolution (A\\u02da ) 24.5\\u20131.6 28.4\\u20131.94 No. reflections 36,293 21,141 Rwork (Rfree) b (%) 19.2 (23.1) 19.9 (25.8) No. molecules per asymmetric unit 1 1 No. atoms Protein 2161 2016 Ligand 28 33 Water 495 164 Average B-factors (A\\u02da c ) Protein atoms 25.8 23.4 Ligand 30.5 41.7 Water 53.5 35.7 R.m.s.d Bond lengths (A\\u02da ) 0.007 0.024 Bond angles () 1.14 2.05 Ramachandron plot % Allowed 98.5 98.2 % Generously allowed 1.5 1.4 % Not allowed 0 0.4 Rsym \\u00bc R|Ihkl  <Ihkl>|/RIhkl. a The value in parentheses is for the highest resolution bin (approximate interval, 0.1 A\\u02da ). b Rwork \\u00bc RIhkl| |Fo  |Fc| |/RIhkl|Fo| for all data except 5%, which is used for the Rfree calculation. 432 PROTEINSCIENCE.ORG Crystal Structures of Human BTK Kinase Domain with the gatekeeper Thr474 hydroxyl and the backbone carbonyl of 475, the N-3 of the pyrimidine accepts a hydrogen bond from the backbone amine of Met477, and the N-1 of the pyrimidine forms a water-mediated hydrogen bond network to the hydroxyl of Tyr476 and the backbone carbonyl of Ala 478 (Fig. 2). The distal phenyl group of the phenoxyphenyl is twisted 38 out of plane of the phenylether, such that it enters a hydrophobic pocket composed of only hydrophobic residues, Phe442, Met449, Leu460, Ile472, Phe540, and Leu542, and is in proximity to Asp539 of the \\u2018\\u2018DFG\\u2019\\u2019 motif. Phe540 of this motif forms a face-to-edge pi-stacking interaction with the phenoxyphenyl group of B43. Asp539 of the DFG-motif forms a salt bridge with the catalytic Lys430 but does not form direct hydrogen bond interactions with the compound. Discussion Relevance of structures for drug discovery The structures of the human BTK-KD Y551E/Dasatinib and BTK-KD/B43 complexes we report here differ from the publicly available structure of apo-murine BTK-KD (PDB ID: 1K2P) and are arguably more relevant for drug discovery for diseases in which inhibition of BTK may be desired. When the apo-mouse BTK structure is superimposed on the human BTK-KD/B43 structure (RMSD of 1.19 A\\u02da over 230 aligned a-carbons), the biggest differences are observed in the activation loop and in the glycine-rich loop. The activation loop of the mouse apoBTK-KD structure adapts an extended configuration with Tyr551 pointed toward solvent. In the mouse apo-BTK structure, the glycine loop also caves into the active site and occludes the ATP binding pocket. Because the mouse and human BTK-KD\\u2019s are 98.3% identical, and only four amino acids are replaced in the mouse sequence (Q379K, K433R, K625R, and T653S), it is likely that the kinase domain flexibility observed in the apo-murine BTK-KD structure is due to a lack of occupancy of a compound in the active site, rather than due to an intrinsic structural difference between the mouse and human species. Selectivity of compound inhibition For both Dasatinib and the reversible Celera compound, the size and hydrogen bonding nature of the gatekeeper residue of a given kinase generally correlates with its degree of biochemical inhibition9 (Table II). Most of the kinases that are inhibited by 10 lM Dasatinib with a Kd < 1 nM, or that are inhibited by 10 lM Celera compound with less than 5% residual activity, have a threonine gatekeeper. A valine residue in this gatekeeper position is tolerated for the Celera compound binding, but is not as well tolerated for Dasatinib binding to the Ret and KDR kinases (Table II). Because the threonine gatekeeper forms H-bond interactions with both compounds, it is possible that the H-bonding binding energy plays a greater role in binding Dasatinib compared to the Celera compound. An alternative explanation for the poor binding of Dasatinib to valine gatekeeper containing kinases KDR and Ret is that there are differences in side chains within 5 A\\u02da of the compound (Table III). In particular, one residue in the back pocket that forms close hydrophobic interactions with Dasatinib in BTK is Met449, which is replaced by a leucine in KDR and Ret. Because the back pocket in the Dasatinib cocrystal structure Figure 3. Differences between the \\u2018\\u2018inactive\\u2019\\u2019 B43 and \\u2018\\u2018active\\u2019\\u2019 Dasatinib-bound conformation of BTK. A: Overlay of BTK-KD bound to B43 (green), ITK bound to staurosporin (magenta, PDB ID: 1SNU) and P38a (yellow, PDB ID: 1P38). This indicates that the larger phenylalanine gatekeeper of ITK compared to the Thr474 gatekeeper of BTK prevents B43 from binding. It also indicates that the shorter hinge of P38a blocks the B43 binding site. B: Overlay of B43 structure (green) and Dasatinib structure (magenta) indicates that they superimpose well near the hinge but differ near the C-helix, resulting in a shift of >10 A\\u02da in the conformation of the Glu445 side chain and the residues that surround the hydrophobic back pocket. Marcotte et al. PROTEIN SCIENCE VOL 19:429\\u2014439 433 is composed of mixed hydrophobic and hydrophilic residues, Dasatinib may have a greater reliance on Met449 compared to B43, whose back pocket is completely surrounded by hydrophobic residues. Either explanation (i.e., different energy considerations for H-bonding to a threonine gatekeeper for different compounds or differences in the makeup of side chains that line Dasatinib\\u2019s unique hydrophobic pocket), could explain why Dasatinib does not bind as well to Ret and KDR. The exception to the rule of requiring a small gatekeeper for compound binding is p38a, EGFR, and NIMA (never in mitosis gene A)-related kinase 11 (NEK11) kinases, which have threonine gatekeepers, but are only moderately inhibited by both small molecules. P38a kinase has a shorter hinge, and thus its reduced affinity can be ascribed to a smaller binding site [Fig. 3(A)]. Similarly, there are differences in the other residues within 5 A\\u02da of the two small molecules (Table III), which could account for the differences in affinity for NEK11 and EGFR. Both differ in the residues that make up the hydrophobic pocket behind the threonine gatekeeper, with EGFR substituting a cysteine for Val458 and NEK11 substituting a larger phenylalanine for Leu460 and a leucine for Met449. Furthermore, NEK11 contains a glycine substitution for Ser538, a residue which is likely to enhance the flexibility of the DFG motif which follows (Table III). In contrast, Abl, Lyn, and Src, kinases which are inhibited well by both small molecules, show no significant variation in the residues that make up the hydrophobic pocket. In these kinases Ser538 is replaced with alanine, a residue with similar conformational flexibility, and is not likely to effect the flexibility of the activation loop (Tables II and III). As the size of the gatekeeper residue increases from threonine to phenylalanine [as in ITK, Fig. 3(A)], methionine (as in Igf1R, JAK1, JNK3, and SYK) (Table II), or leucine (as in Aurora A) (Table II) neither inhibitor reduces kinase activity to the full extent because both binding modes require insertion of the compound past the bulky gatekeeper into the hydrophobic back pocket. Table II. Gatekeeper Residue in Various Kinases, % Activity for Celera Compound and Kd Values for Dasatinib Kinase Gatekeeper % Activity in the presence of 10 lM Celeraa Dasatinib Kd (nM) b Ack1 Ser 3 6 Abl Thr 3 0.5 Bmx Thr 1 0.0 BTK Thr 1 1.0 CSK Thr 0 0.2 EGFR Thr 20 100 FGR Thr 3 0.5 FYN Thr 3 0.7 Hck Thr 5 0.3 Kit Thr 4 0.6 Lck Thr 13 0.2 Lyn Thr 4 0.6 P38a Thr 57 30 Src Thr 1 0.2 Yes Thr 1 0.3 SIK Thr 17 ND RIPK2 Thr 4 30 cRAF Thr 11 600 EphB1 Thr 65 0.4 NEK11 Thr 64 7000 RET Val 0 200 KDR/VEGFR2 Val 6 3000 RSK1 Leu 80 ND RSK2 Leu 83 ND AurA Leu 101 2000 IGF1R Met 87 ND JAK2 Met 88 ND JNK3 Met 76 ND Syk Met 50 3000 Itk Phe 18 ND ND, not determined. a Upstate kinase profiler. b Taken from Ref. 9. Table III. Residues Within 5 A\\u02da of Compounds in the BTK-KD/B43 and BTK-KD Y551E/Dasatinib Structures NTD GRL UPH LWH HYP AVL 428b 430c 408b 409d 413d 416b 472d 474a,c 475b 476b 477b 479d 480b 481c 458c 460b 449b 538b 539b 540b 542b BTK A K L G F V I T E Y M N G C V L M S D F L NEK11 Ve K L G F V I T E YCe Ge Re De V Fe Le Ge DFVe EGRF A K L G F V Le T Qe Le M Fe G CCe LMTe DFL ABL A K L G Ye V I T E FMYe G Ne V L MAe DFL LYN A K L G F V I T E Y M Ke G Se V L MAe DFL SRC A K L G F V I T E Y M Ke G Se V L MAe DFL RET A K L G F V Le Ve E YAe Ye G Se I e L Le SDFL KDR A K L G F V Ve Ve E Fe Ce Fe G Ne VLLe SDFL NTD, N-terminal domain; GRL, glycine rich loop; UPH, upper hinge; LWH, lower hinge; HYP, hydrophobic pocket; AVL, activation loop. a Gatekeeper residue. b Residue interacts with both B43 and Dasatinib in BTK. c Residue only interacts with Dasatinib in BTK. d Residue only interacts with B43 compound in BTK. e Differences in sequence from BTK sequence. 434 PROTEINSCIENCE.ORG Crystal Structures of Human BTK Kinase Domain Overall conformational changes In the BTK-KD Y551E/Dasatinib complex structure, the Gly-rich loop of BTK partially shields Dasatinib from solvent, as found in the Abl kinase structure (data not shown). Because of the curled-in glycinerich loop in the BTK structure, a hydrophobic interaction is formed between Phe413 and the exocyclic methyl of the Dasatinib pyridine ring [Fig. 1(D)], and between Gln412 and Asp539 of the \\u2018\\u2018DFG\\u2019\\u2019 motif. In every other respect, however, the overall conformation of the BTK-KD/Dasatinib structure is similar to the known Dasatinib-bound conformations of Lyn,18 cSrc,19 and Abl,17 including the compound\\u2019s H-bond interactions with the hinge and the position of its C-helix. The nonvisible residues differ between the two BTK structures, which can be correlated with the different interactions made with different compounds or by the mutation in the activation loop. The tip of the glycine-rich loop is disordered in the B43 structure but is ordered in the Dasatinib structure, while the activation loop is disordered in the Dasatinib structure but is well ordered in the B43 structure. The curled glycine-rich loop forms van der Waals contacts with Dasatinib, between a methyl substituent and the Phe413 side chain, whereas no similar interactions take place between B43 and the BTK-KD protein residues and the glycine-rich loop is disordered. One might expect that the Y551E mutation in the activation loop of the BTK-KD Y551E/Dasatinib structure is responsible for the activation loop disorder; the mutated residue is electrostatically incompatible with the conformation of the activation loop seen in the BTK-KD/B43 structure. In the BTK-KD/B43 structure, the Y551 residue is in close proximity to an Asp521 side chain; this is likely to be electrostatically repelled by mutation of the tyrosine to a glutamate. While it is often hard to pinpoint why flexible regions of crystal structures are disordered, it appears that formation of critical molecular interactions produces ordered electron density for the more flexible regions of BTK. Comparison of the structures of the human BTK-KD-Y551E/Dasatinib complex and the BTKKD/B43 complex reveals a change of conformation from catalytically \\u2018\\u2018active\\u2019\\u2019 to \\u2018\\u2018inactive.\\u2019\\u2019 The Dasatinib complex is more similar to the ATP-bound conformation of most kinases, in which a conserved glutamate from the C-helix forms a salt bridge to the catalytic lysine. In fact, no crystals could be formed with the unphosphorylated, wild-type BTK kinase construct, prompting us to make the Y551E mutant as a mimic of the phosphorylated wild-type protein. In contrast, the BTK-KD/B43 complex shows an outward shift of the C-helix [Fig. 3(B)] relative to its position in the Dasatinib structure, the conserved salt bridge from the glutamate to the catalytic lysine breaks, and a large hydrophobic pocket opens behind the gatekeeper residue. The ability of different kinases to adapt a C-helix out conformation might enable the design of specific inhibitors that targets this larger hydrophobic pocket. Furthermore, Cys481 in the active site of BTK-KD could also be exploited to gain kinase selectivity in which a small molecule may be irreversibly bound to this cysteine via a covalent bond.11 To determine the overall similarity of the BTKKD/B43 structure to other kinases, the B43 complex structure was submitted to the Dali-lite server for structure alignment and scoring20 (http://ekhidna. biocenter.helsinki.fi/dali_server/). The top hits, inactive Hck (PDB ID: 1QCF), inactive SRC (PDB ID: 2SRC), inactive ABL (PDB ID: 2G1T), ITK (PDB ID: 1SM2), and mouse BTK (PDB ID: 1K2P), could be aligned with the human BTK over more than 260 a-carbons and with an rmsd of 2.0 A\\u02da or better. The highest scoring hits, excluding the TEC family of kinases, were all inactive conformations of tyrosine kinases from the Src and Abl families, consistent with their overall sequence similarities to human BTK. The conformation of the activation loop and C-helix in the human BTK-KD/B43 structure is very similar to the inactive Src structure (PDB ID: 2SRC) with an rmsd 1.64 A\\u02da over 257 a-carbons; in Src the activation loop forms two alpha helices and occludes access of the substrate peptide. The overall conformation of the BTK-KD Y551E/Dasatinib structure is similar to the active c-Src (CSK) structure (PDB ID: 1Y57) where the activation loop is swung out and the C-helix moves toward the active site (Fig. 4). Comparison of Src and TEC family kinases The phosphorylation-triggered regulation of BTK and Src differ. Unlike the Src family, the TEC family of nonreceptor tyrosine kinases lacks a conserved tyrosine in the C-terminus that could be phosphorylated to then bind to the SH2 domain.16 BTK is regulated by the phosphorylation of two tyrosine residues, Tyr223 in the SH3 domain and Tyr551 in the activation loop of the kinase domain, both of which participate in kinase activation.21 In a recent study of BTK autophosphorylation, the Y551F mutant was shown to have a 5 to 10-fold lower enzymatic activity than the wild-type protein, indicating that this tyrosine plays an important role in BTK activation.22 Furthermore, mutation of a conserved tryptophan in the N-terminal W-E-X motif, in which X is a hydrophobic residue, also appears to effect the activities of the two kinase families differently. In Src, mutation of the Trp to Ala increases kinase activity while in BTK, mutation of the Trp to Ala reduces kinase activity.23 The human BTK structures described here include ordered density for the WEI motif (residues 392\\u2013395), an area which was disordered in the Marcotte et al. PROTEIN SCIENCE VOL 19:429\\u2014439 435 available murine BTK structure (PDB ID: 1K2P) and the human ITK structure (PDB ID: 1SM2). This enables a structural comparison of the TEC family and the Src family kinases in this conserved region. The Trp side chain shifts from being solvent exposed in the \\u2018\\u2018inactive\\u2019\\u2019 BTK-KD/B43 complex structure to being wedged into a pocket behind the inward C-helix in the \\u2018\\u2018active\\u2019\\u2019 BTK-KD Y551E/Dasatinib complex structure [Fig. 4(A,B)]. A structural superposition of the two BTK structures with the inactive SRC (PDB ID: 2SRC) 24 and an active CSK structure (PDB ID: 1Y57) 16 show that the side chain of Trp395 superimposes in the active structures of both kinase families. In the \\u2018\\u2018inactive\\u2019\\u2019 conformations, a lysine or methionine side chain from the rotated C-helix sterically occludes the tryptophan side chain, and the Trp side chains are not superimposable [Fig. 4(B)]. The similar structural shift observed suggests that the Src and Tec families utilize a similar means of activating the conformation of the kinase domain. However, the inactive conformations of the Trp side chain differ and the differential energy required in switching from inactive to active conformations may differ; this could explain why mutation of this residue to alanine produces different regulatory effects on the two proteins. This study reports the structures of human BTKKD with Dasatinib or 4-amino-5-(4-phenoxyphenyl)- 7H-pyrrolo[2,3-d]pyrimidin-7-yl-cyclopentane bound at the active site. Analysis of the binding modes reveals that the size and H-bonding potential of the gatekeeper residue in different kinases and the nature of the residues that make up the hydrophobic pocket behind the gatekeeper residue are critical in dictating if either compound binds. We propose that the presence of a distinct hydrophobic pocket in the B43 structure suggests that one could design compounds with limited selectivity for kinases that can adapt the \\u2018\\u2018C-helix-out\\u2019\\u2019 conformation. Movements in the C-helix, presumably induced by phosphorylation of the activation loop residue Tyr551, can shift BTK into an active conformation and could generate a second metal binding site containing Glu445 that Lin et al. have shown is important for optimal catalytic activity of the Tyr551-phosphorylated BTK.25 Finally, we show that, like the Src-family of kinases, BTK can adapt a similar conformational rotamer of Trp395 in its \\u2018\\u2018active\\u2019\\u2019 conformation, which is correlated with a similar movement of the C-helix. With a growing recognition that BTK plays a key role in many B cell lymphomas and autoimmune diseases, these structures will assist with selective drug design.  Bruton\\u2019s tyrosine kinase (Btk) is required for B cell development and B cell antigen receptor (BCR) function. Cross-linking of BCR induces phosphorylation of Btk at Tyr551 and Tyr223. However, the functional requirement of these phosphorylation for BCR signaling remains unclear. We demonstrate here that mutation of Tyr551, not Tyr223, abrogates the BCR-induced calcium mobilization. Not only Lyn, but also Syk was required for tyrosine phosphorylation of Btk in BCR signaling. These results suggest that transphosphorylation of Btk on Tyr551 is essential for BCR function and that this phosphorylation is mediated through the concerted actions of Lyn and Syk.  The B cell antigen receptor (BCR)1 is composed of surface immunoglobulin noncovalently associated with a pair of Ig\\u03b1/Ig\\u03b2 disulfide-linked heterodimers, which are essential for signal transduction. Stimulation of the BCR induces the enzymatic activation and tyrosine phosphorylation of three distinct families of nonreceptor cytoplasmic protein tyrosine kinases (PTKs), the Src family, Syk, and Btk. The Src family kinases are rapidly activated after BCR engagement, and their activation correlates with the initial tyrosine phosphorylation of the immunoreceptor tyrosine-based activation motif on the BCR Ig\\u03b1 and Ig\\u03b2 subunits (reviewed in Refs.1-4).  Temporally, activation of Src family kinases is followed by Btk and Syk (5). This sequential activation potentially places Btk and Syk downstream of Src family kinases. Utilizing co-overexpression system in fibroblasts and COS cells, it has been demonstrated that Lyn transphosphorylates Btk on Tyr551 in the catalytic domain, a site homologous to the Src family kinase consensus autophosphorylation site (6, 7). This results in a 5\\u201310-fold increase in Btk enzymatic activity (7). The increase in activity also leads to increased autophosphorylation at Tyr223 in the SH3 domain of Btk (8). The identical phosphopeptides were generated after cross-linking of the BCR, indicating that these sites are also tyrosine phosphorylated in B cells (7). Although the importance of phosphorylation of Tyr551 and Tyr223 for fibroblast transformation has been examined (8, 9), functional significance of phosphorylation of Tyr551 and Tyr223 of Btk in BCR signaling remains elusive.  To genetically define the functional relationship among Lyn, Syk, and Btk in BCR signaling, we established each PTK-deficient DT40 B cells (10, 11). Our previous results have shown that the BCR-induced calcium mobilization is abrogated in Btk-deficient DT40 cells and that the loss of Btk does not significantly affect the activation of Lyn and Syk in BCR signaling (11). Here we show that BCR-induced tyrosine phosphorylation of Btk is abolished in Lyn/Syk double-deficient DT40 cells, suggesting that Btk acts downstream of Lyn and/or Syk in BCR signaling. Moreover, this phosphorylation is partially inhibited in Lyn- or Syk-deficient cells, indicating contribution of both Lyn and Syk to Btk phosphorylation. The Btk Y223F mutant was able to restore the BCR-induced calcium mobilization, whereas the Y551F mutant could not. Thus, these results suggest that phosphorylation of Tyr551 of Btk through Lyn and Syk is essential for BCR signaling.  Previous Section Next Section EXPERIMENTAL PROCEDURES  Cells, Antisera, and DNA Transfection DT40 cells were cultured in RPMI 1640 supplemented with 10% fetal calf serum, penicillin, streptomycin, and glutamine. Anti-chicken IgM mAb M4 and anti-phospholipase C (PLC)-\\u03b32 Ab were described previously (10). The anti-phosphotyrosine mAb (4G10) and anti-T7 mAb were obtained from Upstate Biotechnology, Inc. and Novagen, respectively. T7-tagged and mutant Btk cDNAs were created by polymerase chain reaction, and the resulting constructs were confirmed by DNA sequencing. These cDNAs were cloned into pApuro expression vector (10). For DNA transfection into DT40 cells, DNA was linearized, electroporated, and selected in the presence of puromycin (0.5 \\u03bcg/ml). The expression of Btk was analyzed by Western blotting.  Immunoprecipitation and Immunoblot Analysis DT40 cells were stimulated by mAb M4 for indicated time. Cells were solubilized in Nonidet P-40 lysis buffer (1% Nonidet P-40, 150 mM NaCl, 20 mM Tris, pH 7.5, 1 mM EDTA) containing 50 mM NaF, 10 \\u03bcM molybdate, and 0.2 mM sodium vanadate supplemented with protease inhibitors described previously (10). Cell lysates were sequentially incubated (1 h at 4\\u2009\\u00b0C for each incubation with Ab and protein A-Sepharose). For immunoblotting, samples were separated on SDS-PAGE and transferred to nitrocellulose membrane (Amersham Corp.). Filters were incubated with mAb 4G10 or anti-T7 mAb. After washing, filters were developed using a sheep anti-mouse IgG Ab conjugated to horseradish peroxidase and enhanced chemiluminescence (ECL).  For in vitro kinase assay, the immunoprecipitates were washed with 20 mM Hepes, pH 8, and 150 mM NaCl after washing with lysis buffer. Added to each sample was 50 \\u03bcl of kinase buffer (20 mM Hepes, pH 8, 10 mMmagnesium acetate, 10 mM MnCl2) in the absence or presence of ATP (1 \\u03bcM). Recombinant glutathioneS-transferase fusion protein containing a cytoplasmic domain of mouse Ig\\u03b1 (glutathione S-transferase/Ig\\u03b1) was made and used as an exogenous substrate (6). The reactions were allowed at 30\\u2009\\u00b0C for 10 min and terminated by the addition of sample buffer.  Calcium and Phosphoinositide Analysis For calcium analysis, cells (5 \\u00d7 106) were resuspended in phosphate-buffered saline containing 20 mM Hepes, pH 7.2, 5 mM glucose, 0.025% bovine serum albumin, and 1 mM CaCl2 and loaded with 3 \\u03bcMFura-2/AM at 37\\u2009\\u00b0C for 45 min. Cells were washed twice and adjusted to 106 cells/ml with continuous monitoring of fluorescence spectrophotometer (model F-2000; Hitachi) at an excitation wavelength of 340 nm and an emission wavelength of 510 nm. Calibration and calculation of calcium level were done as described (12).  For phosphoinositide analysis, cells (106/ml) were labeled with myo-[3H]inositol (10 \\u03bcCi/ml, 105 Ci/mmol) for 4\\u20135 h in inositol-free RPMI 1640 supplemented with 10% dialyzed fetal calf serum, then stimulated in the presence of 10 mM LiCl with mAb M4. The soluble inositol phosphates were extracted with trichloroacetic acid at indicated time points, and applied to AG1-X8 (formate form) ion exchange columns (Bio-Rad) preequilibrated with 0.1 M formic acid. The columns were washed with 10 ml of H2O and 10 ml of 60 mMammonium formate, 5 mM sodium tetraborate. Elution was performed with increasing concentrations of ammonium formate (0.1\\u20130.7M).  Previous Section Next Section RESULTS  We have used a genetic approach to determine the requirements for Btk tyrosine phosphorylation following BCR engagement. We utilized three mutants of the chicken B cell line DT40, generated by inactivation of either lyn, syk, or both genes by homologous recombination (10, 11). Since the Ab raised against chicken Btk does not immunoprecipitate efficiently, we expressed an epitope-tagged version of Btk (designated T7-Btk) into wild type and these mutant DT40 cells. Clones expressing similar levels of T7-Btk in these deficient DT40 cells were selected. These clones were lysed prior to and following BCR ligation, and T7-Btk was immunoprecipitated with anti-T7 mAb. As shown in Fig. 1, Btk was inducibly tyrosine-phosphorylated following BCR stimulation in wild type DT40 cells, consistent with previous reports (5, 13-15). In contrast to wild type cells, Lyn/Syk double-deficient DT40 cells failed to exhibit any Btk tyrosine phosphorylation following BCR ligation, indicating requirement of Lyn and/or Syk for the BCR-induced tyrosine phosphorylation of Btk. In Lyn-deficient DT40 cells, tyrosine phosphorylation of Btk at 1 and 3 min after BCR ligation was significantly reduced, whereas this phosphorylation at 10 min reached almost the same level as that in wild type cells. Compared with Lyn-deficient DT40 cells, Syk-deficient cells showed a complementary time course of the BCR-induced phosphorylation of Btk; phosphorylation of Btk was only observed at 1 and 3 min after BCR stimulation. These data suggest that either Lyn or Syk alone is capable of phosphorylating Btk at least to some extent and that the concerted actions of Lyn and Syk are required for full phosphorylation of Btk in BCR signaling.  Figure 1 View larger version: In this page In a new window Download as PowerPoint Slide Figure 1 BCR-induced tyrosine phosphorylation of Btk in various DT40 mutant cells. At the indicated time points after M4 stimulation (4 \\u03bcg/ml), cells were lysed in 1% Nonidet P-40 lysis buffer and immunoprecipitated with anti-T7 mAb. Immunoprecipitates were loaded onto 8% SDS-PAGE, and the blotted membrane was incubated with mAb 4G10. After the filter was stripped, the same blot was reprobed with anti-T7 mAb. pY, phosphotyrosine.  It has been demonstrated recently that transphosphorylation of Btk at Tyr551 results in increased its enzymatic activity, leading to autophosphorylation of a second tyrosine Tyr223 in a fibroblast system (8). To determine that this sequential phosphorylation of Btk occurs also after BCR stimulation, we transfected Y551F and Y223F mutants of Btk into Btk-deficient DT40 cells (Fig. 2 A). Stimulation of BCR did not enhance tyrosine phosphorylation of Btk(Y551F) (Fig. 3). This result suggests the possibility that Tyr551 of Btk is only target of Lyn/Syk-dependent phosphorylation after BCR stimulation in DT40 cells. Alternatively, phosphorylation at Tyr551 is a critical step for subsequent phosphorylation of Btk in BCR signaling context. In contrast to Btk(Y551F), Btk(Y223F) showed increased tyrosine phosphorylation upon BCR stimulation, although this phosphorylation was only observed at 1 min after receptor cross-linking (Fig. 3). Thus, these results implicate that a primary target of tyrosine through concerted actions of Lyn and Syk is Tyr551 of Btk in BCR signaling, leading to phosphorylation of Tyr223. Since Btk(Y223F) did not show significant tyrosine phosphorylation at 3 and 10 min after receptor stimulation, our finding also suggests that phosphorylation of Tyr223 is required for sustained Btk phosphorylation in BCR signaling.  Figure 2 View larger version: In this page In a new window Download as PowerPoint Slide Figure 2 Schematic representation of Btk cDNA constructs (A) and expression of mutant Btk in Btk-deficient DT40 cells (B). DT40 cells expressing indicated constructions were lysed with Nonidet P-40 lysis buffer (2 \\u00d7 106 cells/lane) and immunoprecipitated with anti-T7 mAb. Immunoprecipitates were divided, and half of them were used for Western blotting with anti-T7 mAb. The remaining half were used for in vitro kinase assay as described under \\u201cExperimental Procedures\\u201d and blotted with mAb 4G10. In the absence of ATP, in vitro kinase samples of these immunoprecipitates showed no significant tyrosine phosphorylation. pY, phosphotyrosine.  Figure 3 View larger version: In this page In a new window Download as PowerPoint Slide Figure 3 BCR-induced tyrosine phosphorylation of Btk(Y223F) and Btk(Y551F). At the indicated time points after M4 stimulation (4 \\u03bcg/ml), Btk-deficient cells expressing these constructs were lysed in 1% Nonidet P-40 lysis buffer and immunoprecipitated with anti-T7 mAb. Immunoprecipitates were loaded onto 8% SDS-PAGE, and the blotted membrane was incubated with mAb 4G10. After the filter was stripped, the same blot was reprobed with anti-T7 mAb. pY, phosphotyrosine.  Utilizing Btk-deficient DT40 cells expressing Btk(Y551F) and Btk(Y223F), we analyzed the effects of these mutations on BCR signaling. Wild type and kinase-negative T7-Btk were also transfected into Btk-deficient DT40 cells as a positive and a negative control, respectively (Fig. 2 A). To determine whether these mutations affect tyrosine kinase activity, Btk immunoprecipitates were used forin vitro kinase assays with glutathioneS-transferase/Ig\\u03b1 as an exogenous substrate. Btk(R525Q) exhibited no kinase activity, indicating that the immunoprecipitates are largely free of contaminating tyrosine kinases. When the extent of tyrosine phosphorylation is normalized to the amount of protein present in each kinase assay, both Btk(Y551F) and Btk(Y223F) had similar transphosphorylation activity compared with wild type Btk (Fig.2 B). We showed previously that the BCR-induced PLC-\\u03b32 activation is abrogated in Btk-deficient DT40 cells, leading to loss of calcium mobilization (11). Thus, we examined whether these mutations were able to restore these defects or not. As shown in Fig.4 A, DT40 cells expressing Btk(Y223F) exhibited normal calcium mobilization, whereas Btk(Y551F) was able to mobilize only small amount of calcium upon receptor cross-linking. Consistent with these data, cross-linking of BCR on DT40 cells expressing Btk(Y223F) stimulated inositol 1,4,5-trisphosphate (IP3) production and tyrosine phosphorylation of PLC-\\u03b32, although these parameters were lower than wild type Btk (Fig. 4,B and C). This might reflect the lower expression level of Btk(Y223F) than wild type Btk (Fig. 2 B). The BCR-induced IP3 production and tyrosine phosphorylation of PLC-\\u03b32 in DT40 cells expressing Btk(Y551F) was essentially the same as those in DT40 cells expressing Btk(R525Q) (Fig. 4 and data not shown). These results demonstrate that phosphorylation of Tyr551, not Tyr223, is essential for BCR signaling.  Figure 4 View larger version: In this page In a new window Download as PowerPoint Slide Figure 4 Functional restoration of BCR signaling by Btk(Y223F) and Btk(Y551F). Calcium mobilization (A), IP3 generation (B), and tyrosine phosphorylation of PLC-\\u03b32 (C). C, Btk-deficient DT40 cells expressing these mutants were stimulated for 3 min with M4 (4 \\u03bcg/ml). Cells were lysed in 1% Nonidet P-40 lysis buffer and immunoprecipitated with anti-PLC-\\u03b32 Ab. Immunoprecipitates were loaded on 6% SDS-PAGE, and the blotted membrane was incubated with mAb 4G10. After the filter was stripped, the same blot was reprobed with anti-PLC-\\u03b32 Ab. pY, phosphotyrosine.  Previous Section Next Section DISCUSSION  In Lyn-deficient DT40 cells, BCR-induced tyrosine phosphorylation of Btk was significantly inhibited at 1 and 3 min after stimulation (Fig. 1), indicating that Btk phosphorylation is mediated by Lyn in BCR signaling in these early time points. However, at 10 min after stimulation, this phosphorylation reached almost the same level in wild type cells, suggesting that tyrosine phosphorylation of Btk at 10 min after BCR stimulation is independent of Lyn. In contrast to Lyn-deficient DT40 cells, Syk-deficient cells show the profound inhibition of the BCR-induced tyrosine phosphorylation of Btk at 10 min after receptor cross-linking, implicating that this Btk phosphorylation is mediated by Syk. Taken together, these data suggest that the initial Btk phosphorylation and sustained phosphorylation are mediated by coordinated actions of Lyn and Syk after BCR cross-linking.  Our conclusion is somewhat inconsistent with the previous reports using COS cell and fibroblast expression systems (6, 7). In these systems, Lyn is able to phosphorylate Btk, whereas Syk is not. One of the possibilities about this disparity between the heterologous systems and DT40 B cell system is that Syk is maximally activated through transphosphorylation at Tyr518 and/or Tyr519 by Lyn in DT40 cells (16). In contrast, overexpressed Syk itself may not be fully activated in heterologous systems. To test this possibility, we transfected T7-Btk into Syk-deficient cells expressing Syk mutant in which Tyr518/Tyr519 is changed to Phe518/Phe519. In this mutant DT40 cell, the BCR-induced tyrosine phosphorylation of Btk was similar to that in Syk-deficient DT40 cells (data not shown), implicating that the requirement of Syk is due to up-regulated Syk through transphosphorylation of Tyr518/Tyr519. It is also possible that Btk may not be a direct substrate of Syk. Assuming that another PTK acts downstream of Syk in BCR signaling, our data might be accounted for by the involvement of this Syk-regulated PTK in tyrosine phosphorylation of Btk.  It has been reported that two tyrosines, Tyr551 and Tyr223, are phosphorylated after cross-linking of BCR. Btk(Y551F) exhibited no tyrosine phosphorylation upon BCR cross-linking, whereas Btk(Y223F) showed an increase of tyrosine phosphorylation at 1 min after receptor stimulation, suggesting that Tyr551 phosphorylation is a prerequisite for subsequent phosphorylation of Btk in BCR signaling events. Thus, these results support the previous contention that phosphorylation of Btk at Tyr551 is followed by its autophosphorylation at Tyr223 (7, 8). Since Btk(Y223F) did not show significant tyrosine phosphorylation at 3 and 10 min after receptor stimulation, phosphorylation of Tyr223 appears to be required for sustained Btk phosphorylation. Recent crystallographic analysis of Itk (Btk/Tec family PTK expressed in T cells) may provide insights into the function of phosphorylation of Tyr223 of Btk (17). Based on this analysis, the proline-rich domain adjacent to the SH3 domain of Btk/Tec family kinases contains an SH3 ligand (Fig. 2 A), allowing intramolecular interaction. Interestingly, Tyr223of Btk is located within the interface of this interaction. Thus, phosphorylation of Tyr223 may disrupt this intramolecular interaction, thereby changing the conformation of Btk. This conformational change might be required for sustained phosphorylation of Btk in BCR signaling.  Our functional data clearly indicate that Tyr551 is essential for BCR signaling, whereas Tyr223 is dispensable for BCR-induced PLC-\\u03b32 activation. Since phosphorylation of Tyr551 was already reported to increase the kinase activity of Btk with 5\\u201310-fold (7), one of the consequence of phosphorylation of Tyr551 is increased kinase activity upon BCR cross-linking. Although we carried out in vitro kinase assay on Btk immunoprecipitates in wild type DT40 cells, the BCR-induced activation of its in vitro kinase activity could not be reproducibly observed. Previous reports suggest that the magnitude of the BCR-induced activation of Btk is significantly smaller than that of maximum Btk phosphorylation by Lyn in heterologous systems (6, 7). Indeed, in our hand, this 5\\u201310-fold activation of Btk in COS cells could be reproducibly detected. Thus, the most likely explanation is that the increase of Btk enzymatic activity through phosphorylation of Tyr551 in DT40 cells is too small for our detection system.  In the case of Syk, it has been demonstrated that in addition to recruitment of Syk to phosphorylated Ig\\u03b1/Ig\\u03b2, phosphorylation at tyrosine (Tyr519 and/or Tyr518) within its activation loop is critical for BCR signal transduction (16). In this report, we show that phosphorylation of Tyr551 on Btk activation loop is also an obligatory mechanism for its participation in BCR signaling. Thus, cytoplasmic PTK cascade through phosphorylation of tyrosine located in the activation loop may be one of the general mechanisms for cytoplasmic signal transduction.  The Tec family kinases are tyrosine kinases that function primarily in hematopoietic cells. The catalytic activity of the Tec kinases is positively influenced by the regulatory domains outside of the kinase domain. The current lack of a full-length Tec kinase structure leaves a void in our understanding of how these positive regulatory signals are transmitted to the kinase domain. Recently, a conserved structure within kinases, the \\u2018regulatory spine\\u2019, has been identified that assembles and disassembles as a kinase switches between its active and inactive states. Here we define the residues that comprise the regulatory spine within Tec kinases. Compared to previously characterized systems, the Tec kinases contain an extended regulatory spine that includes a conserved methionine within the C-helix and a conserved tryptophan within the SH2-kinase linker of Tec kinases. This extended regulatory spine forms a conduit for transmitting the presence of the regulatory domains of Tec kinases to the catalytic domain. We further show that mutation of the gatekeeper residue at the edge of the regulatory spine stabilizes the regulatory spine resulting in a constitutively active kinase domain. Importantly, the regulatory spine is preassembled in this gatekeeper mutant rendering phosphorylation on the activation loop unnecessary for its activity. Moreover, we show that the disruption of the conserved electrostatic interaction between Btk R544 on the activation loop and Btk E445 on the C-helix also aids in the assembly of the regulatory spine. Thus, the extended regulatory spine is a key structure that is critical for maintaining the activity of Tec kinases.  Keywords: Itk and Btk, regulatory spine, kinase activation, gatekeeper residue, phosphorylation Go to: INTRODUCTION Protein kinases catalyze the transfer of a phosphate group from ATP to a hydroxyl containing amino acid side chain; either Ser/Thr for serine-threonine kinases or Tyr for tyrosine kinases[1]. The activity of protein kinases is exquisitely regulated within the cell[1; 2; 3; 4]. The switch from the catalytically inactive state of a kinase to the active state is often accompanied by the phosphorylation of a key residue within the activation loop, a large flexible loop that lies between the two lobes of the kinase domain structure[1]. Phosphorylation of the activation loop residue can trigger concerted movements in other mobile elements within the kinase domain such as the C-helix and the DFG motif that brings about the assembly of the catalytically critical residues in the kinase active state[1]. The active state conformations associated with different kinases are nearly identical across the many kinases for which high resolution structures have been solved[2; 3; 5; 6; 7]. It is not surprising that the active states of distinct kinases are very similar since the phospho-transfer chemistry carried out by different kinases is the same. In contrast, it is becoming clear that the structural features associated with the inactive state of various kinases differ widely.  The search for features that are conserved within the structures of active kinases has recently led to the identification of a structure termed the \\u2018regulatory spine\\u2019[8; 9]. The regulatory spine was first identified by Local Spatial Patterns alignment analysis using a set of serine-threonine and tyrosine kinase structures that included PKA as a model kinase[8; 9]. The regulatory spine defines a stretch of amino acid residues that is assembled only in the active state of kinases. Unlike consensus sequences that consist of a continuous stretch of amino acids in the primary structure, the regulatory spine consists of disparate residues that span the N- and C-terminal lobes of the kinase domain. Assembly of the regulatory spine has been proposed to be a crucial step in the activation of protein kinases and this structure is disrupted in structures of kinases in the inactive state. Moreover, the regulatory spine has been proposed as the mechanism by which allosteric effects can be propagated to the kinase active site[8; 9].  The Tec kinases are immunologically related tyrosine kinases which consist of five mammalian members: Itk, Btk, Tec, Txk and Bmx[10; 11]. Tec kinases share similar domain architecture as Src, Abl and Csk family of kinases, in that they have the SH3-SH2-kinase domain cassette[10]. Despite domain similarities, we and others have shown that the regulation of Tec kinases is distinct from Src and Abl kinases[10; 12; 13; 14]. Unlike the Src and Abl kinases, the N-terminal regulatory domains of Tec kinases positively regulate the activity of the kinase domain[14]. While the isolated kinase domains of Src and Abl are active, the isolated kinase domains of the Tec family exhibit poor catalytic activity[13; 14; 15]. Regulation of the Tec kinases is in fact more similar to the Csk family of enzymes, whose N-terminal regulatory domains are essential for the catalytic activity of the kinase domain[16]. Moreover, while the structures of full-length Src and Csk kinases are available, the structure of a full-length Tec kinase remains elusive[2; 17; 18]. This leaves a significant gap in our mechanistic understanding of the regulation of the Tec family kinases.  In this manuscript, we define the regulatory spine within the Tec family kinases and show that mutation of the spine residues leads to different effects in the context of the isolated kinase domain verses full-length Itk. Moreover, we show that the assembly of a stable regulatory spine within members of the Tec kinase family is critically dependent on the presence of the SH2-kinase linker region. The residues that comprise the regulatory spine within PKA are insufficient to promote the assembly of a stable regulatory spine within the Tec kinases. We extend the Tec regulatory spine to include a conserved methionine within the C-helix and a conserved tryptophan residue within the SH2-kinase linker of Tec kinases. Together with the spine residues originally identified within the PKA kinase domain, the conserved methionine and tryptophan residues form a continuous structure that links the kinase active site to the N-terminal regulatory domains of Tec kinases. Furthermore, we show that the stabilization of the regulatory spine by the gatekeeper threonine to methionine mutation eliminates the need for phosphorylation on the activation loop for Btk kinase activity. Thus, the extended regulatory spine is a structure that is critical for the regulation of Tec kinases and if stabilized appropriately, is sufficient for activation in the absence of activation loop tyrosine phosphorylation and in the absence of the non-catalytic Tec regulatory domains.  Go to: RESULTS The regulatory spine controls Tec kinase activity  The regulatory spine within PKA consists of five residues: L95, L106, Y164, F185, and D220[9]. These residues are spread throughout the primary sequence of the PKA kinase domain: L95 is located on the C-helix, L106 is on the N-terminus of the \\u03b24 strand, Y164 is part of the \\u2018HRD\\u2019 motif, F185 is from the \\u2018DFG\\u2019 motif and D220 is on the F-helix within the C-terminal lobe[9]. Alignment of the structure of the Btk and Itk kinase domains with that of PKA shows that the corresponding regulatory spine residues within the Btk and Itk kinase domains should consist of: Btk M449, L460, H519, F540 and D579 and Itk M409, L420, H479, F500 and D539 respectively (Fig. 1a).  Figure 1 Figure 1 Identification of the regulatory spine in Tec kinases To test the role of the predicted spine residues in the Tec kinases, we wished to take advantage of the rapid bacterial expression and purification system that has been developed for the isolated kinase domains of Itk and Btk[19]. One issue that arises, however, is the fact that the isolated kinase domains of the Tec kinases exhibit poor catalytic activity and so the expected loss of function mutations in the regulatory spine would be difficult to characterize given the already low activity of the wild type kinase domains. In order to take advantage of the ease of the bacterial expression system, we needed an isolated Btk and Itk kinase domain with higher catalytic activity. It has been demonstrated previously that introduction of a bulky hydrophobic residue such as isoleucine or methionine at the gatekeeper position activates multiple kinases[20]. Indeed, we find that the Itk F434M and Btk T474M isolated kinase domains are more active when compared to wild-type isolated kinase domain (manuscript in preparation). We therefore probed the importance of the predicted regulatory spine residues in Itk and Btk by mutating them individually to alanine in the context of the Itk F434M and Btk T474M isolated kinase domain mutants. Activity measurements are carried out by monitoring the phosphorylation levels of a peptide substrate in a radioactive assay or by detecting the level of autophosphorylation on the activation loop tyrosine (Y511 in Itk and Y551 in Btk) by western immunoblotting. While phosphorylation of the activation loop tyrosine is achieved by the activity of the Src family kinases Lck and Lyn respectively in vivo, under in vitro conditions Tec kinases autophosphorylate on the activation loop tyrosine[21; 22; 23].  Disruption of the regulatory spine residues by mutation to alanine is predicted to disrupt kinase activity. Indeed, mutation of Btk M449, H519, F540 and D579 and Itk M409, H479, F500 and D539 to alanine within the isolated kinase domain of Itk F434M and Btk T474M leads to decreased phosphorylation on the activation loop tyrosine and drastically reduces the catalytic activity (Fig. 1b, c, d and e). Itk kinase residues such as M409, F500 and H479 are highly conserved with other kinases with well-defined roles in catalysis[8]. Itk M409 is involved in binding the substrate ATP[12]. Itk F500 is part of the \\u2018DFG\\u2019 motif at the start of the activation loop segment and is responsible for stabilizing the conformation of the preceding aspartate, and the C-helix[8]. Itk H479 is part of the \\u2018HRD\\u2019 motif where it serves as a scaffold for D499 and F500[8]. It is therefore not surprising that mutation at these sites leads to a loss in activity. However, Itk D539 is not part of any previously characterized regulatory motif and therefore the drastic reduction in Itk activity upon mutation of this residue to alanine highlights the importance of the regulatory spine in regulating Itk activity. Moreover, since the regulatory spine residues are conserved within the Tec kinase family, this structure would be predicted to be critical for regulating the activity of all Tec kinase family members.  Unexpectedly, mutation of Itk L420 and Btk L460 to alanine, which based on the previous PKA work is predicted to be part of the regulatory spine, failed to inactivate the isolated kinase domains of Itk F434M or Btk T474M (Fig. 1b, c, d and e). In fact, the isolated kinase domains of both Itk L420A/F434M and Btk L460A/T474M double mutants showed an increase in activity when compared to the isolated kinase domain of Itk F434M and Btk T474M, respectively. To ensure that the activating effect of the Leu to Ala mutation was not an artifact of working with the activated (gatekeeper mutant) isolated kinase domains of Itk and Btk, the regulatory spine residues were mutated to alanine in the context of wild-type isolated kinase domains of Itk and Btk. Since the catalytic activity of the isolated kinase domain of Tec kinases is generally poor, the detection of activation loop phosphorylation levels by western immunoblotting is difficult and for Itk, in particular, phosphorylation Y511 is below the detection limit by western immunoblotting. Hence, the activity of the wild-type and regulatory spine mutants of the isolated kinase domains of Itk and Btk are monitored by their ability to phosphorylate a peptide substrate in the radioactive assay.  The results of the regulatory spine mutations in the context of the wild type kinase domains mirror the results for the activating gatekeeper mutants described above. Mutation of Btk M449, H519, F540 and D579 to alanine within the isolated wild type kinase domain of Btk leads to decreased catalytic activity (Fig. 1f). Circular dichroism spectra of the Btk mutants overlay well with that of wild-type Btk showing that the decreased activity of the Btk mutants are not due to unfolding of the kinase (Supp. Fig. 1). Since the activity of the isolated Itk wild-type kinase domain is not significantly above background levels, the resulting activity of the Itk spine mutants: Itk M409A, H479A, F500A and D539A can not be interpreted except to say activity is no greater than wild type (Fig. 1g). However, consistent with our earlier results with the gatekeeper mutant, the Itk L420A and Btk L460A mutants are both more active than wild-type isolated kinase domain of Itk and Btk, respectively (Fig. 1f and g). Interestingly, previous studies on the regulatory spine within the Abl kinase have shown that mutation of Abl L320 to glycine (corresponding to Itk L420 and Btk L460), leads to only a slight decrease in kinase activity of full length Abl[20]. This is also consistent with modeling studies of Abl that have shown that Abl L320 has a modest impact on regulatory spine formation[20]. Thus, Itk L420 and Btk L460 do not play a major role in the assembly of the regulatory spine within the context of the isolated kinase domain of Itk and Btk.  The regulatory spine is not assembled in the structure of phosphorylated Itk kinase domain  Activation of Tec kinases requires the phosphorylation of a conserved tyrosine within the activation loop[12; 21; 23]. Separate high-resolution structures of the Btk kinase domain with Y551 either phosphorylated (active) or unphosphorylated (inactive) have recently been reported[24]. A comparison of the inactive and active states of Btk kinase domain shows clear differences in the region of the regulatory spine (Fig. 2a). The regulatory spine residues assemble into a linear arrangement in the structure of the active Btk kinase, while interactions between the regulatory spine residues (in particular L460, M449 and F540) are disrupted in the structure of inactive Btk kinase. The structural differences in this region between active and inactive Btk are consistent with the role of the regulatory spine as defined previously for PKA (Fig. 2a).  Figure 2 Figure 2 The regulatory spine is assembled only in the active state of kinases Crystal structures of the isolated kinase domain of Itk that is either unphosphorylated or phosphorylated on Y511 in the activation loop are also available[12]. Surprisingly, the available Itk kinase domain structures overlay quite well, with little or no conformational differences between them regardless of the phosphorylation state of the activation loop. Inspection of the Itk kinase domain structures shows that the regulatory spine residues in the Itk kinase domain structures adopt a disrupted configuration similar to the inactive Btk kinase domain (Fig. 2b). An additional hallmark of an active kinase domain structure is the formation of a crucial ion pair between a conserved lysine positioned within the \\u03b23 strand of the kinase domain and a conserved glutamate on the C-helix[1]. The distance between the corresponding residues (Itk K390 and E405) within the structures of both phosphorylated and unphosphorylated Itk kinase domain is on the order of 8.0 \\u00c5 which is significantly greater than the 3 to 4 \\u00c5 distance that is observed in the structures of other active kinases (Fig. 2b)[12]. Indeed, the distance between the same conserved ion pair within Btk, (Btk K430 and E445) changes from 14.6 to 3.8 \\u00c5 upon activation of the kinase (Fig. 2a). These observations suggest that both the phosphorylated and unphosphorylated Itk kinase domains adopt a conformation consistent with the \\u2018inactive\\u2019 enzyme. The inability of the Itk kinase domain to fully assemble into an active conformation, despite being phosphorylated on Y511 in the Itk activation loop, points to additional requirements for activation.  A notable difference between the Itk and Btk crystal structures is that the construct used for the crystallization of the Btk kinase domain included the SH2-kinase linker, while that of the Itk kinase did not (Fig. 2a & b)[12; 24]. We hypothesize that the absence of the SH2-kinase linker within the Itk construct used for crystallography might prevent the assembly of a stable regulatory spine in the kinase domain despite phosphorylation on the activation loop Y511.  Extension of the Tec kinase regulatory spine  We have previously shown that the SH2-kinase linker, the 17 amino acids between the SH2 domain and the kinase domain, is critical for the activity of both Btk and Itk, exerting a positive effect on the catalytic function of the kinase domain[14]. More specifically, a conserved tryprophan (Itk W355, Btk W395) in the SH2-kinase linker, as well as a methionine residue in the C helix (Itk M410, Btk M450) are crucial residues in the Tec family kinase regulatory apparatus (Fig. 3a)[14]. Like the regulatory spine mutants described in Figure 1, point mutations of Itk W355, Btk W395 or Itk M410 to alanine all result in a significant drop in catalytic activity (Fig. 3b). Examination of the crystal structures of Btk shows that Btk W395 and Btk M450 are located at the \\u2018top\\u2019 of the regulatory spine and, in the active Btk structure, serve to extend the hydrophobic packing of the spine residues well into the N-terminus of the kinase domain (Fig. 3c & d). In the inactive Btk structure, repositioning of the W395 and M450 side chains disrupts the extended regulatory spine (Fig. 3c & d) in much the same manner that repositioning of M449 in the inactive Btk structure disrupts the core of the spine (Fig. 2a). The active and inactive Btk structures consist of the same amino acids (residues 382\\u2013659) and differ with respect to the activation loop tyrosine (Y551). In the active structure the activation loop tyrosine is mutated to glutamate (Y551E) to mimic phosphorylated Btk, and for the inactive structure wild type Btk in the unphosphorylated form was used for crystallization[24].  Figure 3 Figure 3 Extension of the regulatory spine within Tec kinases to include the SH2-kinase linker Compared to the regulatory spine that has been defined for PKA[9], the Tec kinase family requires at least two additional residues (Itk W355 & M410) to fully assemble the regulatory spine. The tryptophan residue is located in the SH2-kinase linker region providing an explanation for the positive regulatory role of this non-catalytic region[14]. The available Itk kinase domain structures are entirely consistent with this finding; without the contribution of the SH2-linker region, the regulatory spine of Itk does not assemble into the active conformation. As a result, the structures of the phosphorylated and unphosphorlated Itk kinase domain fragments are very similar to each other and neither resembles an active kinase. Future structures of Tec kinases with and without the SH2-kinase linker in various activation (phosphorylation) states will be required to fully probe this hypothesis.  Itk L420 and Btk L460 are essential for the formation of the extended regulatory spine within full-length Tec kinases  The conserved tryptophan in the SH2-kinase linker is critical for the activity of full-length Tec kinases[14]. Upon activation, the tryptophan side-chain forms part of a hydrophobic pocket that is lined by the conserved methionine on the C-helix and leucine on the \\u03b24 strand (Itk M410, L420 and Btk M450, L460) (Fig. 3d). Although Itk L420 and Btk L460 were shown to not be a part of the regulatory spine in the context of the isolated kinase domain (Fig. 1), the structure of the Btk kinase domain (which contains the SH2-kinase linker region) suggests that this leucine would be critical for the formation of the extended regulatory spine in the context of the full-length kinase. We therefore tested the role of this leucine in the context of full-length Itk.  As shown in Figure 3e, mutation of Itk L420 to alanine within the context of full-length Itk disrupted the activity of Itk. Consistent with our earlier results, mutation of Itk M409, F500 and D539 to alanine within full length Itk also inactivated the kinase. Problems with cloning prevented us from testing the activity of the full-length Itk H479A mutant. Together, Itk M409, L420, H479, F500, D539, M410 and W355 form a conserved allosteric signaling network that is absolutely required for the activity of Itk. Based on sequence conservation, the extended regulatory spine defined here likely controls the activity of the entire Tec kinase family.  Phosphorylation on the activation loop tyrosine is not required for the activity of the Btk T474M mutant  It is well established that activation loop phosphorylation is required for activation of tyrosine kinases[1; 8] and specifically for the Tec kinases, phosphorylation on the activation loop tyrosine results in at least a ten-fold increase in activity[21; 25]. Structures of active and inactive kinase domains from a number of different kinases demonstrate a conserved electrostatic network that switches between the active and inactive conformations (Fig. 4a)[1; 8]. In the inactive state of Btk, the conserved glutamate (Btk E445) on the C-helix (of the Lys-Glu ion pair) is associated with a conserved arginine (Btk R544) on the activation loop[24; 26]. Activation of Btk by phosphorylation on Btk Y551 (the activation loop tyrosine) leads to a specific interaction between pY551 and R544, and a concomitant loss of the association between the R544 and E445[24; 26]. Btk E445 on the C-helix then swings toward the kinase active site and associates with the conserved lysine side chain (Btk K430) to bring about the assembly of the active state of the kinase[24; 26]. The conformational adjustment of the C-helix brings M449 and M450 in line with the other residues of the regulatory spine (Fig. 4a). Thus, phosphorylation on the activation loop tyrosine is an initiating step in the process of regulatory spine assembly.  Figure 4 Figure 4 The regulatory spine is preassembled in the Btk T474M gatekeeper mutant Since mutation of the gatekeeper residue to methioine appears to stabilize the regulatory spine within Btk, we next probed the requirement of activation loop phosphorylation in the context of the T474M gatekeeper mutation. The activity of the BtkT474M/Y551F double mutant was compared to that of the Btk T474M mutant by monitoring phosphorylation of an exogenous substrate. We find that mutation of the activation loop Btk Y551 to phenylalanine has no effect on the activity of the Btk T474M mutant (Fig. 4b & c). The Btk T474M/Y551F double mutant and the Btk T474M single mutant are both active, whereas the wild type Btk kinase requires activation loop phosphorylation; the Btk Y551F single mutant exhibits poor activity (Fig. 4b). These data are consistent with the idea that phosphorylation on the activation loop tyrosine initiates the assembly of the regulatory spine by disrupting the association between Btk E445 and Btk R544. Once pY551 competes with E445 for association with R544, the E445/K430 salt bridge is formed, bringing the C-helix (and importantly M449) into the regulatory spine structure. Under conditions that pre-organize the regulatory spine structure (as in the Btk T474M mutant), phosphorylation on the activation loop Y551 is no longer required to trigger the conformational changes that accompany Btk activation.  We further tested the importance of this switched electrostatic network by mutating Btk R544. We reasoned that mutation of Btk R544 will activate the kinase as inward movement of the C-helix is restrained by the E445:R544 interaction and loss of this electrostatic interaction should facilitate movement of the C-helix. Indeed, mutation of Btk R544 to serine in the context of wild-type isolated kinase domain of Btk leads to a two-fold increase in activity (Fig. 4d & e). In contrast, mutation of Btk R544 to serine in the context of Btk T474M isolated kinase domain does not further activate the kinase (Fig. 4d & e). These results again suggest that pre-assembly of the kinase regulatory spine (by mutation) can overcome the regulatory interactions that normally control kinase activity. Thus, for the wild-type kinase under physiological conditions, phosphorylation on the activation loop sets into motion a cascade of events: (1) formation of the pY551:R544 interaction with concomitant disruption of the Btk E445:R544 interaction, (2) inward movement of the C-helix and formation of the E445:K430 interaction and (3) assembly of the regulatory spine, that culminates in the formation of an active kinase (Fig. 4a).  Go to: DISCUSSION The structures of the isolated kinase domain of Btk in both the active and inactive states have provided significant insight into Tec kinase activation[24; 26]. However, the lack of a full-length structure of any Tec kinase leaves numerous unanswered questions regarding the regulation of Tec kinases. While the SH2 domain and the SH2-kinase linker region of Tec kinases have been shown to be required for the activity of Tec kinases[12; 13; 14], the mechanism by which these regulatory domains positively influence catalytic activity has not been clear. Here we identify an intramolecular allosteric signaling network that extends from the SH2-kinase linker into the kinase domain of Tec kinases. This intramolecular connectivity defines how the non-catalytic Tec regulatory domains, through the SH2-kinase linker region, impinge on the kinase domain and stabilize the regulatory spine. In the absence of the Tec regulatory domains, whether achieved by deletion or conformational changes within the full-length molecule, the regulatory spine is disrupted and kinase activity is inhibited.  Comparing our results to those previously published for PKA shows that the Tec kinases require an extended spine structure and it is this longer regulatory spine that couples kinase activity to regions outside of the kinase domain. Specifically, a conserved methionine in the C-helix and a conserved tryptophan in the SH2-linker swing in to \\u2018cap\\u2019 the spine in the active Btk structure and are critical for the activity of the Tec kinases. Mutation of these extended spine residues disables kinase activity even if the \\u2018core\\u2019 residues defined for PKA are intact.  Further support for the importance of the entire regulatory spine comes from examination of the genetic mutations in Btk that are associated with X-linked agammaglobulinemia (XLA) in humans, a disease that is characterized by impaired B cell development[27]. Several of the extended regulatory spine residues identified in this study are mutated in XLA patients[27]. In addition to nonsense mutations at Btk M449, M450 and W395, which cause premature truncation of the protein, there are also missense mutations at Btk M450, F450 and D579 (M450I, F450S and D579V). These mutations likely destabilize the regulatory spine and prevent Btk kinase activation.  Activation loop tyrosine phosphorylation has long been known to influence kinase activity. In addition to priming the kinase domain for the assembly of the regulatory spine, phosphorylation on the conserved Tyr of the activation loop is also thought to stabilize the substrate-binding site of the activation loop[1]. However, our work has shown that in the context of the activating gatekeeper Btk T474M mutation, loss of Y551 phosphorylation (by mutation to phenylalanine) has no affect on substrate phosphorylation. Pre-assembly of the regulatory spine (mutation of T474M) removes any requirement for activation loop phosphorylation. These results are consistent with earlier studies that focused on phosphorylation of Y551 in Btk[25]. That earlier work did show that phosphorylation on Btk Y551 significantly alters catalytic activity of Btk; kcat of the Btk Y551F mutant is greatly diminished compared to wild-type Btk presumably due to loss of the trigger for regulatory spine assembly. However, the affinity for a peptide substrate is unaffected by Y551 phosphorylation; Km of a peptide substrate for Btk Y551F mutant is the same as wild-type Btk. As well, an alternative direct substrate docking mechanism has been identified for the Tec kinases, in which an SH2 domain within the substrate docks onto the kinase domain outside of the active site and facilitates substrate phosphorylation[28; 29; 30]. It is therefore possible that the peptide substrate-binding region on the activation loop may only play a minor role in substrate recognition in Tec kinases and that activation loop phosphorylation plays one significant role: initiation of spine assembly by altering electrostatic interactions in and around the active site.  We have previously shown that the regulation of Tec family kinases is similar to that of Csk (C-terminal Src kinase)[14]. Unlike the Src and Abl family of kinases, the SH3 and SH2 regulatory domains of Csk and Tec kinases positively influence the catalytic activity of the kinase domain[14; 16]. Like Itk and Btk, the isolated kinase domain of Csk has poor catalytic activity[16; 31; 32]. In order to define the elements within the Csk kinase domain that are responsible for the poor catalytic activity, a mutagenesis study was carried out in which Src:Csk kinase domain chimeras were created[33]. A Src:Csk chimeric kinase domain where the N-terminal lobe of Csk was replaced with the N-terminal lobe of Src was shown to exhibit activity comparable to that of full-length Csk[33]. Further mutagenesis of the N-terminal lobe, identified the C-helix and the \\u03b2 turn between the \\u03b24 and \\u03b25 strands (the \\u2018top\\u2019 of the regulatory spine) as key structural elements that are required for the activity of the isolated kinase domain of Csk[33].  There is remarkable correlation between the elements that are identified in the Csk mutagenesis study and the extended regulatory spine of Tec kinases identified in this study. Since the Csk and Tec family kinases are both positively regulated by domains outside of the kinase domain, it is not surprising that they would share the key determinants of catalytic activity. Indeed, as suggested in the original identification of the kinase regulatory spine[9], this feature likely plays a critical role in all active kinases. Our work confirms this notion for the Tec family kinases, and illustrates that extension of the regulatory spine by two residues couples this regulatory feature to allosteric events occurring outside of the kinase domain. Moreover, our data suggest that despite a high degree of sequence conservation, the five core regulatory spine residues do not assemble into the active conformation in the context of the isolated Itk or Btk kinase domains. The energetics of spine assembly seem to be tailored for each specific regulatory environment; the Tec kinase domains are maintained in their inactive state (spine assembly does not occur even when the activation loop is phosphorylated) until additional regions of the protein (in this case the SH2-linker) are present to drive complete spine assembly forward and fully activate the kinase.\",\n          \"More than 50% of transitional cell carcinomas of the bladder show loss of heterozygosity of a region spanning the TSC1 locus at 9q34 and mutations of TSC1 have been identified in 14.5% of tumours. These comprise nonsense mutations, splicing mutations, small deletions and missense mutations. Missense mutations are only rarely found in the germline in TSC disease. Therefore, we have examined six somatic missense mutations found in bladder cancer to determine whether these result in loss of function. We describe loss of function via distinct mechanisms. Five mutations caused mutually exclusive defects at mRNA and protein levels. Of these, two mutations caused pre-mRNA splicing errors that were predicted to result in premature protein truncation and three resulted in markedly reduced stability of exogenous TSC1 protein. Primary tumours with aberrant TSC1 pre-mRNA splicing were confirmed as negative for TSC1 expression by immunohistochemistry. Expression was also significantly reduced in a tumour with a TSC1 missense mutation resulting in diminished protein half-life. A single TSC1 missense mutation identified in a tumour with retained heterozygosity of the TSC1 region on chromosome 9 caused an apparently TSC2- and mTOR-independent localization defect of the mutant protein. We conclude that although TSC1 missense mutations do not play a major role in causation of TSC disease, they represent a significant proportion of somatic loss of function mutations in bladder cancer.  Go to: INTRODUCTION Tuberous Sclerosis Complex (TSC) is an autosomal dominant tumour suppressor gene syndrome with an incidence of 1 in 6000\\u201310 000 births. TSC is characterized by the development of benign growths, called hamartomas, in the kidneys, heart, brain and skin, and patients present clinically with a variety of developmental disorders (1). TSC is caused by mutations affecting either of the tumour suppressor genes TSC1 or TSC2. TSC1 on chromosome 9q34 encodes hamartin (2) and TSC2 on chromosome 16p13.3 encodes tuberin (3). Approximately half of large TSC families show linkage to 9q34 and half to 16p13.3 (4\\u20136). Tumour development in TSC patients is thought to occur as the result of a somatic \\u2018second-hit\\u2019 in either TSC1 or TSC2, according to Knudson\\u2019s tumour suppressor model (7). Loss of heterozygosity (LOH) of TSC1 or TSC2 has been reported in some TSC hamartomas, such as renal angiomyolipomas. However, loss of the wild-type allele in brain lesions is rare, suggesting the possibility of tissue-specific haploinsufficiency of TSC genes (8\\u201310).  Co-localization and co-immunoprecipitation of TSC1 and TSC2 in mammalian cells (11,12) and direct binding in yeast two-hybrid assays provide a tentative explanation for the similar disease phenotype in TSC patients with mutations in either TSC1 or TSC2 genes (2,13). Functionally, the TSC1/TSC2 complex is positioned at the centre of multiple growth signalling pathways and is a key integrator of signals controlling protein translation and cell growth (14). Activation of the TSC1/TSC2 complex in growth-limiting conditions attenuates signalling through mTOR via specific GTPase activating protein (GAP) activity of TSC2 towards RHEB (15,16).  While epithelial malignancy is not a common feature of TSC, studies in this laboratory and others have implicated loss of function of TSC1 in bladder tumorigenesis (17\\u201319). Loss of heterozygosity (LOH) for markers on chromosome 9 is observed in more than 50% of bladder tumours of all grades and stages (20) and sub-chromosomal LOH analyses have identified the TSC1 locus at 9q34 as a common critical region of deletion between markers D9S149 and D9S66 (19,21\\u201323). To date, we have screened 154 bladder tumours by fluorescent single strand conformation polymorphism (F-SSCP) analysis and direct sequencing, and found an overall mutation frequency of 14.5%. The mutation spectrum comprises nonsense (35%), missense (26%), frameshift (26%), in-frame deletions (3%) and splicing (10%) mutations (24) (Platt et al., in preparation). In all cases but one, TSC1 missense mutations were tumour-specific somatic events. TSC1 is the only gene on 9q that has been found to be mutated in bladder tumours, and may therefore be the critical gene on this chromosome arm implicated in >50% of all bladder tumours.  Missense mutations of TSC1 have not routinely been confirmed as functionally inactivating in TSC disease, though two recent reports provide evidence that in a few cases these are likely to be disease-causing (25,26). Here we sought to determine whether the TSC1 missense mutations identified in bladder tumours constituted inactivating mutations. We anticipated that discrete amino acid changes of mutant proteins might allow the identification of functionally important residues. Wild-type and mutant TSC1 constructs were retrovirally delivered into TSC1-null bladder tumour cell lines and functionally characterized. All somatic TSC1 missense mutations perturbed TSC1 function by causing aberrant splicing, protein instability or protein mislocalization. Defects were confirmed in primary tumours by RT\\u2013PCR analysis of mutant transcripts and immunohistochemical analysis.  Go to: RESULTS Missense mutations of TSC1 identified in bladder tumours  Previously, we identified 8 mutations including 2 missense mutations in a series of 62 bladder tumours (24). Screening of an additional 92 tumours (Platt et al., in preparation) identified an additional 15 mutations of which 4 were missense mutations. In total, therefore, 6 missense mutations have been identified in 154 tumours, representing 26% of all mutations found (Table 1). Mutations were determined as tumour-specific by genotyping of paired tumour and blood samples. 1250C>T (Thr417Ile) was previously described in the germline in TSC disease in Japanese patients, but was not confirmed as causative of TSC (27,28). 1250C>T was also identified in our laboratory in the patient\\u2019s constitutional DNA, and the tumour sample retained heterozygosity for microsatellite markers at the TSC1 gene locus (24). Threonine 417 was previously identified as a site of CDK1-dependent phosphorylation (29). To determine the biological significance of this variant, 1250C>T (Thr417Ile) was characterized here alongside tumour-specific missense mutations. Five of six other tumours with TSC1 missense mutations showed LOH for markers at the TSC1 locus (Table 1). There was no relationship between mutation and tumour stage or grade. Missense mutations were predominantly N-terminal but did not localize to a common functional domain (Fig. 1).  Figure 1. Figure 1. Positions of amino acid substitutions in relation to described functional domains of hamartin. Table 1. Table 1. TSC1 missense variants identified in bladder tumours To assess possible functional implications of amino acid substitutions, conservation of missense mutant residues was determined in TSC1 orthologs. His68, Phe158 and Phe216 were conserved among Rattus, Mus, Drosophila, Fugu and Gallus orthologs. His105, His206 and Thr417 differed only in Drosophila, which shares 31% identity with human TSC1. Ser35 differed in Drosophila, Fugu and Gallus orthologs. According to the BLOSUM62 scoring matrix (30), His68Arg and His105Arg substitutions are considered conservative. Ser35Cys, His206Asp and Thr417Ile are less conservative and Phe158Cys and Phe216Asp are least conservative (Table 1).  Re-expression of missense mutant TSC1 proteins in TSC1-null urothelial cells  We anticipated that missense mutations might lead to loss of function at the amino acid level. Thus, our initial approach was to express wild-type and missense mutant TSC1 cDNAs in TSC1-null bladder cell lines and investigate function of the mutant proteins. Missense mutant proteins were C-terminally FLAG- or GFP-tagged, expressed in 97-1 and HCV29 cells and characterized for TSC2 binding activity, and mTOR suppressive activity in nutrient-starved conditions.  Expression of mutant proteins was investigated by immunoblotting following retroviral transduction and selection of neomycin resistant mass cell populations. Expression levels of mutant proteins were markedly different; Ser35Cys, His105Arg, Phe216Asp and Thr417Ile were expressed at high levels similar to wild-type protein, whereas His68Arg and Phe158Cys were much reduced and His206Asp was not detected (Fig. 2A). Repeated independent infections of these two cell lines and of telomerase-immortalized normal human urothelial cells (TERT-NHUC) and assessment of mass populations of cells following selection resulted in entirely reproducible expression levels of all mutant proteins (data not shown). The transcription of missense RNA was confirmed by real time RT\\u2013PCR and uniform levels of wild-type and missense transcripts were detected (Fig. 2B). The consistently reduced or absent protein expression of His68Arg and Phe158Cys and His206Asp missense mutant forms despite the presence of RNA expression suggested possible effects of these missense changes on protein stability.  Figure 2. Figure 2. (A) Immunoblot showing levels of wild-type and mutant TSC1-FLAG proteins and endogenous TSC2 in 97-1 cell lines. (B) Measurement of TSC1 RNA levels by real time RT\\u2013PCR analysis of wild-type and mutant TSC1-FLAG mRNA transcript levels in 97-1 cell ... Mutant TSC1 proteins retain interaction with TSC2  The interaction between TSC1 and TSC2 appears to be important in maintaining the stability of each of the proteins. TSC1/TSC2 binding specifically augments TSC2 expression by limiting its ubiquitination (31,32). TSC2 GAP activity towards RHEB defines TSC1/2 mediated control of mTOR signalling, and phosphorylation of downstream effectors of mTOR is constitutive and refractory to amino acid withdrawal in cells lacking TSC1 or TSC2 (33\\u201335). Where expressed, missense mutant TSC1 proteins stabilized TSC2 levels in 97-1 cells (Fig. 2A) and co-immunoprecipitated with it (Fig. 3A). However, our data cannot exclude minor effects on interaction or TSC2 stability.  Figure 3. Figure 3. (A) Immunoblot showing TSC1 and TSC2 in 97-1 Neo control and FLAG-tagged wild-type and mutant TSC1 cell line lysates immunoprecipitated with anti-TSC1 and non-specific mouse IgM antibodies. (B) Immunoblot showing expression levels of GFP-tagged wild-type ... While His206Asp-FLAG was undetected in transduced 97-1 cells, we were able to achieve low-level expression of His206Asp-GFP in HCV29 cells, suggesting some stabilizing effect of the GFP tag. TSC2 co-immunoprecipitation and S6 phosphorylation assays were not accurately quantitative, but expression of all missense mutant proteins in TSC1-null cells reduced S6 phosphorylation in amino acid starved conditions, relative to vector alone (Fig. 3B), indicating that none of these mutant forms of TSC1 abolish interaction with TSC2.  Aberrant RNA splicing caused by TSC1 missense mutations  High-level expression and TSC2 binding activity of TSC1 Ser35Cys, His105Arg and Phe216Ala proteins suggested no functional effect of amino acid substitutions caused by 104C>G, 314A>G and 648T>A missense mutations. However, the expression of proteins from exogenous missense cDNAs did not allow the assessment of possible effects of mutations at the pre-mRNA level. We speculated that TSC1 missense mutations may cause loss of function through introduction of splicing errors in mutant transcripts in vivo. Therefore, wild-type and missense mutant TSC1 pre-mRNA sequences were screened for effects of mutations on splice site definition using the neural network algorithm (http://www.fruitfly.org/seq_tools/splice.html).  Interestingly, significant differences were seen between splice site scores of wild-type and 104C>G and 314A>G TSC1 transcripts. The 104C>G mutation, positioned 3 bp upstream of the TSC1 exon 3/4 junction, resulted in a reduced exon 3/4 splice motif score. The 314A>G mutation resulted in the introduction of a high-scoring 5\\u2032 donor splice site, immediately upstream of the A/G transversion, by generation of a novel consensus splice motif. No differences in splice site scores were observed between wild-type and 648T>A or 1250C>T transcripts or between wild-type and mutant transcripts that generated low exogenous protein expression.  To examine splicing of missense mutant TSC1 transcripts, fragments spanning the mutation site and flanking intron/exon junctions were amplified from respective tumour cDNAs by RT\\u2013PCR and sequenced. An RT\\u2013PCR product reproducibly amplified from cDNA of the tumour containing 104C>G showed increased electrophoretic mobility relative to a control fragment amplified from TERT-NHUC cDNA (Fig. 4A). Sequencing of the tumour product revealed use of a cryptic 5\\u2032 donor site in exon 4, the adjacent downstream exon to the 104C>G mutant exon (Supplementary Material, Fig. S1). The reduced splice motif score at the exon 3/4 junction was shown to have no effect on exon 3/4 splicing. If translated, this 104C>G mutant transcript would generate 26 new amino acids from an alternate reading frame and truncate prematurely at residue 79.  Figure 4. Figure 4. Semi quantitative RT\\u2013PCR analysis of TSC1 RNA in normal urothelial cells and TSC1 mutant tumour samples, showing increased electrophoretic mobility of RT\\u2013PCR products amplified from cDNA from tumours containing TSC1 104C>G (A) ... A faster migrating band was also reproducibly amplified from cDNA of the tumour containing 314A>G (Fig. 4B), compared to control TERT-NHUC cDNA. Sequence analysis of PCR products revealed a 50-nucleotide deletion in the transcript generated from the missense allele. The 314A>G mutation created a de novo 5\\u2032 donor splice site immediately upstream of 314A>G and resulted in the splicing of 50 nucleotides from the 3\\u2032 end of exon 5. The effect seen at the mRNA level was entirely consistent with the prediction made by in silico analysis. If translated, the 314A>G mutant transcript is expected to generate two new C-terminal amino acids and truncate prematurely at residue 107.  Exon skipping through introduction of a de novo 5\\u2032 splice site by point mutation is a relatively well-described mechanism of aberrant pre-mRNA splicing (36\\u201338). No normal transcript was amplified from cDNA from tumours containing TSC1 104C>G or 314A>G mutations, suggesting that all splicing occurs via the novel sites. The abundance of missense transcripts appeared lower than normal transcript by semi-quantitative RT\\u2013PCR, when standardized to HPRT. However, by real time RT\\u2013PCR, TSC1 transcript abundance was relatively higher in tumours with TSC1 missense mutations causing transcript splicing or protein stability defects, than in uncultured or cultured TERT-NHUC, when standardized to SDHA (data not shown).  Missense mutant TSC1 proteins exhibit reduced protein stability  The demonstration of consistently low-level exogenous protein expression, despite uniform mRNA transcript abundance, suggested diminished stability of TSC1 His68Arg, Phe158Cys and His206Asp mutant proteins. By inhibiting protein synthesis with cycloheximide, we determined that His68Arg, Phe158Cys and His206Asp mutant proteins were turned-over relatively faster than wild-type TSC1, in a proteasome-dependent manner (Fig. 5 A and B and data not shown). Moreover, by 35S labelling, we were able to show that His68Arg, Phe158Cys and His206Asp proteins had markedly shorter half-lives than wild-type TSC1 (Fig. 5C).  Figure 5. Figure 5. (A) Immunoblot showing turnover of wild-type and S35C and H68R missense TSC1 proteins in cycloheximide (CHX)-treated cells. Cells were cultured in full growth medium supplemented with 100 \\u00b5g/ml CHX or DMSO vehicle alone, and lysed at time-points ... Phe216Ala TSC1 protein shows altered localization  Previous studies have described a granular, cytoplasmic localization of endogenous TSC1 in vitro and in vivo and also of overexpressed TSC1 in COS-7 cells (39\\u201341). Localization of monomeric TSC1 and of TSC1 complexed with TSC2 is likely influenced by culture conditions given that components of the Akt-mTOR signalling cascade are membrane localized when activated. In addition, TSC2 is reported to shuttle into the nucleus in a cell cycle and phosphorylation-dependent manner (42\\u201344).  It was anticipated that the characterization of discrete missense amino acid changes may offer insight into potentially mTOR-independent or bladder-specific functions of TSC1. Our results indicated that TSC1 104C>G, 203A>G, 314A>G, 473T>G and 616C>G missense mutations cause loss of function by generic mechanisms of altered message or reduced protein stability. However, sequencing of RT\\u2013PCR products amplified from cDNA from the tumour containing the TSC1 648T>A mutation showed no altered splicing of the mutant transcript. Also, at the protein level, Phe216Ala was expressed at high levels similar to wild-type TSC1. The substitution of a phenylalanine residue for an alanine residue constitutes the loss of a high-molecular weight, hydrophobic benzyl group and is assigned a non-conservative \\u20132 BLOSUM62 score. The lack of effect on splicing or protein stability raised the possibility that this mutation may cause a defect in TSC1 protein function per se.  We determined the localization of GFP-tagged mutant proteins in nutrient replete and deficient conditions. Wild-type, Phe216Ala, Ser35Cys, His68Arg and Thr417Ile proteins were compared. In complete growth medium, wild-type TSC1 and Ser35Cys, His68Arg and Thr417Ile mutant proteins showed diffuse punctate cytoplasmic distribution with distinct cytoplasmic foci. In amino acid deficient medium, these proteins became localized almost exclusively to large cytoplasmic bodies. Intriguingly, the Phe216Ala substitution markedly altered the localization of TSC1; Phe216Ala was exclusively cytoplasmic and diffuse in full growth medium and did not redistribute to discrete bodies in amino acid deficient conditions (Fig. 6). However, it was shown to stabilize and to co-immunoprecipitate with endogenous TSC2, and to attenuate growth signalling through mTOR in starved conditions (Fig. 3B). These observations were reproduced in TSC1-transduced 97-1 and HCV29 cell lines and TERT-NHUC and suggest that localization of TSC1 to cytoplasmic foci is not a requirement for TSC2 binding or negative regulation of mTOR. Also, defective localization of Phe216Ala is likely TSC2- and mTOR-independent, possibly suggesting an independent function of TSC1 at cytoplasmic foci.  Figure 6. Figure 6. Localization of wild-type TSC1 (A) and TSC1 Ser35Cys (B), Phe216Ala (C) and Thr417Ile (D) mutant proteins in amino acid-starved 97-1 cells. Cells were cultured in full growth medium on highly optically clear microscopy dishes to sub-confluence and amino ... Unlike the other five tumours with missense mutations, the tumour containing the TSC1 648T>A mutation did not show LOH of 9q, as confirmed by analysis of pure microdissected tumour cell populations (data not shown). Both normal and mutant alleles were detected by sequencing of tumour cDNA.  TSC1 protein expression in bladder tumour tissues  To examine the effects of pre-mRNA splicing defects and protein stability defects caused by missense mutations at the tumour level, TSC1 mutant and wild-type tumours were screened for expression of TSC1 protein by immunohistochemistry. Sensitivity and specificity of a rabbit monoclonal anti-TSC1 antibody was confirmed by staining of paraffin-embedded pellets of TSC1-null HCV29 cells and HCV29 in which wild-type TSC1 had been re-expressed (Fig. 7A and D). Normal ureter showed strong cytoplasmic TSC1 expression in the urothelium (Fig. 7E). Tumours with wild-type TSC1 showed strong cytoplasmic staining (Fig. 7F), and a tumour with a TSC1 73\\u201377\\u0394 5 small deletion causing premature truncation at residue 27, showed no TSC1 expression (Fig. 7C). Both tumours with homozygous TSC1 missense mutations causing pre-mRNA splicing defects were negative for TSC1 expression (Fig. 7G and H). Figure 7H shows normal urothelium with strong TSC1 staining adjacent to immunonegative TSC1 314A>G mutant tumour cells. The 648T>A (Phe216Ala) mutant tumour showed moderate TSC1 expression consistent with normal stability of the Phe216Ala protein and retention of chromosome 9q heterozygosity in the tumour (Fig. 7I). Of the three missense mutations causing reduced protein stability (TSC1 203A>G, 473T>G and 616C>G), tumour material was available only for the 616C>G (His206Asp) mutant sample. The 616C>G mutation was identified from tumour material resected in 2003, and TSC1 expression was shown to be low in three tumour resections from this patient in successive years (Fig. 7J\\u2013L).  Figure 7. Figure 7. TSC1 immunostaining of HCV29 Neo (A) and TSC1 (D) cell pellets, normal ureter (negative (B) and positive (E) antibody controls) and TSC1 73\\u201377\\u0394 5 (C) and TSC1 wild-type (F) bladder tumours. TSC1 staining of TSC1 missense mutant bladder ... Go to: DISCUSSION We have demonstrated that bladder tumour-derived TSC1 missense mutations result in loss of TSC1 function and that this occurs via distinct mechanisms. An overall TSC1 mutation frequency of \\u223c14.5% is found in bladder cancer (24) (Platt et al., in preparation) and missense mutations comprise 26% of mutations found to date. The identification of deleterious missense mutations in bladder tumours indicates a causative role of loss of TSC1 function via this mechanism in bladder tumorigenesis. The vast majority of TSC1 mutations in TSC disease are predicted to be protein truncating in nature, and no significant genotype/phenotype correlations have been observed (2,5,45\\u201348). Non-chain terminating TSC1 mutations (missense or in-frame deletions) are rare in TSC disease (27,47,49,50) (www.LOVD.nl/TSC1). Although missense mutations have been reported previously, most have not been confirmed as disease-causing. Several have been revealed as rare polymorphisms or associated with other nonsense mutations in the same patient (46,50). Others have been disregarded as potentially disease-causing on the basis of conservative amino acid changes, or have not been characterized further (27,51). However, a recent publication by Jansen et al. (26) that identified three missense mutations (L916R, M224R and E412V) in affected individuals reported functional analyses on two of these. It was reported that E412V affected RNA splicing. Interestingly, in transfections of constructs of wild-type TSC1 and the M224R variant, the latter showed lower levels of protein expression that were unable to completely suppress S6 phosphorylation, results similar to those described here for missense variants with reduced protein half-life.  We have shown that two of six bladder tumour-derived missense mutations result in pre-mRNA splicing defects, three lead to reduced stability of mutant proteins and intriguingly, one mutation causes a TSC2- and mTOR-independent localization defect of the mutant protein. Wild-type TSC1 showed a granular cytoplasmic distribution in cells in full growth medium and became localized almost exclusively to large cytoplasmic bodies in amino acid starved cells. In contrast, TSC1 was cytoplasmic and diffuse in serum-starved cells. Preliminary results indicated that TSC1 bodies were dynamic, non-aggresomal structures (data not shown). Interestingly, the Phe216Ala substitution abolished the localization of TSC1 to these bodies. As expected from its position outside the recognized TSC2 binding domain, TSC1 Phe216Ala retained TSC2 binding activity and mTOR suppressive activity in amino acid starved conditions, suggesting that localization of TSC1 to cytoplasmic foci was not a requirement for TSC2 binding or for suppression of mTOR signalling. This may also suggest that TSC1 has a separable function at cytoplasmic foci that is independent of TSC2 and independent of negative regulation of mTOR by TSC1/TSC2. However, it is not clear whether the formation of intensely staining bodies in conditions of over-expression of TSC1 and/or TSC2 (39,52) is relevant to the normal physiological condition. Further investigation of the function of Phe216Ala is now required, ideally at levels of expression that are closer to normal and in both TSC1-null cells and those expressing endogenous wild-type TSC1.  Although the missense variant 1250C>T (T417I) was found in the patient\\u2019s germline and this patient showed no symptoms of TSC, we included this variant in our analyses as threonine 417 has previously been identified as a site of CDK1-dependent phosphorylation (29). We found no evidence for a functional defect and conclude that this represents a rare polymorphism. As this patient was Japanese, as were both TSC patients in whom this variant was reported previously (27,28), this rare variant may be confined to the Japanese population.  Evidence suggests that cis-acting mutations affecting splicing of some tumour suppressor genes can have causal roles in tumour initiation and progression (53). Predicted and confirmed effects of TSC-related and bladder tumour-derived TSC1 missense changes on pre-mRNA splicing reported here underscore the importance of using RNA-based techniques, together with conventional mutation detection methods, to effectively identify disease-causing mutations. One of the mutations that deleteriously affected splicing (104C>G) had an unexpected effect. The use of a cryptic 5\\u2032 donor site in an adjacent downstream exon is a non-conventional splicing event; disease-associated mutations at splice junctions typically result in skipping of the mutant exon (38,54,55). The 104C>G mutation was shown to reduce the exon 3 5\\u2032 splice site motif score and to disrupt an enhancer sequence spanning exon 3/4. 104C>G also disrupts a U1 snRNA-binding motif, spanning the 5\\u2032 splice site from position \\u20133 to +8 (Supplementary Material, Fig. S1). In combination with a normally low-scoring exon 4 3\\u2032 acceptor site, these factors may result in reduced splicing efficiency of introns 3\\u20134. Spliceosome assembly is directed by juxtaposed splicing elements, and were introns 4\\u20135 to splice first, splicing machinery at the 3\\u2032 acceptor site of exon 4 may stimulate recruitment of U1 snRNA to possible binding sites in exon 4, and result in use of a cryptic 5\\u2032 donor site.  In bladder tumours as in TSC disease, nonsense, deletion and frameshift TSC1 mutations result in premature protein truncation and loss of protein function. We have now shown that missense mutations cause loss of function by aberrant splicing or reduced protein stability. The identification of tumour-specific TSC1 mutations in the context of chromosome 9 LOH argues strongly for a direct role of loss of TSC1 function in the aetiology of these tumours. These data are consistent with TSC1 acting as a tumour suppressor gene in bladder cancer in accordance with Knudsen\\u2019s two-hit hypothesis. Biallelic inactivation of TSC1 or TSC2 may not be necessarily required in some TSC-related tumours (9). The discrepancy between frequency of TSC1 mutation and frequency of LOH in the TSC1 gene region in bladder tumours suggests that haploinsufficiency of TSC1 may contribute to tumour development in some cases. LOH of chromosome 9 is a particularly frequent event in bladder cancer and to date, TSC1 is the only gene on 9q found to be mutated in bladder tumours. The contribution of partial loss of TSC1 to clonal expansion of tumour cells with 9q LOH is unknown, and haploinsufficiency remains a possibility in those bladder tumours with 9q LOH and no TSC1 mutation. LOH at the TSC1 locus may accompany another event driving loss of chromosome 9. Deletion of the CDKN2A locus at 9p21, which occurs in up to 50% of bladder tumours (56,57), or of an as yet unidentified chromosome 9 tumour suppressor gene, may constitute such a driving force. Loss of one copy of TSC1 may therefore be an advantageous gratuitous hit or \\u2018passenger event\\u2019 (58).  TSC is not a cancer prone syndrome and TSC lesions very rarely progress to malignancy. That TSC patients do not have an increased risk of developing bladder cancer, or other sporadic cancers, may be explained by the requirement of cumulative genetic insults and the typically late onset of malignant disease. The timing and order of initiating and subsequent genetic events in hamartoma and bladder tumour development is likely to be critical in determining malignant potential. Why TSC1 appears to be involved in bladder cancer and not other epithelial cancers is an unresolved question.  Frequent LOH of 9q is found in other tumour types, including ovarian carcinoma, gallbladder carcinoma, nasopharyngeal carcinoma and non-small cell lung cancer (59\\u201365). However, reports of TSC1 and TSC2 mutation status in sporadic tumours other than bladder are very few. No mutations were observed in sporadic glial and glioneuronal tumours or renal cell carcinomas (66,67). Fifty-three and 39% of lung adenocarcinomas and precursor lesions, respectively, were found to have LOH of 9q (68). Subsequently, a screen of 47 lung adenocarcinomas identified three confirmed TSC1 mutations. However, LOH and mutations were not detected simultaneously (69).  In ovarian carcinoma, gallbladder carcinoma, nasopharyngeal carcinoma and lung adenocarcinoma, LOH or deletion is described in both TSC gene regions (63,68,70,71). If loss of TSC1/2 complex function is the pathogenic effect of loss of TSC1, it may be expected that bladder tumours would also show loss of TSC2 function. In an LOH screen of 16p, we have detected LOH for markers at the TSC2 locus in 16% of bladder tumours (Platt et al., in preparation). It will be important to screen for mutations in the retained copy of TSC2 in cases with LOH to determine whether there is also an involvement of TSC2 or whether there is an important independent role of TSC1 in urothelial cells.  Abstract We have surveyed the mutations of TSC1 and TSC2 from 38 (25 sporadic, 11 familial, and 2 unknown) Japanese patients with tuberous sclerosis complex. In 23 of 38 subjects, we detected 18 new mutations in addition to 4 mutations that had been previously reported. We also found 3 new polymorphisms. The mutations were not clustered on a particular exon in either of the genes. Seven TSC1 mutations found in 3 familial and 4 sporadic cases were on the exons (3 missense, 2 nonsense point mutations, a 1-base insertion, and a 2-bp deletion). Fifteen TSC2 mutations were found in 5 familial cases, 10 sporadic cases, and 1 unknown case. The 12 mutations were on the exons (8 missense, 1 nonsense point mutations, a 1-bp insertion, a 5- bp deletion, and a 4-bp replacement) and 3 point mutations were on the exon\\u2013intron junctions. Although the patients with TSC2 mutations tend to exhibit relatively severe mental retardation in comparison to those with TSC1 mutations, a genotype\\u2013phenotype correlation could not yet be established. The widespread distribution of TSC1/TSC2 mutations hinders the development of a simple diagnostic test, and the identification of individual mutations does not provide the prediction of prognosis. Key words Tuberous sclerosis complex \\u2022 TSC1 gene \\u2022 TSC2 gene \\u2022 Hamartin \\u2022 Tuberin \\u2022 Mutation Introduction Tuberous sclerosis complex (TSC) is an autosomal dominant disease with an estimated prevalence of 1 in 10,000 in the Caucasian population and 1 in 31,000 in the Japanese population (Ohno et al. 1981; Gomez 1988). Multiple organs are affected in TSC, including the central nervous system (mental retardation, epilepsy), skin (facial angiofibroma, shagreen patches, hypopigmented macules, periungual fibromas), heart (cardiac rhabdomyomas), and kidney (cysts, angiomyolipoma). There are two causative genes of TSC. The TSC1 (hamartin) is located on 9q34 and consists of 23 exons. The TSC2 (tuberin) is located on 16p13.3 and consists of 41 exons (European Chromosome 16 Tuberous Sclerosis Consortium 1993; Van Slegtenhorst et al. 1997). Loss of heterozygosity (LOH) of either TSC1 or TSC2 in the affected tissues indicates that both act as a tumor suppressor (Green et al. 1994; Henske et al. 1995, 1996; Sepp et al. 1996). Multiple isotypes of tuberin are generated by alternative splicing at two different exons (exon 25 and 31) of TSC2 (Xiao et al. 1997). Since the identification of the TSC1/ TSC2 genes, the mutations in Caucasian TSC patients have been extensively surveyed (Kumar et al. 1995 a,b; Vrtel et al. 1996; Wilson et al. 1996; Bajek et al. 1997; Jones et al. 1997; Maheshwar et al. 1997; Van Slegtenhorst et al. 1997; Au et al. 1997, 1998). The mutations in Japanese TSC patients, however, have remained unknown. In the present study, we surveyed the mutations in Japanese patients and assessed the relationship between the mutations and clinical symptoms. Materials and methods Patients and sample collection Thirty-eight (25 sporadic, 11 familial, and 2 unknown) Japanese TSC patients were clinically diagnosed according to the criteria (Gomez 1988). In some cases, ultrasound renogra392 phy, MRI, and CT brain scan gave supportive evidence for the diagnosis. Genomic DNAs were prepared from the blood samples as described (Nanba et al. 1995). Healthy Japanese volunteer DNA as normal controls were extracted by the Nucleic Acid Purification System (MagExtractor MFX-2000; Toyobo, Osaka, Japan) from 100\\u00edl blood. Polymerase chain reaction-single strand conformation polymorphism (PCR-SSCP) analysis All coding exons of TSC1 and TSC2 were analyzed for every patient. Sets of PCR primers for the 41 exons of TSC2 were designed based on the TSC2 sequence, except for the primers for exon 13 and 25, which were kindly obtained by Dr. J.R. Sampson at the University of Wales, Cardiff, UK (Maheshwar et al. 1996) (Table 1). The primer information for the 21 coding exons of the TSC1 gene was obtained from Dr. O Hino in the Department of Experimental Pathology, Cancer Institute, Tokyo, Japan, and Dr. D.J. Kwiatkowski in Brigham and Womens\\u2019 Hospital, Boston, USA, except for the primers for exon 9 (CACTGAGTTGACACTCTGAAG and CTGAACTAAGTCTTACTCCAG), which were originally designed. PCR contained 25ng of the genomic DNA as a template, 10pmol of each primer, 0.25\\u00edM of each dNTP, 0.1 unit of Ampli Taq Gold (Perkin-Elmer, Norwalk, CT, USA), and a buffer in a total volume of 5\\u00edl. Cycling conditions were as follows: an initial denaturation at 95\\u00b0C for 10 min followed by 30 cycles of denaturation at 95\\u00b0C for 1 min, annealing at 65\\u00b0C for 1min and elongation at 72\\u00b0C for 1min, with a final extension at 72\\u00b0C for 5min. All the PCR products were analyzed on 1.5% agarose gel. SSCP analysis was performed as described (Orita et al. 1989; Yuasa et al. 1997). Using a minigel (10 3 10 cm), the samples were analyzed under four different electrophoresis conditions, in a combination of two sets of gel mixtures (12% polyacrylamide gel with or without 5% glycerol) and two temperature conditions (4\\u00b0C or 22\\u00b0C). Table 1. Primers for TSC2 gene analysis Exon Product size (bp) 1 F: AAGGTTATGCCCACCAGAGA; R: AGACACAGGTAGCTCACTCA 296 2 F: CACTGGCCCCTTTTTCTTCT; R: CTCTAGTAGCTCAACTGGAT 150 3 F: CTTGGAGAGCACATCCTCAC; R: CAGCCTGACGTCACCCATCC 195 4 F: CTGATCCTGTGGCTTTTGTC; R: AGAAACCTCCAACCCAAGGT 199 5 F: TCGCAAACTGCGCGACTTCT; R: CAGAACAGGATCTCAATTCT 173 6 F: GACTGAGCTCGGTGCTCCCT; R: TGAAATGGGCCGGCCCTGGG 109 7 F: GAAGGAGGTGGGAAGGAAG; R: CATCCATGTGCTCTCAGGAA 278 8 F: CTTTGGGAGGAGATGGTGG; R: ATGTGTGCGTTGGTAAGGGA 286 9 F: CGTCTCTCTGGGGAACACTT; R: TCACTGCACACAGAAACCGC 176 10 F: TGCTGGCCGGGCTCGTGTTC; R: TGCTCCCCGGAGCTCCTGCC 198 11 F: GCCTGTGTCATCGTGCCTGG; R: AAAGGCCCCACCCAGGAGGG 194 12 F: CAACACCGGCTCTTCTTTTG; R: AGGCAAGGCTACAGAGGACC 153 13a F: GGGCTGTGGCGGGCACTC; R: AGAGGTCCGGCAGACCGAAGTC 245 14 F: TTGGCCTCCCTTGTGCCTGT; R: GCCCCGGGTACAACGGCTCT 203 15 F: GACTCAGAACCATGAGCCTG; R: AACAGACTCCAACACAACGC 251 16 F: CGTGGTGAGCTGCGTCCTCT; R: ACTGCGTGCGCAACCCCAGC 178 17 F: GGCTTTCACCATCCTCTTCC; R: TCATGGGCCGTGGGCAGGTC 160 18 F: GCCTCAGCTGCTTCTCTTGC; R: AACGTGGGACGGATGGTCCC 216 19 F: CCTGACGCCTCCTCTCCTCG; R: CCCAACCCCAGGCCGGCATG 185 20 F: TCATGCCTGGATTTGGTCAT; R: TCAAGCTCGCCTGCTCTGAC 187 21 F: GGGCCTGAGGTGTCCTGTCT; R: AGGTGCAGTGCTGCAGGGCG 246 22 F: GGCTCCCTGACCACCTCTCC; R: ACAGGGCCTGGGGCGACCAC 148 23 F: GTGCCAGCCCCCTTCTCATC; R: ACAGCCTTCACCGCCCTGAG 152 24 F: TCACTGTCTGGGTGTGCTC; R: TGCCCTGCCTCACATACTC 260 25a F: CCCTCCACTGGCTTGTTCTCC; R: CGGGCAAGACGATGAGGTCAT \\u2014b 26 F: CCTGGTCACGGCCTCTCCCT; R: CCAGCCCTGTAGTGCCGCCT 213 27 F: GGTTTCACGCTCCCTGTCTT; R: GGAGGAAAGGAAGGTGCAGT 200 28 F: ACCCTGTGCGTGGGATTCTC; R: AGGTGGCTGGGGCCAAGGCT 163 29 F: CCTCATGCCCGTCTTCTTC; R: AGATGGCGCTCAGGCCAC 267 30 F: AAGGTAGTCTGCCGCCTCCG; R: CCAAGGCCCGCCATGCCACT 251 31 F: CGTCGACACGGCCTTCCCTT; R: ACCGCTTCCCTCTGAGAGGC 118 32 F: AGCAGCCCCGTCTGTGTCCT; R: GTCCAGGCTCTGAGCCACAC 171 33 1F: CTCTTTGGGATGGTCCTTTC; 1R: CTGTGACCGGGCCTTAACCT 275 33 2F: CCTGGGGACAAGGCCGACGT; 2R: CCCGCCCGGAAGCAAGAGGC 317 34 F: CCACCATCCCCTCCCTGT; R: TAGCCAGAGCCCTCTGCAA 206 35 F: CTCTGGCTAAGCTCCCTGT; R: TGAGCACTTCATGCTGTAGG 326 36 F: GGGAGTGATGCCACCCTG; R: ATGGGAGCCGTGCCCTGA \\u2014b 37 F: CATCCGGCCCTGCTCACCCT; R: GCCTCACTGACGGCCCTCAC 187 38 F: TGACCCTTTCTCTTGTCCGG; R: TCTGCACTGCAGCCCCACCC 131 39,40 F: TGGCGTGACCACCAAGTCTC; R: GCTGAGGAGCCCCATATTCC 325 41 F: CAGACTTACTGCCCAAGCCGCCT; R: CCCCGCACCAAGCAGACAAA 342 a Data were kindly provided by Dr. J.R. Sampson (University of Wales, UK) b The exact sizes of the PCR products were not known 393 Sequencing Variant bands were reamplified and subcloned into pGEMT Vector (Promega, Madison, WI, USA). The DNA sequences were determined using the Thermo Sequenase Fluorescent Labeled Primer Cycle Sequencing Kit (Amersham, Buckinghamshire, England) with Cy-5-labeled M13 universal or reversal primers and ALFred Automatic Sequencer (Pharmacia Biotech, Tokyo, Japan). At least ten independent clones of each PCR product were sequenced in both directions. The sequence data were analyzed by Genetyx computer software (Software Development, Tokyo, Japan). Results SSCP analysis A total of 25 variants were detected by SSCP analysis (Fig. 1) from 23 patients (60% of the total 38 patients). Seven variants of TSC1 gene were detected in 3 familial cases and 4 sporadic ones. Fifteen variants of TSC2 gene were detected in 5 familial cases, 10 sporadic cases, and one unknown case. L574L of TSC1 and I531I of TSC2 genes were considered to be polymorphisms because the point mutations did not cause amino acid substitution. M322T of TSC1 was detected in the normal controls (6 of 80) and was supposed to represent a polymorphism (Table 2A). All other missense mutations were not detected in 60 or 100 normal controls. Any DNA sample from the parents was not available except for P28. Mutations in TSC1 gene Two nonsense, two frame shift, and three missense mutations were located in various exons of the gene. Two mutations (R509X, Q654E) in three patients were located in exon 15, and the R509X was found both in a sporadic patient (P26) and a familial patient (P3). Two mutations (W676X and T417I) were found in one patient (P31). Mutations in TSC2 gene One nonsense, 3 frame shift, and 8 missense mutations were identified in 16 patients (Table 2B). The two single nucleotide substitutions (2760 1 1 G to A, 5179 2 1 G to T) of an exon\\u2013intron junction were predicted to cause a splicing error. Although a substitution (5178 1 5 G to A) in the intron was not in the consensus sequence of the splicing, the mutation was located 5bp distant from the exon and was not detected in 100 normal controls. The mutation might cause a splicing error. L717R in a patient with pulmonary tuberous sclerosis was reported previously (Zhan et al. 1999). Both the V769E mutation (P2 and P21) and R1459X mutation (P6 and P8) were detected in 2 unrelated sporadic patients. Two missense mutations (H137R and D647N) Fig. 1. PCR-SSCP analysis of the TSC1/TSC2 genes. Arrows indicate the aberrant bands found in the patients\\u2019 samples. C, control samples from healthy subjects; P, patients\\u2019 samples 394 were found in the same patient (P32). P1657L in P28 was confirmed to be a de novo mutation by examination of the parents\\u2019 samples. Clinical symptoms and mutation types The clinical symptoms and the gene mutations are summarized in Table 3. The number of the patients with mental retardation (1 and 11) in TSC2 was significantly larger than that in TSC1 (\\u00f82 5 4.8, P 5 0.0285). The severity of mental retardation of the patients with TSC1 mutations appeared to be milder than that of the patients with TSC2 mutations. Complete information on renal and cardiac involvements was not available and could not be assessed. None of the mutation types (missense, nonsense, frame shift, and splicing) appeared to be correlated with a specific clinical symptom. In particular, the R509X mutation in TSC1 was detected in two patients, and the severity of mental retardation in these patients were quite different. Discussion Mutations in a given gene may be screened by various methods such as Southern blot analysis, SSCP, heteroduplex analysis, protein truncation test, and RT-PCR followed by SSCP (Kumar et al. 1995a,b; Vrtel et al. 1996; Wilson et al. 1996; Bajek et al. 1997; Jones et al. 1997; Maheshwar et al. 1997; Au et al. 1997, 1998). In the present study, we employed SSCP to survey the mutations of TSC1 and TSC2 genes because the method is simple enough to cover the multiple numbers of exons. To increase the mutation detection rate of SSCP, we used four electrophoresis conditions by a combination of different sets of temperature and glycerol content of the gel. Our mutation detection rate was 60% (23 of 38), which is comparable with those in other reports (Jones et al. 1997; Van Slegtenhorst et al. 1997; Au et al. 1998). There are several possible explanations for the failure to detect of TSC1/TSC2 mutations in the 15 patients. First, it can be false negative. One report showed that the SSCP Table 2A. Mutations in TSC1 Type of Nucleotide Patient Amino acid change Location mutation alteration S/F* 46 216PheFS-216X(a) exon 7 Frame shift 866delTT F 11 311SerFS-340X exon 10 Frame shift 1210insT F 31 T417l exon 12 Missense 1471 CtoT S 26,3 R509X(b) exon 15 Nonsense 1746 CtoT F,S 23 Q654E(b) exon 15 Missense 2181 CtoG S 31 W676X exon 16 Nonsense 2249 GtoA S 12 T899S exon 21 Missense 2918 CtoG S 46,27,3 L574L exon 15 Polymorphism 1947 TtoC 17,34,36 M322T exon 10 Polymorphism 1186 TtoC Table 2B. Mutations in TSC2 Type of Nucleotide Patient Mutation Location mutation alteration S/F* 32 H137R Exon 4 Missense 428 AtoG S 48 238LeuFS-337X Exon 7 Frame shift 725 insT S 30 F320L Exon 9 Missense 978 TtoG 43 337GluFS-351X Exon 10 Frame shift 1029GATCdel, CATGGCAT ins F 22 R611Q(c) Exon 16 Missense 1850 GtoA F 47 597HisFS-614X Exon 16 Frame shift 1808delACTAC S 32 D647N Exon 17 Missense 1957 AtoG S 1 L717R Exon 19 Missense 2168 TtoG S 21,2 V769E Exon 20 Missense 2324 TtoA F,S 33 \\u2014 Intron 24 Splicing 2760 1 1 GtoA S 27 V963M Exon 25 Missense 2905 GtoA S 6,8 R1459X Exon 33 Nonsense 4393 CtoT S,S 28 P1657L(d) Exon 38 Missense 5042 CtoT S 24 \\u2014 Intron 39 Splicing 5178 1 5 GtoA F 41 \\u2014 Intron 39 Splicing 5179 2 1 GtoT F 33 1531l Exon 14 Polymorphism 1611 CtoT *S, sporadic; F, familial The initiator ATG begins at base 222 of TSC1 and at base 19 for TSC2 The original amino acid and its position in the protein (numbered from the initiator Met as 1) are followed by a new amino acid for missense mutations, and by X for nonsense mutation a,b The identical change was reported by Van Slegtenhorst et al. (1997) c The identical change was reported by Wilson et al. (1996) d The identical change was reported by Maheshwar et al. (1997) 395 method to detect a point mutation on a 250-bp DNA fragment was 63% effective (Sheffield et al. 1993). Second, it may be true negative in those cases in which the mutation lies outside of the coding sequence, either in the 59-regulatory elements, within the intronic sequences, or in the 39- UTR. In addition, a large-scale rearrangement of genomic DNA may yield true negative results in the SSCP of the coding exons. Although there is no report of a large-scale mutation in TSC1, there are indeed some in TSC2 (Jones et al. 1997; The European Chromosome 16 Tuberous Sclerosis Consortium 1993; Au et al. 1997; Van Slegtenhorst et al. 1997). The mutation surveys of TSC1/TSC2 genes in Caucasian TSC patients revealed no clustering of the mutation in either gene (Wilson et al. 1996; Jones et al. 1997; Van Slegtenhorst et al. 1997; Au et al. 1998). In accordance with these previous findings, the 22 mutations (18 new and 4 reported) found in this study were distributed on various exons and there was no clustering of the mutations. Again in accordance with the previous findings, there was no obvious relationship between the type and location of the mutation and the clinical symptoms. However, the patients with TSC2 mutations appeared to have more severe mental retardation compared with the patients with TSC1 mutations. The same tendency has been noted (Jones et al. 1997). It is therefore at least clear that the clinical phenotype cannot be predicted from the genotype. Because of the heterogeneity of the mutations, it also appears impossible at present to develop a simple diagnostic test for TSC. Acknowledgements We thank Dr. Satoko Kumada, Dr. Akira Uchiyama (Tokyo Metropolitan Fuchu Ryoiku Center), Dr. Youich Sakakihara, Dr. Hidekazu Takeshita (Departement of Pediatrics, Graduate School of Medicine, University of Tokyo), Dr. Khotaro Table 3. Clinical data of mutation detected patients Patient Mental White Subependymal number Age Sex retardation AF macules nodules Seizures S/F Mutations Location of mutation 46 9 M 1 2 1 1 1 F Frame shift TSC1 exon 7 11 7 F 6 1 1 1 1 F Frame shift TSC1 exon 10 31 8 F 1 n.d. 1 1 1 S Missense/nonsense TSC1 exon 12; TSC1 exon 16 3 32 F 11 n.d. n.d. n.d. n.d. S Nonsense TSC1 exon 15 26 21 M 2 2 1 1 2 F Nonsense TSC1 exon 15 23 21 M 1 2 1 1 1 S Missense TSC1 exon 15 12 32 F 2 1 1 1 1 S Missense TSC1 exon 21 32 2 M n.d. n.d. 1 1 1 S Missenses TSC2 exon 4; TSC2 exon 17 48 24 M 11 1 1 1 1 S Frame shift TSC2 exon 7 30 nd nd n.d. n.d. n.d. n.d. n.d. n.d. Missense TSC2 exon 9 43 8 M 11 1 1 1 1 F Frame shift TSC2 exon 10 22 6 F 2 2 1 1 1 F Missense TSC2 exon 16 47 6 F 1 1 1 1 1 S Frame shift TSC2 exon 16 1 17 F 2 1 1 1 1 S Missense TSC2 exon 19 21 44 F 11 1 1 n.d. 1 F Missense TSC2 exon 20 2 32 M 11 1 1 1 1 S Missense TSC2 exon 20 33 48 M 11 n.d. n.d. n.d. 1 S Splicing TSC2 intron 24 27 13 M 2 2 1 1 1 F Missense TSC2 exon 25 6 8 M 11 n.d. n.d. n.d. n.d. F Nonsense TSC2 exon 33 8 9 F 11 1 1 1 1 S Nonsense TSC2 exon 33 28 3 F 1 n.d. 1 1 1 S Missense TSC2 exon 38 24 12 M 2 2 1 1 1 F Splicing TSC2 intron 39 41 7 M 2 1 1 1 1 F Splicing TSC2 intron 39 n.d., information not available; AF, angiofibroma; S, sporadic; F, familial Izumi, Dr. Masahiro Nakagawa (Third Department of Internal Medicine, Faculty of Medicine, Kagoshima University), Dr. Ryutaro Kira (Department of Pediatrics, Kyushu University), Dr. Hitoshi Sejima (Department of Pediatrics, Shimane Medical University), Dr. Masahito Miyazaki (Department of Pediatrics, School of Medicine, Tokushima University), Dr. Akira Kuramochi (Department of Dermatology, Saitama Medical School), and Dr. Sadahisa Ohta (Department of Neurosurgery, Tokyo Medical and Dental University) for collecting the samples of the TSC patients. This work was supported by the Ministry of Health and Welfare of Japan by a special grant for neurocutaneous disease, and by the Ministry of Education, Science, Sport and Culture of Japan by a grant-in-aid for scientific research.  Twenty-seven Japanese patients with the tuberous sclerosis complex (TSC), consisting of 23 sporadic and 4 familial cases, were tested for mutations in the TSC1 and TSC2 genes, using single-strand conformational polymorphism analysis and direct sequencing. Four possible pathogenic mutations were found in the TSC1 gene, including three frame shifts and a nonsense mutation in a familial case. All mutations were expected to result in a truncated hamartin gene product. The TSC2 gene analysis identified six possible pathogenic mutations only in the sporadic cases, including two frame shifts, one in-frame deletion, and three missense mutations. Two of the TSC2 mutations were expected to result in a truncated tuberin gene product. These results of the Japanese TSC patients were compatible with the reports from Europe and the United States, i.e., (1) TSC1 mutations are rarer in sporadic cases than in familial cases, (2) substantial numbers of sporadic cases arise from mutations in the TSC2 gene, and (3) mutations of the TSC1 gene may cause premature truncation of hamartin.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train_data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ff083018-fa51-4c39-8b0a-a251ef4a107b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: center;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Gene</th>\n",
              "      <th>Variation</th>\n",
              "      <th>Class</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>FAM58A</td>\n",
              "      <td>Truncating Mutations</td>\n",
              "      <td>1</td>\n",
              "      <td>Cyclin-dependent kinases (CDKs) regulate a variety of fundamental cellular processes. CDK10 stands out as one of the last orphan CDKs for which no activating cyclin has been identified and no kinase activity revealed. Previous work has shown that CDK10 silencing increases ETS2 (v-ets erythroblastosis virus E26 oncogene homolog 2)-driven activation of the MAPK pathway, which confers tamoxifen resistance to breast cancer cells. The precise mechanisms by which CDK10 modulates ETS2 activity, and more generally the functions of CDK10, remain elusive. Here we demonstrate that CDK10 is a cyclin-dependent kinase by identifying cyclin M as an activating cyclin. Cyclin M, an orphan cyclin, is the product of FAM58A, whose mutations cause STAR syndrome, a human developmental anomaly whose features include toe syndactyly, telecanthus, and anogenital and renal malformations. We show that STAR syndrome-associated cyclin M mutants are unable to interact with CDK10. Cyclin M silencing phenocopies CDK10 silencing in increasing c-Raf and in conferring tamoxifen resistance to breast cancer cells. CDK10/cyclin M phosphorylates ETS2 in vitro, and in cells it positively controls ETS2 degradation by the proteasome. ETS2 protein levels are increased in cells derived from a STAR patient, and this increase is attributable to decreased cyclin M levels. Altogether, our results reveal an additional regulatory mechanism for ETS2, which plays key roles in cancer and development. They also shed light on the molecular mechanisms underlying STAR syndrome.Cyclin-dependent kinases (CDKs) play a pivotal role in the control of a number of fundamental cellular processes (1). The human genome contains 21 genes encoding proteins that can be considered as members of the CDK family owing to their sequence similarity with bona fide CDKs, those known to be activated by cyclins (2). Although discovered almost 20 y ago (3, 4), CDK10 remains one of the two CDKs without an identified cyclin partner. This knowledge gap has largely impeded the exploration of its biological functions. CDK10 can act as a positive cell cycle regulator in some cells (5, 6) or as a tumor suppressor in others (7, 8). CDK10 interacts with the ETS2 (v-ets erythroblastosis virus E26 oncogene homolog 2) transcription factor and inhibits its transcriptional activity through an unknown mechanism (9). CDK10 knockdown derepresses ETS2, which increases the expression of the c-Raf protein kinase, activates the MAPK pathway, and induces resistance of MCF7 cells to tamoxifen (6).Here, we deorphanize CDK10 by identifying cyclin M, the product of FAM58A, as a binding partner. Mutations in this gene that predict absence or truncation of cyclin M are associated with STAR syndrome, whose features include toe syndactyly, telecanthus, and anogenital and renal malformations in heterozygous females (10). However, both the functions of cyclin M and the pathogenesis of STAR syndrome remain unknown. We show that a recombinant CDK10/cyclin M heterodimer is an active protein kinase that phosphorylates ETS2 in vitro. Cyclin M silencing phenocopies CDK10 silencing in increasing c-Raf and phospho-ERK expression levels and in inducing tamoxifen resistance in estrogen receptor (ER)+ breast cancer cells. We show that CDK10/cyclin M positively controls ETS2 degradation by the proteasome, through the phosphorylation of two neighboring serines. Finally, we detect an increased ETS2 expression level in cells derived from a STAR patient, and we demonstrate that it is attributable to the decreased cyclin M expression level observed in these cells.Previous SectionNext SectionResultsA yeast two-hybrid (Y2H) screen unveiled an interaction signal between CDK10 and a mouse protein whose C-terminal half presents a strong sequence homology with the human FAM58A gene product [whose proposed name is cyclin M (11)]. We thus performed Y2H mating assays to determine whether human CDK10 interacts with human cyclin M (Fig. 1 A–C). The longest CDK10 isoform (P1) expressed as a bait protein produced a strong interaction phenotype with full-length cyclin M (expressed as a prey protein) but no detectable phenotype with cyclin D1, p21 (CIP1), and Cdi1 (KAP), which are known binding partners of other CDKs (Fig. 1B). CDK1 and CDK3 also produced Y2H signals with cyclin M, albeit notably weaker than that observed with CDK10 (Fig. 1B). An interaction phenotype was also observed between full-length cyclin M and CDK10 proteins expressed as bait and prey, respectively (Fig. S1A). We then tested different isoforms of CDK10 and cyclin M originating from alternative gene splicing, and two truncated cyclin M proteins corresponding to the hypothetical products of two mutated FAM58A genes found in STAR syndrome patients (10). None of these shorter isoforms produced interaction phenotypes (Fig. 1 A and C and Fig. S1A).Fig. 1.In a new window Download PPTFig. 1.CDK10 and cyclin M form an interaction complex. (A) Schematic representation of the differ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>CBL</td>\n",
              "      <td>W802*</td>\n",
              "      <td>2</td>\n",
              "      <td>Abstract Background  Non-small cell lung cancer (NSCLC) is a heterogeneous group of disorders with a number of genetic and proteomic alterations. c-CBL is an E3 ubiquitin ligase and adaptor molecule important in normal homeostasis and cancer. We determined the genetic variations of c-CBL, relationship to receptor tyrosine kinases (EGFR and MET), and functionality in NSCLC.  Methods and Findings  Using archival formalin-fixed paraffin embedded (FFPE) extracted genomic DNA, we show that c-CBL mutations occur in somatic fashion for lung cancers. c-CBL mutations were not mutually exclusive of MET or EGFR mutations; however they were independent of p53 and KRAS mutations. In normal/tumor pairwise analysis, there was significant loss of heterozygosity (LOH) for the c-CBL locus (22%, n = 8/37) and none of these samples revealed any mutation in the remaining copy of c-CBL. The c-CBL LOH also positively correlated with EGFR and MET mutations observed in the same samples. Using select c-CBL somatic mutations such as S80N/H94Y, Q249E and W802* (obtained from Caucasian, Taiwanese and African-American samples, respectively) transfected in NSCLC cell lines, there was increased cell viability and cell motility.  Conclusions  Taking the overall mutation rate of c-CBL to be a combination as somatic missense mutation and LOH, it is clear that c-CBL is highly mutated in lung cancers and may play an essential role in lung tumorigenesis and metastasis.  Go to: Introduction In the US alone, each year approximately 219,400 people are diagnosed with lung cancers, out of which more than 145,000 of them succumb to the disease [1]. This number is roughly equivalent to the combined mortality rates of cancers of the breast, prostate, colon, liver, kidney and melanoma [1]. In addition the prognosis is usually poor and the five-year survival rate is less than 15%. There are also significant ethnic differences for lung cancer, and the outcome is worse for blacks compared to whites. Gender differences are also striking with women having significantly better prognosis as compared to men. There are a number of genetic alterations that can occur in lung cancer. As an example, in NSCLC, mutations in KRAS, p53, EGFR and MET have been identified. Many of these pathways, especially Receptor Tyrosine Kinases (RTKs) are controlled by c-CBL.  CBL (Casitas B-lineage lymphoma) is a mammalian gene located on human chromosome 11q23.3 [2] and is involved in cell signaling and protein ubiquitination [3]. CBL proteins belong to the RING finger class of ubiquitin ligases (E3) and there are three homologues c-CBL, CBL-b, CBL-3 [4]. The c-CBL and CBL-b genes are ubiquitously expressed with the highest levels in hematopoietic tissues [5]. c-CBL consists of four regions encoding for functionally distinct protein domains: the N-terminal tyrosine kinase binding (TKB) domain, the linker region, the catalytic RING finger domain, the proline-rich region and the c-terminal ubiquitin-associated (UBA) domain that also overlaps with a leucine-zipper (LZ) domain [3]. Both TKB and RING finger domains are essential for ligand-induced ubiquitination of RTKs [6], [7], [8], [9]. The RING finger domain is required for the recruitment of E2 ubiquitin-conjugating enzymes. The TKB domain includes four-helix bundle (4H), a calcium-biding EF hand, and a modified SH2 domain, which binds to phosphotyrosine residues [3], [10], [11], [12]. In addition, the proline-rich region of c-CBL can associate with the SH3 domain of Grb2, which can indirectly recruit c-CBL to RTKs via the GRB2 adaptor protein [7], [13], [14].  c-CBL also binds to EGFR and acts as the E3 that targets EGFR for ubiquitination and degradation. Furthermore, CBL desensitizes EGF signaling and opposes cellular proliferation induced by EGF [15]. EGF activation also appears to activate the tyrosine kinase SRC, which phosphorylates c-CBL and in turn activates the ubiquitination and degradation of EGFR [16], [17], [18]. A recent study shows that defective endocytosis of EGFR is characterized by a deletion mutant and the point mutation L858R, whereby its association with c-CBL and subsequent ubiquitination are impaired [19]. Recently, the first human c-CBL mutations were reported in acute myeloid leukemia (AML) patients [20]. The mutation R420Q inhibits FMS-like tyrosine kinase 3 (FLT3) internalization and ubiquitination [20].  Not only can E3 activity be important in oncogenesis, c-CBL has a dual but separate function as a signal transduction molecule. We have previously shown that c-CBL is important in binding CRKL and BCR/ABL in hematopoietic cells. Also, it can bind and modulate functions of cytoskeleton by binding to proteins like talin and paxillin. The TKB domain is important in binding to a number of molecules, and they then function in signal transduction.  Given the critical role of CBL in normal homeostasis and cancer, we hypothesized that it might be mutated in lung cancers. In this study, we report novel c-C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>CBL</td>\n",
              "      <td>Q249E</td>\n",
              "      <td>2</td>\n",
              "      <td>Abstract Background  Non-small cell lung cancer (NSCLC) is a heterogeneous group of disorders with a number of genetic and proteomic alterations. c-CBL is an E3 ubiquitin ligase and adaptor molecule important in normal homeostasis and cancer. We determined the genetic variations of c-CBL, relationship to receptor tyrosine kinases (EGFR and MET), and functionality in NSCLC.  Methods and Findings  Using archival formalin-fixed paraffin embedded (FFPE) extracted genomic DNA, we show that c-CBL mutations occur in somatic fashion for lung cancers. c-CBL mutations were not mutually exclusive of MET or EGFR mutations; however they were independent of p53 and KRAS mutations. In normal/tumor pairwise analysis, there was significant loss of heterozygosity (LOH) for the c-CBL locus (22%, n = 8/37) and none of these samples revealed any mutation in the remaining copy of c-CBL. The c-CBL LOH also positively correlated with EGFR and MET mutations observed in the same samples. Using select c-CBL somatic mutations such as S80N/H94Y, Q249E and W802* (obtained from Caucasian, Taiwanese and African-American samples, respectively) transfected in NSCLC cell lines, there was increased cell viability and cell motility.  Conclusions  Taking the overall mutation rate of c-CBL to be a combination as somatic missense mutation and LOH, it is clear that c-CBL is highly mutated in lung cancers and may play an essential role in lung tumorigenesis and metastasis.  Go to: Introduction In the US alone, each year approximately 219,400 people are diagnosed with lung cancers, out of which more than 145,000 of them succumb to the disease [1]. This number is roughly equivalent to the combined mortality rates of cancers of the breast, prostate, colon, liver, kidney and melanoma [1]. In addition the prognosis is usually poor and the five-year survival rate is less than 15%. There are also significant ethnic differences for lung cancer, and the outcome is worse for blacks compared to whites. Gender differences are also striking with women having significantly better prognosis as compared to men. There are a number of genetic alterations that can occur in lung cancer. As an example, in NSCLC, mutations in KRAS, p53, EGFR and MET have been identified. Many of these pathways, especially Receptor Tyrosine Kinases (RTKs) are controlled by c-CBL.  CBL (Casitas B-lineage lymphoma) is a mammalian gene located on human chromosome 11q23.3 [2] and is involved in cell signaling and protein ubiquitination [3]. CBL proteins belong to the RING finger class of ubiquitin ligases (E3) and there are three homologues c-CBL, CBL-b, CBL-3 [4]. The c-CBL and CBL-b genes are ubiquitously expressed with the highest levels in hematopoietic tissues [5]. c-CBL consists of four regions encoding for functionally distinct protein domains: the N-terminal tyrosine kinase binding (TKB) domain, the linker region, the catalytic RING finger domain, the proline-rich region and the c-terminal ubiquitin-associated (UBA) domain that also overlaps with a leucine-zipper (LZ) domain [3]. Both TKB and RING finger domains are essential for ligand-induced ubiquitination of RTKs [6], [7], [8], [9]. The RING finger domain is required for the recruitment of E2 ubiquitin-conjugating enzymes. The TKB domain includes four-helix bundle (4H), a calcium-biding EF hand, and a modified SH2 domain, which binds to phosphotyrosine residues [3], [10], [11], [12]. In addition, the proline-rich region of c-CBL can associate with the SH3 domain of Grb2, which can indirectly recruit c-CBL to RTKs via the GRB2 adaptor protein [7], [13], [14].  c-CBL also binds to EGFR and acts as the E3 that targets EGFR for ubiquitination and degradation. Furthermore, CBL desensitizes EGF signaling and opposes cellular proliferation induced by EGF [15]. EGF activation also appears to activate the tyrosine kinase SRC, which phosphorylates c-CBL and in turn activates the ubiquitination and degradation of EGFR [16], [17], [18]. A recent study shows that defective endocytosis of EGFR is characterized by a deletion mutant and the point mutation L858R, whereby its association with c-CBL and subsequent ubiquitination are impaired [19]. Recently, the first human c-CBL mutations were reported in acute myeloid leukemia (AML) patients [20]. The mutation R420Q inhibits FMS-like tyrosine kinase 3 (FLT3) internalization and ubiquitination [20].  Not only can E3 activity be important in oncogenesis, c-CBL has a dual but separate function as a signal transduction molecule. We have previously shown that c-CBL is important in binding CRKL and BCR/ABL in hematopoietic cells. Also, it can bind and modulate functions of cytoskeleton by binding to proteins like talin and paxillin. The TKB domain is important in binding to a number of molecules, and they then function in signal transduction.  Given the critical role of CBL in normal homeostasis and cancer, we hypothesized that it might be mutated in lung cancers. In this study, we report novel c-C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>CBL</td>\n",
              "      <td>N454D</td>\n",
              "      <td>3</td>\n",
              "      <td>Recent evidence has demonstrated that acquired uniparental disomy (aUPD) is a novel mechanism by which pathogenetic mutations in cancer may be reduced to homozygosity. To help identify novel mutations in myeloproliferative neoplasms (MPNs), we performed a genome-wide single nucleotide polymorphism (SNP) screen to identify aUPD in 58 patients with atypical chronic myeloid leukemia (aCML; n = 30), JAK2 mutation–negative myelofibrosis (MF; n = 18), or JAK2 mutation–negative polycythemia vera (PV; n = 10). Stretches of homozygous, copy neutral SNP calls greater than 20Mb were seen in 10 (33%) aCML and 1 (6%) MF, but were absent in PV. In total, 7 different chromosomes were involved with 7q and 11q each affected in 10% of aCML cases. CBL mutations were identified in all 3 cases with 11q aUPD and analysis of 574 additional MPNs revealed a total of 27 CBL variants in 26 patients with aCML, myelofibrosis or chronic myelomonocytic leukemia. Most variants were missense substitutions in the RING or linker domains that abrogated CBL ubiquitin ligase activity and conferred a proliferative advantage to 32D cells overexpressing FLT3. We conclude that acquired, transforming CBL mutations are a novel and widespread pathogenetic abnormality in morphologically related, clinically aggressive MPNs.  Introduction  Myeloproliferative neoplasms (MPNs) are clonal hematopoietic stem cell disorders characterized by overproliferation of one or more myeloid cell lineages in the bone marrow and increased numbers of mature and immature myeloid cells in the peripheral blood. Excess proliferation is frequently associated with splenomegaly and cardiovascular complications as well as increased risk of transformation to acute leukemia. MPNs are categorized into subtypes based on specific morphologic, hematologic, and laboratory parameters, the best characterized being the 4 so-called classic MPNs: polycythemia vera (PV), essential thrombocythemia (ET), primary myelofibrosis (MF), and chronic myeloid leukemia (CML).1 In addition, several atypical MPNs are recognized, some of which show both dysplastic and proliferative features, such as atypical, BCR-ABL negative CML (aCML).2  MPNs are associated with acquired, activating mutations or gene fusions of tyrosine kinases, abnormalities that are believed to be critical drivers of excess proliferation as a result of deregulated or constitutive signaling.3 The 2 most prominent examples are BCR-ABL in CML4 and the V617F JAK2 mutation in PV, ET, and MF,5⇓⇓–8 but more than 40 variant tyrosine kinase fusions have been identified in MPNs as well as other mutations in JAK2 and FLT3.2 Activating mutations have been described in components that signal upstream (eg, MPL) or downstream (eg, NRAS) of tyrosine kinases9,10; however, the molecular pathogenesis of the majority of atypical MPNs and approximately 50% of ET and MF cases remains obscure.  V617F JAK2 was initially identified by several different routes, one of which was based on the observation that many PV patients show evidence of acquired uniparental disomy (aUPD) at chromosome 9p.11,12 Regions of aUPD exhibit loss of heterozygosity (LOH) compared with constitutional DNA without change of copy number and arise by mitotic recombination followed by selection for one of the products. After the initial observations in PV, it has emerged that aUPD is common in both hematologic and epithelial malignancies, and is associated with known oncogenic changes in a variety of genes within the affected regions.13 In this study we set out to determine whether aUPD characterizes MPNs of unknown molecular etiology and, if so, whether it could be used as a tool to help identify novel driver mutations.  Methods  Patients  Peripheral blood or bone marrow samples were received from patients diagnosed with an MPN or other hematologic malignancy according to standard morphologic, hematologic, and laboratory criteria. Clinical data were available from a subset of these cases. The study was approved by the Internal Review Boards from participating institutions and informed consent was obtained in accordance with the Declaration of Helsinki.  SNP array analysis  DNA labeling and hybridization to Affymetrix 50k XbaI chips was performed at the Deutsches Ressourcenzentrum für Genomforschung (RZPD, Berlin, Germany). Raw data were imported into the Affymetrix GeneChip Operating Software, analyzed using Affymetrix (High Wycombe, United Kingdom) GeneChip Genotyping Analysis Software (GTYPE 4.1) and copy number analysis tool (CNAT). Data were exported to custom-designed spreadsheets that display loss of heterozygosity and copy number changes in ideogram format. Data were also analyzed using Affymetrix Genotyping Console (version 2.1). Overall, a median of 98.2% (range, 91.5%-99.6%) of SNPs gave readable calls.  Mutation analysis  Detection of mutations by high resolution melting (HRM) analysis was performed as described14 using a Rotor-Gene 6000 (Corbett Life Sciences, St Neots, U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>CBL</td>\n",
              "      <td>L399V</td>\n",
              "      <td>4</td>\n",
              "      <td>Oncogenic mutations in the monomeric Casitas B-lineage lymphoma (Cbl) gene have been found in many tumors, but their significance remains largely unknown. Several human c-Cbl (CBL) structures have recently been solved depicting the protein at different stages of its activation cycle and thus provide mechanistic insight underlying how stability-activity tradeoffs in cancer-related proteins may influence disease onset and progression. In this study, we computationally modeled the effects of missense cancer mutations on structures representing four stages of the CBL activation cycle to identify driver mutations that affect CBL stability, binding, and activity. We found that recurrent, homozygous, and leukemia-specific mutations had greater destabilizing effects on CBL states than did random non-cancer mutations. We further tested the ability of these computational models assessing the changes in CBL stability and its binding to ubiquitin conjugating enzyme E2, by performing blind CBL-mediated EGFR ubiquitination assays in cells. Experimental CBL ubiquitin ligase activity was in agreement with the predicted changes in CBL stability and, to a lesser extent, with CBL-E2 binding affinity. Two-thirds of all experimentally tested mutations affected the ubiquitin ligase activity by either destabilizing CBL or disrupting CBL-E2 binding, whereas about one-third of tested mutations were found to be neutral. Collectively, our findings demonstrate that computational methods incorporating multiple protein conformations and stability and binding affinity evaluations can successfully predict the functional consequences of cancer mutations on protein activity, and provide a proof of concept for mutations in CBL.  Keywords: CBL, driver mutations, protein interactions Go to: Introduction Whole exome sequencing of cancer patients has produced unprecedented amounts of data to analyze and interpret; these studies report a very large fraction of missense mutations which can potentially be implicated in tumorigenensis (1). Although some missense mutations can provide selective growth advantage to tumor cells (driver mutations), the large majority of them are considered to be neutral (passenger mutations). The mechanisms by which the driver variants may affect protein stability, interactions, and function remain largely unknown. Various computational methods have been developed to estimate the impacts of disease mutations on proteins but most of them exclusively use sequence features and do not explicitly utilize the protein three-dimensional structures, their physico-chemical properties and dynamics (2, 3). Many cancers are characterized by (de)activation of certain proteins which may be a result of missense mutations (4). The interconversion between active and inactive states is highly regulated in proteins and it is not well understood how these regulatory mechanisms are disrupted in cancer. The development of in silico approaches to estimate the effects of disease mutations on protein activity, stability and binding will help to define which are likely to be driver or passenger mutations. Moreover, understanding the mechanisms of their actions would allow for prioritization of potential driver candidates for better targeted therapies to design drugs which might in turn compensate for the reduced/enhanced protein stability or activity.  The monomeric Casitas B-lineage lymphoma (Cbl) RING finger ubiquitin ligase (E3) represents an exceptionally difficult yet important system to study the mechanisms of cancer mutations (5, 6). Strikingly, proteins from this family play both positive and negative regulatory roles in tyrosine kinase signaling which is aberrantly activated in many cancers (5). Oncogenic mutations in the c-Cbl gene (referred to as CBL thereafter) were found in human myeloid neoplasms and other tumors (5) but the significance of these mutations and their impacts on CBL function were studied only for very few mutants (7). The mechanistic aspects of CBL cancer mutations can now be adequately addressed as several CBL structures have become available which represent the snapshots of different stages of the CBL activation cycle (Fig. 1). All CBL proteins share a highly conserved N-terminus which includes a tyrosine kinase–binding domain (TKBD), a linker helix region (LHR) and a RING finger domain, while the C-terminus comprises a proline-rich region (8). The RING domain of CBL has E3 activity and ubiquitinates activated receptor tyrosine kinases which subsequently targets them for degradation (8). At the same time, since CBL proteins can bind to activated receptor tyrosine kinases via the TKBD domain, they can serve as adaptors by recruiting downstream signal transduction components such as SHP2 and P13K (9, 10).  Figure 1 Figure 1 CBL activation cycle. The structures representing the activation cycle of CBL are shown. In the inactive closed state (nCBL) the protein exists in the cytosol. Upon activation of the RTK, CBL c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff083018-fa51-4c39-8b0a-a251ef4a107b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff083018-fa51-4c39-8b0a-a251ef4a107b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff083018-fa51-4c39-8b0a-a251ef4a107b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e06521e6-306d-4c75-a894-1a5c931028eb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e06521e6-306d-4c75-a894-1a5c931028eb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e06521e6-306d-4c75-a894-1a5c931028eb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   ID   Gene        Variation        Class  \\\n",
              "0   0  FAM58A  Truncating Mutations    1     \n",
              "1   1     CBL                 W802*    2     \n",
              "2   2     CBL                 Q249E    2     \n",
              "3   3     CBL                 N454D    3     \n",
              "4   4     CBL                 L399V    4     \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
              "0  Cyclin-dependent kinases (CDKs) regulate a variety of fundamental cellular processes. CDK10 stands out as one of the last orphan CDKs for which no activating cyclin has been identified and no kinase activity revealed. Previous work has shown that CDK10 silencing increases ETS2 (v-ets erythroblastosis virus E26 oncogene homolog 2)-driven activation of the MAPK pathway, which confers tamoxifen resistance to breast cancer cells. The precise mechanisms by which CDK10 modulates ETS2 activity, and more generally the functions of CDK10, remain elusive. Here we demonstrate that CDK10 is a cyclin-dependent kinase by identifying cyclin M as an activating cyclin. Cyclin M, an orphan cyclin, is the product of FAM58A, whose mutations cause STAR syndrome, a human developmental anomaly whose features include toe syndactyly, telecanthus, and anogenital and renal malformations. We show that STAR syndrome-associated cyclin M mutants are unable to interact with CDK10. Cyclin M silencing phenocopies CDK10 silencing in increasing c-Raf and in conferring tamoxifen resistance to breast cancer cells. CDK10/cyclin M phosphorylates ETS2 in vitro, and in cells it positively controls ETS2 degradation by the proteasome. ETS2 protein levels are increased in cells derived from a STAR patient, and this increase is attributable to decreased cyclin M levels. Altogether, our results reveal an additional regulatory mechanism for ETS2, which plays key roles in cancer and development. They also shed light on the molecular mechanisms underlying STAR syndrome.Cyclin-dependent kinases (CDKs) play a pivotal role in the control of a number of fundamental cellular processes (1). The human genome contains 21 genes encoding proteins that can be considered as members of the CDK family owing to their sequence similarity with bona fide CDKs, those known to be activated by cyclins (2). Although discovered almost 20 y ago (3, 4), CDK10 remains one of the two CDKs without an identified cyclin partner. This knowledge gap has largely impeded the exploration of its biological functions. CDK10 can act as a positive cell cycle regulator in some cells (5, 6) or as a tumor suppressor in others (7, 8). CDK10 interacts with the ETS2 (v-ets erythroblastosis virus E26 oncogene homolog 2) transcription factor and inhibits its transcriptional activity through an unknown mechanism (9). CDK10 knockdown derepresses ETS2, which increases the expression of the c-Raf protein kinase, activates the MAPK pathway, and induces resistance of MCF7 cells to tamoxifen (6).Here, we deorphanize CDK10 by identifying cyclin M, the product of FAM58A, as a binding partner. Mutations in this gene that predict absence or truncation of cyclin M are associated with STAR syndrome, whose features include toe syndactyly, telecanthus, and anogenital and renal malformations in heterozygous females (10). However, both the functions of cyclin M and the pathogenesis of STAR syndrome remain unknown. We show that a recombinant CDK10/cyclin M heterodimer is an active protein kinase that phosphorylates ETS2 in vitro. Cyclin M silencing phenocopies CDK10 silencing in increasing c-Raf and phospho-ERK expression levels and in inducing tamoxifen resistance in estrogen receptor (ER)+ breast cancer cells. We show that CDK10/cyclin M positively controls ETS2 degradation by the proteasome, through the phosphorylation of two neighboring serines. Finally, we detect an increased ETS2 expression level in cells derived from a STAR patient, and we demonstrate that it is attributable to the decreased cyclin M expression level observed in these cells.Previous SectionNext SectionResultsA yeast two-hybrid (Y2H) screen unveiled an interaction signal between CDK10 and a mouse protein whose C-terminal half presents a strong sequence homology with the human FAM58A gene product [whose proposed name is cyclin M (11)]. We thus performed Y2H mating assays to determine whether human CDK10 interacts with human cyclin M (Fig. 1 A–C). The longest CDK10 isoform (P1) expressed as a bait protein produced a strong interaction phenotype with full-length cyclin M (expressed as a prey protein) but no detectable phenotype with cyclin D1, p21 (CIP1), and Cdi1 (KAP), which are known binding partners of other CDKs (Fig. 1B). CDK1 and CDK3 also produced Y2H signals with cyclin M, albeit notably weaker than that observed with CDK10 (Fig. 1B). An interaction phenotype was also observed between full-length cyclin M and CDK10 proteins expressed as bait and prey, respectively (Fig. S1A). We then tested different isoforms of CDK10 and cyclin M originating from alternative gene splicing, and two truncated cyclin M proteins corresponding to the hypothetical products of two mutated FAM58A genes found in STAR syndrome patients (10). None of these shorter isoforms produced interaction phenotypes (Fig. 1 A and C and Fig. S1A).Fig. 1.In a new window Download PPTFig. 1.CDK10 and cyclin M form an interaction complex. (A) Schematic representation of the differ...  \n",
              "1   Abstract Background  Non-small cell lung cancer (NSCLC) is a heterogeneous group of disorders with a number of genetic and proteomic alterations. c-CBL is an E3 ubiquitin ligase and adaptor molecule important in normal homeostasis and cancer. We determined the genetic variations of c-CBL, relationship to receptor tyrosine kinases (EGFR and MET), and functionality in NSCLC.  Methods and Findings  Using archival formalin-fixed paraffin embedded (FFPE) extracted genomic DNA, we show that c-CBL mutations occur in somatic fashion for lung cancers. c-CBL mutations were not mutually exclusive of MET or EGFR mutations; however they were independent of p53 and KRAS mutations. In normal/tumor pairwise analysis, there was significant loss of heterozygosity (LOH) for the c-CBL locus (22%, n = 8/37) and none of these samples revealed any mutation in the remaining copy of c-CBL. The c-CBL LOH also positively correlated with EGFR and MET mutations observed in the same samples. Using select c-CBL somatic mutations such as S80N/H94Y, Q249E and W802* (obtained from Caucasian, Taiwanese and African-American samples, respectively) transfected in NSCLC cell lines, there was increased cell viability and cell motility.  Conclusions  Taking the overall mutation rate of c-CBL to be a combination as somatic missense mutation and LOH, it is clear that c-CBL is highly mutated in lung cancers and may play an essential role in lung tumorigenesis and metastasis.  Go to: Introduction In the US alone, each year approximately 219,400 people are diagnosed with lung cancers, out of which more than 145,000 of them succumb to the disease [1]. This number is roughly equivalent to the combined mortality rates of cancers of the breast, prostate, colon, liver, kidney and melanoma [1]. In addition the prognosis is usually poor and the five-year survival rate is less than 15%. There are also significant ethnic differences for lung cancer, and the outcome is worse for blacks compared to whites. Gender differences are also striking with women having significantly better prognosis as compared to men. There are a number of genetic alterations that can occur in lung cancer. As an example, in NSCLC, mutations in KRAS, p53, EGFR and MET have been identified. Many of these pathways, especially Receptor Tyrosine Kinases (RTKs) are controlled by c-CBL.  CBL (Casitas B-lineage lymphoma) is a mammalian gene located on human chromosome 11q23.3 [2] and is involved in cell signaling and protein ubiquitination [3]. CBL proteins belong to the RING finger class of ubiquitin ligases (E3) and there are three homologues c-CBL, CBL-b, CBL-3 [4]. The c-CBL and CBL-b genes are ubiquitously expressed with the highest levels in hematopoietic tissues [5]. c-CBL consists of four regions encoding for functionally distinct protein domains: the N-terminal tyrosine kinase binding (TKB) domain, the linker region, the catalytic RING finger domain, the proline-rich region and the c-terminal ubiquitin-associated (UBA) domain that also overlaps with a leucine-zipper (LZ) domain [3]. Both TKB and RING finger domains are essential for ligand-induced ubiquitination of RTKs [6], [7], [8], [9]. The RING finger domain is required for the recruitment of E2 ubiquitin-conjugating enzymes. The TKB domain includes four-helix bundle (4H), a calcium-biding EF hand, and a modified SH2 domain, which binds to phosphotyrosine residues [3], [10], [11], [12]. In addition, the proline-rich region of c-CBL can associate with the SH3 domain of Grb2, which can indirectly recruit c-CBL to RTKs via the GRB2 adaptor protein [7], [13], [14].  c-CBL also binds to EGFR and acts as the E3 that targets EGFR for ubiquitination and degradation. Furthermore, CBL desensitizes EGF signaling and opposes cellular proliferation induced by EGF [15]. EGF activation also appears to activate the tyrosine kinase SRC, which phosphorylates c-CBL and in turn activates the ubiquitination and degradation of EGFR [16], [17], [18]. A recent study shows that defective endocytosis of EGFR is characterized by a deletion mutant and the point mutation L858R, whereby its association with c-CBL and subsequent ubiquitination are impaired [19]. Recently, the first human c-CBL mutations were reported in acute myeloid leukemia (AML) patients [20]. The mutation R420Q inhibits FMS-like tyrosine kinase 3 (FLT3) internalization and ubiquitination [20].  Not only can E3 activity be important in oncogenesis, c-CBL has a dual but separate function as a signal transduction molecule. We have previously shown that c-CBL is important in binding CRKL and BCR/ABL in hematopoietic cells. Also, it can bind and modulate functions of cytoskeleton by binding to proteins like talin and paxillin. The TKB domain is important in binding to a number of molecules, and they then function in signal transduction.  Given the critical role of CBL in normal homeostasis and cancer, we hypothesized that it might be mutated in lung cancers. In this study, we report novel c-C...  \n",
              "2   Abstract Background  Non-small cell lung cancer (NSCLC) is a heterogeneous group of disorders with a number of genetic and proteomic alterations. c-CBL is an E3 ubiquitin ligase and adaptor molecule important in normal homeostasis and cancer. We determined the genetic variations of c-CBL, relationship to receptor tyrosine kinases (EGFR and MET), and functionality in NSCLC.  Methods and Findings  Using archival formalin-fixed paraffin embedded (FFPE) extracted genomic DNA, we show that c-CBL mutations occur in somatic fashion for lung cancers. c-CBL mutations were not mutually exclusive of MET or EGFR mutations; however they were independent of p53 and KRAS mutations. In normal/tumor pairwise analysis, there was significant loss of heterozygosity (LOH) for the c-CBL locus (22%, n = 8/37) and none of these samples revealed any mutation in the remaining copy of c-CBL. The c-CBL LOH also positively correlated with EGFR and MET mutations observed in the same samples. Using select c-CBL somatic mutations such as S80N/H94Y, Q249E and W802* (obtained from Caucasian, Taiwanese and African-American samples, respectively) transfected in NSCLC cell lines, there was increased cell viability and cell motility.  Conclusions  Taking the overall mutation rate of c-CBL to be a combination as somatic missense mutation and LOH, it is clear that c-CBL is highly mutated in lung cancers and may play an essential role in lung tumorigenesis and metastasis.  Go to: Introduction In the US alone, each year approximately 219,400 people are diagnosed with lung cancers, out of which more than 145,000 of them succumb to the disease [1]. This number is roughly equivalent to the combined mortality rates of cancers of the breast, prostate, colon, liver, kidney and melanoma [1]. In addition the prognosis is usually poor and the five-year survival rate is less than 15%. There are also significant ethnic differences for lung cancer, and the outcome is worse for blacks compared to whites. Gender differences are also striking with women having significantly better prognosis as compared to men. There are a number of genetic alterations that can occur in lung cancer. As an example, in NSCLC, mutations in KRAS, p53, EGFR and MET have been identified. Many of these pathways, especially Receptor Tyrosine Kinases (RTKs) are controlled by c-CBL.  CBL (Casitas B-lineage lymphoma) is a mammalian gene located on human chromosome 11q23.3 [2] and is involved in cell signaling and protein ubiquitination [3]. CBL proteins belong to the RING finger class of ubiquitin ligases (E3) and there are three homologues c-CBL, CBL-b, CBL-3 [4]. The c-CBL and CBL-b genes are ubiquitously expressed with the highest levels in hematopoietic tissues [5]. c-CBL consists of four regions encoding for functionally distinct protein domains: the N-terminal tyrosine kinase binding (TKB) domain, the linker region, the catalytic RING finger domain, the proline-rich region and the c-terminal ubiquitin-associated (UBA) domain that also overlaps with a leucine-zipper (LZ) domain [3]. Both TKB and RING finger domains are essential for ligand-induced ubiquitination of RTKs [6], [7], [8], [9]. The RING finger domain is required for the recruitment of E2 ubiquitin-conjugating enzymes. The TKB domain includes four-helix bundle (4H), a calcium-biding EF hand, and a modified SH2 domain, which binds to phosphotyrosine residues [3], [10], [11], [12]. In addition, the proline-rich region of c-CBL can associate with the SH3 domain of Grb2, which can indirectly recruit c-CBL to RTKs via the GRB2 adaptor protein [7], [13], [14].  c-CBL also binds to EGFR and acts as the E3 that targets EGFR for ubiquitination and degradation. Furthermore, CBL desensitizes EGF signaling and opposes cellular proliferation induced by EGF [15]. EGF activation also appears to activate the tyrosine kinase SRC, which phosphorylates c-CBL and in turn activates the ubiquitination and degradation of EGFR [16], [17], [18]. A recent study shows that defective endocytosis of EGFR is characterized by a deletion mutant and the point mutation L858R, whereby its association with c-CBL and subsequent ubiquitination are impaired [19]. Recently, the first human c-CBL mutations were reported in acute myeloid leukemia (AML) patients [20]. The mutation R420Q inhibits FMS-like tyrosine kinase 3 (FLT3) internalization and ubiquitination [20].  Not only can E3 activity be important in oncogenesis, c-CBL has a dual but separate function as a signal transduction molecule. We have previously shown that c-CBL is important in binding CRKL and BCR/ABL in hematopoietic cells. Also, it can bind and modulate functions of cytoskeleton by binding to proteins like talin and paxillin. The TKB domain is important in binding to a number of molecules, and they then function in signal transduction.  Given the critical role of CBL in normal homeostasis and cancer, we hypothesized that it might be mutated in lung cancers. In this study, we report novel c-C...  \n",
              "3  Recent evidence has demonstrated that acquired uniparental disomy (aUPD) is a novel mechanism by which pathogenetic mutations in cancer may be reduced to homozygosity. To help identify novel mutations in myeloproliferative neoplasms (MPNs), we performed a genome-wide single nucleotide polymorphism (SNP) screen to identify aUPD in 58 patients with atypical chronic myeloid leukemia (aCML; n = 30), JAK2 mutation–negative myelofibrosis (MF; n = 18), or JAK2 mutation–negative polycythemia vera (PV; n = 10). Stretches of homozygous, copy neutral SNP calls greater than 20Mb were seen in 10 (33%) aCML and 1 (6%) MF, but were absent in PV. In total, 7 different chromosomes were involved with 7q and 11q each affected in 10% of aCML cases. CBL mutations were identified in all 3 cases with 11q aUPD and analysis of 574 additional MPNs revealed a total of 27 CBL variants in 26 patients with aCML, myelofibrosis or chronic myelomonocytic leukemia. Most variants were missense substitutions in the RING or linker domains that abrogated CBL ubiquitin ligase activity and conferred a proliferative advantage to 32D cells overexpressing FLT3. We conclude that acquired, transforming CBL mutations are a novel and widespread pathogenetic abnormality in morphologically related, clinically aggressive MPNs.  Introduction  Myeloproliferative neoplasms (MPNs) are clonal hematopoietic stem cell disorders characterized by overproliferation of one or more myeloid cell lineages in the bone marrow and increased numbers of mature and immature myeloid cells in the peripheral blood. Excess proliferation is frequently associated with splenomegaly and cardiovascular complications as well as increased risk of transformation to acute leukemia. MPNs are categorized into subtypes based on specific morphologic, hematologic, and laboratory parameters, the best characterized being the 4 so-called classic MPNs: polycythemia vera (PV), essential thrombocythemia (ET), primary myelofibrosis (MF), and chronic myeloid leukemia (CML).1 In addition, several atypical MPNs are recognized, some of which show both dysplastic and proliferative features, such as atypical, BCR-ABL negative CML (aCML).2  MPNs are associated with acquired, activating mutations or gene fusions of tyrosine kinases, abnormalities that are believed to be critical drivers of excess proliferation as a result of deregulated or constitutive signaling.3 The 2 most prominent examples are BCR-ABL in CML4 and the V617F JAK2 mutation in PV, ET, and MF,5⇓⇓–8 but more than 40 variant tyrosine kinase fusions have been identified in MPNs as well as other mutations in JAK2 and FLT3.2 Activating mutations have been described in components that signal upstream (eg, MPL) or downstream (eg, NRAS) of tyrosine kinases9,10; however, the molecular pathogenesis of the majority of atypical MPNs and approximately 50% of ET and MF cases remains obscure.  V617F JAK2 was initially identified by several different routes, one of which was based on the observation that many PV patients show evidence of acquired uniparental disomy (aUPD) at chromosome 9p.11,12 Regions of aUPD exhibit loss of heterozygosity (LOH) compared with constitutional DNA without change of copy number and arise by mitotic recombination followed by selection for one of the products. After the initial observations in PV, it has emerged that aUPD is common in both hematologic and epithelial malignancies, and is associated with known oncogenic changes in a variety of genes within the affected regions.13 In this study we set out to determine whether aUPD characterizes MPNs of unknown molecular etiology and, if so, whether it could be used as a tool to help identify novel driver mutations.  Methods  Patients  Peripheral blood or bone marrow samples were received from patients diagnosed with an MPN or other hematologic malignancy according to standard morphologic, hematologic, and laboratory criteria. Clinical data were available from a subset of these cases. The study was approved by the Internal Review Boards from participating institutions and informed consent was obtained in accordance with the Declaration of Helsinki.  SNP array analysis  DNA labeling and hybridization to Affymetrix 50k XbaI chips was performed at the Deutsches Ressourcenzentrum für Genomforschung (RZPD, Berlin, Germany). Raw data were imported into the Affymetrix GeneChip Operating Software, analyzed using Affymetrix (High Wycombe, United Kingdom) GeneChip Genotyping Analysis Software (GTYPE 4.1) and copy number analysis tool (CNAT). Data were exported to custom-designed spreadsheets that display loss of heterozygosity and copy number changes in ideogram format. Data were also analyzed using Affymetrix Genotyping Console (version 2.1). Overall, a median of 98.2% (range, 91.5%-99.6%) of SNPs gave readable calls.  Mutation analysis  Detection of mutations by high resolution melting (HRM) analysis was performed as described14 using a Rotor-Gene 6000 (Corbett Life Sciences, St Neots, U...  \n",
              "4  Oncogenic mutations in the monomeric Casitas B-lineage lymphoma (Cbl) gene have been found in many tumors, but their significance remains largely unknown. Several human c-Cbl (CBL) structures have recently been solved depicting the protein at different stages of its activation cycle and thus provide mechanistic insight underlying how stability-activity tradeoffs in cancer-related proteins may influence disease onset and progression. In this study, we computationally modeled the effects of missense cancer mutations on structures representing four stages of the CBL activation cycle to identify driver mutations that affect CBL stability, binding, and activity. We found that recurrent, homozygous, and leukemia-specific mutations had greater destabilizing effects on CBL states than did random non-cancer mutations. We further tested the ability of these computational models assessing the changes in CBL stability and its binding to ubiquitin conjugating enzyme E2, by performing blind CBL-mediated EGFR ubiquitination assays in cells. Experimental CBL ubiquitin ligase activity was in agreement with the predicted changes in CBL stability and, to a lesser extent, with CBL-E2 binding affinity. Two-thirds of all experimentally tested mutations affected the ubiquitin ligase activity by either destabilizing CBL or disrupting CBL-E2 binding, whereas about one-third of tested mutations were found to be neutral. Collectively, our findings demonstrate that computational methods incorporating multiple protein conformations and stability and binding affinity evaluations can successfully predict the functional consequences of cancer mutations on protein activity, and provide a proof of concept for mutations in CBL.  Keywords: CBL, driver mutations, protein interactions Go to: Introduction Whole exome sequencing of cancer patients has produced unprecedented amounts of data to analyze and interpret; these studies report a very large fraction of missense mutations which can potentially be implicated in tumorigenensis (1). Although some missense mutations can provide selective growth advantage to tumor cells (driver mutations), the large majority of them are considered to be neutral (passenger mutations). The mechanisms by which the driver variants may affect protein stability, interactions, and function remain largely unknown. Various computational methods have been developed to estimate the impacts of disease mutations on proteins but most of them exclusively use sequence features and do not explicitly utilize the protein three-dimensional structures, their physico-chemical properties and dynamics (2, 3). Many cancers are characterized by (de)activation of certain proteins which may be a result of missense mutations (4). The interconversion between active and inactive states is highly regulated in proteins and it is not well understood how these regulatory mechanisms are disrupted in cancer. The development of in silico approaches to estimate the effects of disease mutations on protein activity, stability and binding will help to define which are likely to be driver or passenger mutations. Moreover, understanding the mechanisms of their actions would allow for prioritization of potential driver candidates for better targeted therapies to design drugs which might in turn compensate for the reduced/enhanced protein stability or activity.  The monomeric Casitas B-lineage lymphoma (Cbl) RING finger ubiquitin ligase (E3) represents an exceptionally difficult yet important system to study the mechanisms of cancer mutations (5, 6). Strikingly, proteins from this family play both positive and negative regulatory roles in tyrosine kinase signaling which is aberrantly activated in many cancers (5). Oncogenic mutations in the c-Cbl gene (referred to as CBL thereafter) were found in human myeloid neoplasms and other tumors (5) but the significance of these mutations and their impacts on CBL function were studied only for very few mutants (7). The mechanistic aspects of CBL cancer mutations can now be adequately addressed as several CBL structures have become available which represent the snapshots of different stages of the CBL activation cycle (Fig. 1). All CBL proteins share a highly conserved N-terminus which includes a tyrosine kinase–binding domain (TKBD), a linker helix region (LHR) and a RING finger domain, while the C-terminus comprises a proline-rich region (8). The RING domain of CBL has E3 activity and ubiquitinates activated receptor tyrosine kinases which subsequently targets them for degradation (8). At the same time, since CBL proteins can bind to activated receptor tyrosine kinases via the TKBD domain, they can serve as adaptors by recruiting downstream signal transduction components such as SHP2 and P13K (9, 10).  Figure 1 Figure 1 CBL activation cycle. The structures representing the activation cycle of CBL are shown. In the inactive closed state (nCBL) the protein exists in the cytosol. Upon activation of the RTK, CBL c...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# merging structured and text data with id\n",
        "train_data = pd.merge(train_variants, train_text, on=\"ID\", how=\"left\")\n",
        "test_data = pd.merge(test_variants, test_text, on=\"ID\", how=\"left\")\n",
        "\n",
        "\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_7HlI736_vV",
        "outputId": "04154d38-d6f1-49a9-814a-de6c73169e73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3321, 5), (5668, 4))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display dataset shape\n",
        "train_data.shape, test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0QpwmSY37UsA",
        "outputId": "6c1ea1b7-1264-4a82-89cb-d11f14b3a371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of your Data Set loaded: (3321, 4)\n",
            "#######################################################################################\n",
            "######################## C L A S S I F Y I N G  V A R I A B L E S  ####################\n",
            "#######################################################################################\n",
            "Classifying variables in data set...\n",
            "  Printing up to 30 columns (max) in each category:\n",
            "    Numeric Columns : []\n",
            "    Integer-Categorical Columns: []\n",
            "    String-Categorical Columns: []\n",
            "    Factor-Categorical Columns: []\n",
            "    String-Boolean Columns: []\n",
            "    Numeric-Boolean Columns: []\n",
            "    Discrete String Columns: ['Gene']\n",
            "    NLP text Columns: ['Variation']\n",
            "    Date Time Columns: []\n",
            "    ID Columns: ['ID']\n",
            "    Columns that will not be considered in modeling: []\n",
            "    3 Predictors classified...\n",
            "        1 variable(s) removed since they were ID or low-information variables\n",
            "        List of variables removed: ['ID']\n",
            "\n",
            "################ Multi_Classification problem #####################\n",
            "   Columns to delete:\n",
            "'   []'\n",
            "   Boolean variables %s \n",
            "'   []'\n",
            "   Categorical variables %s \n",
            "'   []'\n",
            "   Continuous variables %s \n",
            "'   []'\n",
            "   Discrete string variables %s \n",
            "\"   ['Variation', 'Gene']\"\n",
            "   Date and time variables %s \n",
            "'   []'\n",
            "   ID variables %s \n",
            "\"   ['ID']\"\n",
            "   Target variable %s \n",
            "'   Class'\n",
            "To fix these data quality issues in the dataset, import FixDQ from autoviz...\n",
            "    All variables classified into correct types.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_97d18_row0_col0, #T_97d18_row0_col3, #T_97d18_row0_col4, #T_97d18_row0_col5, #T_97d18_row1_col0, #T_97d18_row1_col3, #T_97d18_row1_col4, #T_97d18_row1_col5, #T_97d18_row2_col0, #T_97d18_row2_col3, #T_97d18_row2_col4, #T_97d18_row2_col5 {\n",
              "  font-family: Segoe UI;\n",
              "}\n",
              "#T_97d18_row0_col1, #T_97d18_row1_col1, #T_97d18_row2_col1, #T_97d18_row2_col2 {\n",
              "  background-color: #fff5f0;\n",
              "  color: #000000;\n",
              "  font-family: Segoe UI;\n",
              "}\n",
              "#T_97d18_row0_col2 {\n",
              "  background-color: #fee8de;\n",
              "  color: #000000;\n",
              "  font-family: Segoe UI;\n",
              "}\n",
              "#T_97d18_row1_col2 {\n",
              "  background-color: #67000d;\n",
              "  color: #f1f1f1;\n",
              "  font-family: Segoe UI;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_97d18\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_97d18_level0_col0\" class=\"col_heading level0 col0\" >Data Type</th>\n",
              "      <th id=\"T_97d18_level0_col1\" class=\"col_heading level0 col1\" >Missing Values%</th>\n",
              "      <th id=\"T_97d18_level0_col2\" class=\"col_heading level0 col2\" >Unique Values%</th>\n",
              "      <th id=\"T_97d18_level0_col3\" class=\"col_heading level0 col3\" >Minimum Value</th>\n",
              "      <th id=\"T_97d18_level0_col4\" class=\"col_heading level0 col4\" >Maximum Value</th>\n",
              "      <th id=\"T_97d18_level0_col5\" class=\"col_heading level0 col5\" >DQ Issue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_97d18_level0_row0\" class=\"row_heading level0 row0\" >Gene</th>\n",
              "      <td id=\"T_97d18_row0_col0\" class=\"data row0 col0\" >object</td>\n",
              "      <td id=\"T_97d18_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
              "      <td id=\"T_97d18_row0_col2\" class=\"data row0 col2\" >7</td>\n",
              "      <td id=\"T_97d18_row0_col3\" class=\"data row0 col3\" ></td>\n",
              "      <td id=\"T_97d18_row0_col4\" class=\"data row0 col4\" ></td>\n",
              "      <td id=\"T_97d18_row0_col5\" class=\"data row0 col5\" >Possible high cardinality column with 264 unique values: Use hash encoding or text embedding to reduce dimension.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_97d18_level0_row1\" class=\"row_heading level0 row1\" >Variation</th>\n",
              "      <td id=\"T_97d18_row1_col0\" class=\"data row1 col0\" >object</td>\n",
              "      <td id=\"T_97d18_row1_col1\" class=\"data row1 col1\" >0.000000</td>\n",
              "      <td id=\"T_97d18_row1_col2\" class=\"data row1 col2\" >90</td>\n",
              "      <td id=\"T_97d18_row1_col3\" class=\"data row1 col3\" ></td>\n",
              "      <td id=\"T_97d18_row1_col4\" class=\"data row1 col4\" ></td>\n",
              "      <td id=\"T_97d18_row1_col5\" class=\"data row1 col5\" >No issue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_97d18_level0_row2\" class=\"row_heading level0 row2\" >Class</th>\n",
              "      <td id=\"T_97d18_row2_col0\" class=\"data row2 col0\" >int64</td>\n",
              "      <td id=\"T_97d18_row2_col1\" class=\"data row2 col1\" >0.000000</td>\n",
              "      <td id=\"T_97d18_row2_col2\" class=\"data row2 col2\" >0</td>\n",
              "      <td id=\"T_97d18_row2_col3\" class=\"data row2 col3\" >1.000000</td>\n",
              "      <td id=\"T_97d18_row2_col4\" class=\"data row2 col4\" >9.000000</td>\n",
              "      <td id=\"T_97d18_row2_col5\" class=\"data row2 col5\" >Target column. Appears to have Imbalanced classes. Try balancing classes.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7e5bb344c890>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No continuous var in data set: drawing categorical distribution plots\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Could not draw wordcloud plot for Variation. \n",
            "Looks like you are missing some required data for this feature.\n",
            "\n",
            "To download the necessary data, simply run\n",
            "\n",
            "    python -m textblob.download_corpora\n",
            "\n",
            "or use the NLTK downloader to download the missing data: http://nltk.org/data.html\n",
            "If this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n",
            "\n",
            "Could not draw wordcloud plot for Gene. \n",
            "Looks like you are missing some required data for this feature.\n",
            "\n",
            "To download the necessary data, simply run\n",
            "\n",
            "    python -m textblob.download_corpora\n",
            "\n",
            "or use the NLTK downloader to download the missing data: http://nltk.org/data.html\n",
            "If this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n",
            "\n",
            "All Plots are saved in ./AutoViz_Plots/Class\n",
            "Time to run AutoViz = 8 seconds \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        }
      ],
      "source": [
        "AV = AutoViz_Class()\n",
        "\n",
        "# Run AutoViz on structured data (train_variants)\n",
        "auto_report = AV.AutoViz(filename=\"\", dfte=train_variants, depVar=\"Class\", verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L7BbAln57asl",
        "outputId": "d333a662-7091-4d5f-a41d-5423ce790ecb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of your Data Set loaded: (3321, 5)\n",
            "#######################################################################################\n",
            "######################## C L A S S I F Y I N G  V A R I A B L E S  ####################\n",
            "#######################################################################################\n",
            "Classifying variables in data set...\n",
            "  Printing up to 30 columns (max) in each category:\n",
            "    Numeric Columns : []\n",
            "    Integer-Categorical Columns: []\n",
            "    String-Categorical Columns: []\n",
            "    Factor-Categorical Columns: []\n",
            "    String-Boolean Columns: []\n",
            "    Numeric-Boolean Columns: []\n",
            "    Discrete String Columns: ['Gene']\n",
            "    NLP text Columns: ['Variation', 'Text']\n",
            "    Date Time Columns: []\n",
            "    ID Columns: ['ID']\n",
            "    Columns that will not be considered in modeling: []\n",
            "    4 Predictors classified...\n",
            "        1 variable(s) removed since they were ID or low-information variables\n",
            "        List of variables removed: ['ID']\n",
            "\n",
            "################ Multi_Classification problem #####################\n",
            "   Columns to delete:\n",
            "'   []'\n",
            "   Boolean variables %s \n",
            "'   []'\n",
            "   Categorical variables %s \n",
            "'   []'\n",
            "   Continuous variables %s \n",
            "'   []'\n",
            "   Discrete string variables %s \n",
            "\"   ['Variation', 'Text', 'Gene']\"\n",
            "   Date and time variables %s \n",
            "'   []'\n",
            "   ID variables %s \n",
            "\"   ['ID']\"\n",
            "   Target variable %s \n",
            "'   Class'\n",
            "To fix these data quality issues in the dataset, import FixDQ from autoviz...\n",
            "    All variables classified into correct types.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_c917e_row0_col0, #T_c917e_row0_col3, #T_c917e_row0_col4, #T_c917e_row0_col5, #T_c917e_row1_col0, #T_c917e_row1_col3, #T_c917e_row1_col4, #T_c917e_row1_col5, #T_c917e_row2_col0, #T_c917e_row2_col3, #T_c917e_row2_col4, #T_c917e_row2_col5, #T_c917e_row3_col0, #T_c917e_row3_col3, #T_c917e_row3_col4, #T_c917e_row3_col5 {\n",
              "  font-family: Segoe UI;\n",
              "}\n",
              "#T_c917e_row0_col1, #T_c917e_row1_col1, #T_c917e_row3_col1, #T_c917e_row3_col2 {\n",
              "  background-color: #fff5f0;\n",
              "  color: #000000;\n",
              "  font-family: Segoe UI;\n",
              "}\n",
              "#T_c917e_row0_col2 {\n",
              "  background-color: #fee8de;\n",
              "  color: #000000;\n",
              "  font-family: Segoe UI;\n",
              "}\n",
              "#T_c917e_row1_col2, #T_c917e_row2_col1 {\n",
              "  background-color: #67000d;\n",
              "  color: #f1f1f1;\n",
              "  font-family: Segoe UI;\n",
              "}\n",
              "#T_c917e_row2_col2 {\n",
              "  background-color: #ec382b;\n",
              "  color: #f1f1f1;\n",
              "  font-family: Segoe UI;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_c917e\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_c917e_level0_col0\" class=\"col_heading level0 col0\" >Data Type</th>\n",
              "      <th id=\"T_c917e_level0_col1\" class=\"col_heading level0 col1\" >Missing Values%</th>\n",
              "      <th id=\"T_c917e_level0_col2\" class=\"col_heading level0 col2\" >Unique Values%</th>\n",
              "      <th id=\"T_c917e_level0_col3\" class=\"col_heading level0 col3\" >Minimum Value</th>\n",
              "      <th id=\"T_c917e_level0_col4\" class=\"col_heading level0 col4\" >Maximum Value</th>\n",
              "      <th id=\"T_c917e_level0_col5\" class=\"col_heading level0 col5\" >DQ Issue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_c917e_level0_row0\" class=\"row_heading level0 row0\" >Gene</th>\n",
              "      <td id=\"T_c917e_row0_col0\" class=\"data row0 col0\" >object</td>\n",
              "      <td id=\"T_c917e_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
              "      <td id=\"T_c917e_row0_col2\" class=\"data row0 col2\" >7</td>\n",
              "      <td id=\"T_c917e_row0_col3\" class=\"data row0 col3\" ></td>\n",
              "      <td id=\"T_c917e_row0_col4\" class=\"data row0 col4\" ></td>\n",
              "      <td id=\"T_c917e_row0_col5\" class=\"data row0 col5\" >Possible high cardinality column with 264 unique values: Use hash encoding or text embedding to reduce dimension.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c917e_level0_row1\" class=\"row_heading level0 row1\" >Variation</th>\n",
              "      <td id=\"T_c917e_row1_col0\" class=\"data row1 col0\" >object</td>\n",
              "      <td id=\"T_c917e_row1_col1\" class=\"data row1 col1\" >0.000000</td>\n",
              "      <td id=\"T_c917e_row1_col2\" class=\"data row1 col2\" >90</td>\n",
              "      <td id=\"T_c917e_row1_col3\" class=\"data row1 col3\" ></td>\n",
              "      <td id=\"T_c917e_row1_col4\" class=\"data row1 col4\" ></td>\n",
              "      <td id=\"T_c917e_row1_col5\" class=\"data row1 col5\" >No issue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c917e_level0_row2\" class=\"row_heading level0 row2\" >Text</th>\n",
              "      <td id=\"T_c917e_row2_col0\" class=\"data row2 col0\" >object</td>\n",
              "      <td id=\"T_c917e_row2_col1\" class=\"data row2 col1\" >0.150557</td>\n",
              "      <td id=\"T_c917e_row2_col2\" class=\"data row2 col2\" >57</td>\n",
              "      <td id=\"T_c917e_row2_col3\" class=\"data row2 col3\" ></td>\n",
              "      <td id=\"T_c917e_row2_col4\" class=\"data row2 col4\" ></td>\n",
              "      <td id=\"T_c917e_row2_col5\" class=\"data row2 col5\" >5 missing values. Impute them with mean, median, mode, or a constant value such as 123., Mixed dtypes: has 2 different data types:  object, float,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c917e_level0_row3\" class=\"row_heading level0 row3\" >Class</th>\n",
              "      <td id=\"T_c917e_row3_col0\" class=\"data row3 col0\" >int64</td>\n",
              "      <td id=\"T_c917e_row3_col1\" class=\"data row3 col1\" >0.000000</td>\n",
              "      <td id=\"T_c917e_row3_col2\" class=\"data row3 col2\" >0</td>\n",
              "      <td id=\"T_c917e_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
              "      <td id=\"T_c917e_row3_col4\" class=\"data row3 col4\" >9.000000</td>\n",
              "      <td id=\"T_c917e_row3_col5\" class=\"data row3 col5\" >Target column. Appears to have Imbalanced classes. Try balancing classes.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7e5bb1913090>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No continuous var in data set: drawing categorical distribution plots\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Could not draw wordcloud plot for Variation. \n",
            "Looks like you are missing some required data for this feature.\n",
            "\n",
            "To download the necessary data, simply run\n",
            "\n",
            "    python -m textblob.download_corpora\n",
            "\n",
            "or use the NLTK downloader to download the missing data: http://nltk.org/data.html\n",
            "If this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n",
            "\n",
            "Could not draw wordcloud plot for Text. \n",
            "Looks like you are missing some required data for this feature.\n",
            "\n",
            "To download the necessary data, simply run\n",
            "\n",
            "    python -m textblob.download_corpora\n",
            "\n",
            "or use the NLTK downloader to download the missing data: http://nltk.org/data.html\n",
            "If this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n",
            "\n",
            "Could not draw wordcloud plot for Gene. \n",
            "Looks like you are missing some required data for this feature.\n",
            "\n",
            "To download the necessary data, simply run\n",
            "\n",
            "    python -m textblob.download_corpora\n",
            "\n",
            "or use the NLTK downloader to download the missing data: http://nltk.org/data.html\n",
            "If this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n",
            "\n",
            "All Plots are saved in ./AutoViz_Plots/Class\n",
            "Time to run AutoViz = 9 seconds \n"
          ]
        }
      ],
      "source": [
        "auto_report_merged = AV.AutoViz(filename=\"\", dfte=train_data, depVar=\"Class\", verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eno2gEt3R8e5",
        "outputId": "3f74cf51-1bb7-4fd6-c754-5f35381e1e0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(   ID  Gene  Variation  Class  \\\n",
              " 0   0    85       2629      1   \n",
              " 1   1    39       2856      2   \n",
              " 2   2    39       1897      2   \n",
              " 3   3    39       1667      3   \n",
              " 4   4    39       1447      4   \n",
              " \n",
              "                                                 Text  \n",
              " 0  Cyclin-dependent kinases (CDKs) regulate a var...  \n",
              " 1   Abstract Background  Non-small cell lung canc...  \n",
              " 2   Abstract Background  Non-small cell lung canc...  \n",
              " 3  Recent evidence has demonstrated that acquired...  \n",
              " 4  Oncogenic mutations in the monomeric Casitas B...  ,\n",
              "    ID  Gene  Variation                                               Text\n",
              " 0   0   264       2996  2. This mutation resulted in a myeloproliferat...\n",
              " 1   1   264       2996   Abstract The Large Tumor Suppressor 1 (LATS1)...\n",
              " 2   2   264       2996  Vascular endothelial growth factor receptor (V...\n",
              " 3   3   264       2996  Inflammatory myofibroblastic tumor (IMT) is a ...\n",
              " 4   4   264       2996   Abstract Retinoblastoma is a pediatric retina...)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# encoding gene and variation for training data\n",
        "gene_encoder = LabelEncoder()\n",
        "variation_encoder = LabelEncoder()\n",
        "\n",
        "train_data[\"Gene\"] = gene_encoder.fit_transform(train_data[\"Gene\"])\n",
        "train_data[\"Variation\"] = variation_encoder.fit_transform(train_data[\"Variation\"])\n",
        "\n",
        "# function to safely encode test data, so we can address unseen label in test data\n",
        "def encode_with_fallback(encoder, data_column, train_labels):\n",
        "    mapping = {label: idx for idx, label in enumerate(train_labels)}\n",
        "    return data_column.apply(lambda x: mapping.get(x, -1))  # assign -1 for unseen labels\n",
        "\n",
        "# encoding test data (handling unseen labels)\n",
        "test_data[\"Gene\"] = encode_with_fallback(gene_encoder, test_data[\"Gene\"], gene_encoder.classes_)\n",
        "test_data[\"Variation\"] = encode_with_fallback(variation_encoder, test_data[\"Variation\"], variation_encoder.classes_)\n",
        "\n",
        "# converting -1 labels to a new category index\n",
        "test_data[\"Gene\"] = test_data[\"Gene\"].replace(-1, len(gene_encoder.classes_))\n",
        "test_data[\"Variation\"] = test_data[\"Variation\"].replace(-1, len(variation_encoder.classes_))\n",
        "\n",
        "# Convert labels to categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "num_classes = train_data[\"Class\"].nunique()\n",
        "train_labels = to_categorical(train_data[\"Class\"] - 1, num_classes=num_classes)\n",
        "\n",
        "train_data.head(), test_data.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHtZlP5RnbUJ",
        "outputId": "88430f0b-7893-41a1-df4c-3d09ec3fb43f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3321, 500), (5668, 500))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Text preprocessing parameters\n",
        "MAX_WORDS = 30000  # Increased vocabulary size\n",
        "MAX_SEQUENCE_LENGTH = 500  # Maximum sequence length\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<UNK>\")\n",
        "tokenizer.fit_on_texts(train_data[\"Text\"].fillna(\"\"))\n",
        "\n",
        "# Convert text to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_data[\"Text\"].fillna(\"\"))\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data[\"Text\"].fillna(\"\"))\n",
        "\n",
        "# Pad sequences\n",
        "train_padded = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
        "test_padded = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "# Display sequence shape\n",
        "train_padded.shape, test_padded.shape\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFgw5NDQxD0V"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100  # Size of the word embedding vectors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUX91R9n-SwL",
        "outputId": "0ccba180-2f3c-41fe-a6f6-7a50de7b7fb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.2102 - loss: 2.1270 - val_accuracy: 0.2617 - val_loss: 2.0159\n",
            "Epoch 2/40\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.3890 - loss: 1.7515 - val_accuracy: 0.3639 - val_loss: 1.8316\n",
            "Epoch 3/40\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.4501 - loss: 1.6020 - val_accuracy: 0.3624 - val_loss: 1.6693\n",
            "Epoch 4/40\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.4848 - loss: 1.5099 - val_accuracy: 0.3368 - val_loss: 1.8177\n",
            "Epoch 5/40\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.5033 - loss: 1.4182 - val_accuracy: 0.3429 - val_loss: 1.8053\n",
            "Epoch 6/40\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.5247 - loss: 1.2903 - val_accuracy: 0.3579 - val_loss: 1.7352\n"
          ]
        }
      ],
      "source": [
        "#from tensorflow.keras.models import Model\n",
        "#from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense, Concatenate, Dropout, Attention, Flatten\n",
        "#from tensorflow.keras.optimizers import Adam\n",
        "#from tensorflow.keras.callbacks import EarlyStopping\n",
        "#from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "#\n",
        "## Learning rate scheduler\n",
        "#lr_schedule = ExponentialDecay(initial_learning_rate=0.001, decay_steps=5000, decay_rate=0.8)\n",
        "#optimizer = Adam(learning_rate=lr_schedule)\n",
        "#\n",
        "## Text Input (LSTM Branch)\n",
        "#text_input = Input(shape=(MAX_SEQUENCE_LENGTH,), name=\"Text_Input\")\n",
        "#embedding_layer = Embedding(input_dim=MAX_WORDS, output_dim=embedding_dim, trainable=True)(text_input)\n",
        "#lstm_layer = Bidirectional(LSTM(64, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))(embedding_layer)\n",
        "#lstm_layer2 = Bidirectional(LSTM(64, return_sequences=False, dropout=0.5, recurrent_dropout=0.5))(lstm_layer)\n",
        "#\n",
        "## Attention Layer\n",
        "#attention = Attention()([lstm_layer, lstm_layer])\n",
        "#lstm_output = Flatten()(attention)\n",
        "#\n",
        "## Gene Input\n",
        "#gene_input = Input(shape=(1,), name=\"Gene_Input\")\n",
        "#gene_embedding = Embedding(input_dim=len(gene_encoder.classes_)+1, output_dim=8)(gene_input)\n",
        "#gene_embedding = Flatten()(gene_embedding)\n",
        "#\n",
        "## Variation Input\n",
        "#variation_input = Input(shape=(1,), name=\"Variation_Input\")\n",
        "#variation_embedding = Embedding(input_dim=len(variation_encoder.classes_)+1, output_dim=8)(variation_input)\n",
        "#variation_embedding = Flatten()(variation_embedding)\n",
        "#\n",
        "## Merge Inputs\n",
        "#merged = Concatenate()([lstm_output, gene_embedding, variation_embedding])\n",
        "#dense1 = Dense(64, activation=\"relu\")(merged)\n",
        "#dropout = Dropout(0.5)(dense1)\n",
        "#dense2 = Dense(32, activation=\"relu\")(dropout)\n",
        "#dropout2 = Dropout(0.5)(dense2)\n",
        "#output = Dense(num_classes, activation=\"softmax\")(dropout2)\n",
        "#\n",
        "## Build Model\n",
        "#model = Model(inputs=[text_input, gene_input, variation_input], outputs=output)\n",
        "#model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "#\n",
        "## Early Stopping Callback\n",
        "##early_stop = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
        "#\n",
        "## Train Model\n",
        "#history = model.fit(\n",
        "#    [train_padded, train_data[\"Gene\"], train_data[\"Variation\"]],\n",
        "#    train_labels,\n",
        "#    validation_split=0.2,\n",
        "#    epochs=40,\n",
        "#    batch_size=32,\n",
        "#    verbose=1,\n",
        "#    #callbacks=[early_stop]\n",
        "#)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "id": "QTxi_i9Rnh_X",
        "outputId": "dc0f5a67-4fef-4a3f-9e1b-2e772fa8581f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ Text_Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,000,000</span> │ Text_Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">234,496</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Gene_Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Variation_Input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,120</span> │ Gene_Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">23,976</span> │ Variation_Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128000</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128016</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,386,176</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">585</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ Text_Input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │      \u001b[38;5;34m3,000,000\u001b[0m │ Text_Input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m234,496\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Gene_Input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Variation_Input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ attention (\u001b[38;5;33mAttention\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │          \u001b[38;5;34m2,120\u001b[0m │ Gene_Input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │         \u001b[38;5;34m23,976\u001b[0m │ Variation_Input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128000\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128016\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m16,386,176\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │            \u001b[38;5;34m585\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,655,609</span> (74.98 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,655,609\u001b[0m (74.98 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,655,609</span> (74.98 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,655,609\u001b[0m (74.98 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense, Concatenate, Dropout, Attention, Flatten\n",
        "\n",
        "# Text Input\n",
        "text_input = Input(shape=(MAX_SEQUENCE_LENGTH,), name=\"Text_Input\")\n",
        "embedding_layer = Embedding(input_dim=MAX_WORDS, output_dim=embedding_dim, trainable=True)(text_input)\n",
        "lstm_layer = Bidirectional(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3))(embedding_layer)\n",
        "\n",
        "# Attention Layer\n",
        "attention = Attention()([lstm_layer, lstm_layer])\n",
        "lstm_output = Flatten()(attention)\n",
        "\n",
        "# Gene Input\n",
        "gene_input = Input(shape=(1,), name=\"Gene_Input\")\n",
        "gene_embedding = Embedding(input_dim=len(gene_encoder.classes_)+1, output_dim=8)(gene_input)\n",
        "gene_embedding = Flatten()(gene_embedding)\n",
        "\n",
        "# Variation Input\n",
        "variation_input = Input(shape=(1,), name=\"Variation_Input\")\n",
        "variation_embedding = Embedding(input_dim=len(variation_encoder.classes_)+1, output_dim=8)(variation_input)\n",
        "variation_embedding = Flatten()(variation_embedding)\n",
        "\n",
        "# Merge Inputs\n",
        "merged = Concatenate()([lstm_output, gene_embedding, variation_embedding])\n",
        "dense1 = Dense(128, activation=\"relu\")(merged)\n",
        "dropout = Dropout(0.4)(dense1)\n",
        "dense2 = Dense(64, activation=\"relu\")(dropout)\n",
        "dropout2 = Dropout(0.3)(dense2)\n",
        "output = Dense(num_classes, activation=\"softmax\")(dropout2)\n",
        "\n",
        "# Build model\n",
        "model = Model(inputs=[text_input, gene_input, variation_input], outputs=output)\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm60n4_nnoPc",
        "outputId": "d9803b92-273f-4d6c-9aa7-4d8c94a125cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 2s/step - accuracy: 0.3139 - loss: 1.8587 - val_accuracy: 0.3579 - val_loss: 1.8502\n",
            "Epoch 2/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.4838 - loss: 1.4379 - val_accuracy: 0.4015 - val_loss: 1.6393\n",
            "Epoch 3/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 2s/step - accuracy: 0.6005 - loss: 1.1588 - val_accuracy: 0.4105 - val_loss: 1.5484\n",
            "Epoch 4/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6510 - loss: 1.0680 - val_accuracy: 0.3323 - val_loss: 1.7061\n",
            "Epoch 5/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.6863 - loss: 0.9339 - val_accuracy: 0.4045 - val_loss: 1.7335\n",
            "Epoch 6/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6814 - loss: 0.9694 - val_accuracy: 0.4075 - val_loss: 1.5627\n",
            "Epoch 7/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - accuracy: 0.7177 - loss: 0.8422 - val_accuracy: 0.3940 - val_loss: 1.8246\n",
            "Epoch 8/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 2s/step - accuracy: 0.7330 - loss: 0.7465 - val_accuracy: 0.3774 - val_loss: 1.8164\n",
            "Epoch 9/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.7440 - loss: 0.7413 - val_accuracy: 0.3173 - val_loss: 2.0869\n",
            "Epoch 10/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.7301 - loss: 0.7650 - val_accuracy: 0.3038 - val_loss: 2.1582\n",
            "Epoch 11/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.7566 - loss: 0.6506 - val_accuracy: 0.3504 - val_loss: 2.0098\n",
            "Epoch 12/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.7574 - loss: 0.6554 - val_accuracy: 0.3729 - val_loss: 2.0968\n",
            "Epoch 13/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - accuracy: 0.7746 - loss: 0.5932 - val_accuracy: 0.3534 - val_loss: 2.1538\n",
            "Epoch 14/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.8115 - loss: 0.5403 - val_accuracy: 0.3925 - val_loss: 2.1405\n",
            "Epoch 15/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 2s/step - accuracy: 0.8138 - loss: 0.5256 - val_accuracy: 0.3624 - val_loss: 2.2461\n",
            "Epoch 16/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.8240 - loss: 0.4656 - val_accuracy: 0.3835 - val_loss: 2.1172\n",
            "Epoch 17/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.8471 - loss: 0.4502 - val_accuracy: 0.3669 - val_loss: 2.1935\n",
            "Epoch 18/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 2s/step - accuracy: 0.8624 - loss: 0.4004 - val_accuracy: 0.3594 - val_loss: 2.6624\n",
            "Epoch 19/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 2s/step - accuracy: 0.8784 - loss: 0.3684 - val_accuracy: 0.3955 - val_loss: 2.6768\n",
            "Epoch 20/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 2s/step - accuracy: 0.8669 - loss: 0.3602 - val_accuracy: 0.3218 - val_loss: 2.7029\n",
            "Epoch 21/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - accuracy: 0.8842 - loss: 0.3467 - val_accuracy: 0.2797 - val_loss: 2.8856\n",
            "Epoch 22/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.9040 - loss: 0.2951 - val_accuracy: 0.3308 - val_loss: 2.6248\n",
            "Epoch 23/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.9036 - loss: 0.2829 - val_accuracy: 0.3444 - val_loss: 2.8008\n",
            "Epoch 24/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 2s/step - accuracy: 0.9215 - loss: 0.2416 - val_accuracy: 0.3835 - val_loss: 2.8564\n",
            "Epoch 25/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 2s/step - accuracy: 0.9221 - loss: 0.2273 - val_accuracy: 0.3534 - val_loss: 2.8187\n",
            "Epoch 26/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 2s/step - accuracy: 0.9152 - loss: 0.2493 - val_accuracy: 0.3323 - val_loss: 3.3963\n",
            "Epoch 27/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.9287 - loss: 0.1912 - val_accuracy: 0.3323 - val_loss: 2.9791\n",
            "Epoch 28/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 2s/step - accuracy: 0.9348 - loss: 0.2133 - val_accuracy: 0.3128 - val_loss: 3.1786\n",
            "Epoch 29/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.9275 - loss: 0.2071 - val_accuracy: 0.3880 - val_loss: 2.5239\n",
            "Epoch 30/30\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 2s/step - accuracy: 0.9340 - loss: 0.1903 - val_accuracy: 0.3669 - val_loss: 2.8233\n"
          ]
        }
      ],
      "source": [
        "# Prepare structured inputs\n",
        "train_structured = train_data[[\"Gene\", \"Variation\"]].values\n",
        "test_structured = test_data[[\"Gene\", \"Variation\"]].values\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    [train_padded, train_structured[:, 0], train_structured[:, 1]],\n",
        "    train_labels,\n",
        "    validation_split=0.2,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NQlpC3enrBm",
        "outputId": "847c8c88-234b-4460-becd-9ec5d3e1526b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Save model\n",
        "#model.save(\"/content/drive/MyDrive/biobert_genetic_mutation_classifier.h5\")\n",
        "\n",
        "# Make predictions (if test labels available)\n",
        "# test_predictions = model.predict([test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"], test_structured])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ND2VHw3W0BQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "048d6a67f1cc4445a64f1e0e6e7b8e78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0592974f930543a58854cc5ea8d6600f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_338ab666d6294a0aa716bf80f4985159",
              "IPY_MODEL_35402a30152a4aebb68f61d6f8d98639",
              "IPY_MODEL_5873ad72b64b417ebfce0d94d3b14ede"
            ],
            "layout": "IPY_MODEL_06d048447a9d440bbf58d3167611fb92"
          }
        },
        "062a32a2dee1422f830cd3f1dd2e0219": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf039c1cc03b4a0db3896df0c5db3020",
            "placeholder": "​",
            "style": "IPY_MODEL_66ace486599b4596a85a1b6ae2dfc7c3",
            "value": "config.json: 100%"
          }
        },
        "06d048447a9d440bbf58d3167611fb92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "075f470455e24caea12c16d3eb6246ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "118efbad7c404420a7ae018a1de21f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12784b56e13e453896568a5c0d07e009": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "140ba05043a54b8f9afc9566cae9540f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b3172d7238d41e1b233ba5a8a707375",
            "max": 433286112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ca6acbb0502477a9f80d8bd8d439588",
            "value": 433286112
          }
        },
        "14ccdff704bd4f9f840260f52fc2ccac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f5f114c9c6d4bf48b5bcbb5c5ba0bd8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24ae0638ff2546fcb8d00b4c6a9e5016": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c9809bcd8d549f38d4e952b955d9798": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d4e73f1916c4116b3fbd2ba72019612": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ec4837692534769be63d6878427b233": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "338ab666d6294a0aa716bf80f4985159": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b8fef0a51a04027999f5071cdb586b8",
            "placeholder": "​",
            "style": "IPY_MODEL_ecf4f83dcda949a8a8d7d49f5d7f4cf8",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "339d98fbafc1493aa7e51d21570f536a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35402a30152a4aebb68f61d6f8d98639": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d4e73f1916c4116b3fbd2ba72019612",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_118efbad7c404420a7ae018a1de21f9e",
            "value": 112
          }
        },
        "396e0f61f94345b8a61021c792b6cbe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d792fe3d56e04a609cca2814cd4af95b",
            "placeholder": "​",
            "style": "IPY_MODEL_744ff37c0f18482ab67cda877ad9c676",
            "value": " 213k/213k [00:00&lt;00:00, 11.1MB/s]"
          }
        },
        "3b3172d7238d41e1b233ba5a8a707375": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b3ac5e2f4c44d2eaa1af9e3517420cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b7fdcc242d646df99fc88bc82c48a74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ba91fb3ab0543c1b9c36a5e70725ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4432c69129644a859e414b63d0439e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "468f879041734b0283afe6e8da05c9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b3ac5e2f4c44d2eaa1af9e3517420cb",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e82cedbbda104e4c83c438d01982c93e",
            "value": 213450
          }
        },
        "5542ae823aae4621937fbb18a6c480fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7814706326ba4e08be46ac2bce6a1ba9",
              "IPY_MODEL_b103eb82067b446ba01e68c3d4b5c707",
              "IPY_MODEL_ccb9867b625c466fa7b7ab86e2232e34"
            ],
            "layout": "IPY_MODEL_048d6a67f1cc4445a64f1e0e6e7b8e78"
          }
        },
        "5873ad72b64b417ebfce0d94d3b14ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_075f470455e24caea12c16d3eb6246ac",
            "placeholder": "​",
            "style": "IPY_MODEL_78ea49656e444cc28cf5447d97177a70",
            "value": " 112/112 [00:00&lt;00:00, 12.4kB/s]"
          }
        },
        "5ca6acbb0502477a9f80d8bd8d439588": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66ace486599b4596a85a1b6ae2dfc7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bd6d6eb13ba4a7ea528e8d72fa2e3b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f767103326594cd3a4bf5a7413dff1ff",
              "IPY_MODEL_140ba05043a54b8f9afc9566cae9540f",
              "IPY_MODEL_89492fa780234b918496dfc096abaef3"
            ],
            "layout": "IPY_MODEL_c2a0e1b2c12e42c89c67595407019982"
          }
        },
        "6fb30998687947429910cc787a81ddb6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70df5d4e61694593a8f8e6ee1f9947d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "744ff37c0f18482ab67cda877ad9c676": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7814706326ba4e08be46ac2bce6a1ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86f9121d5ad7406eb3e5c0e2eb83c80d",
            "placeholder": "​",
            "style": "IPY_MODEL_12784b56e13e453896568a5c0d07e009",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "78ea49656e444cc28cf5447d97177a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86f9121d5ad7406eb3e5c0e2eb83c80d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89492fa780234b918496dfc096abaef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ec4837692534769be63d6878427b233",
            "placeholder": "​",
            "style": "IPY_MODEL_3ba91fb3ab0543c1b9c36a5e70725ac6",
            "value": " 433M/433M [00:01&lt;00:00, 241MB/s]"
          }
        },
        "8b1e830094ed4849955fe448a3ae880e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b8fef0a51a04027999f5071cdb586b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8939a894b7348ecbdd239f3084f1ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abec15d950004abb8d64e9e42770f747": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_062a32a2dee1422f830cd3f1dd2e0219",
              "IPY_MODEL_cc3e319dadd048a78acdcab9ae0dbfc7",
              "IPY_MODEL_bbe1d6e9db2944c18bf080c86611a2e8"
            ],
            "layout": "IPY_MODEL_8b1e830094ed4849955fe448a3ae880e"
          }
        },
        "b103eb82067b446ba01e68c3d4b5c707": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f5f114c9c6d4bf48b5bcbb5c5ba0bd8",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0d9ff06680f4405b035283ee290dae2",
            "value": 49
          }
        },
        "bbe1d6e9db2944c18bf080c86611a2e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70df5d4e61694593a8f8e6ee1f9947d5",
            "placeholder": "​",
            "style": "IPY_MODEL_c588b526352b4f9baa9358dc0230e595",
            "value": " 462/462 [00:00&lt;00:00, 51.0kB/s]"
          }
        },
        "c0d9ff06680f4405b035283ee290dae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2a0e1b2c12e42c89c67595407019982": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c588b526352b4f9baa9358dc0230e595": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5e423e9d54e49fa84b8403197da5cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8d8fc86d75a4280b31f45f2c2be0096",
              "IPY_MODEL_468f879041734b0283afe6e8da05c9b1",
              "IPY_MODEL_396e0f61f94345b8a61021c792b6cbe7"
            ],
            "layout": "IPY_MODEL_2c9809bcd8d549f38d4e952b955d9798"
          }
        },
        "cc3e319dadd048a78acdcab9ae0dbfc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24ae0638ff2546fcb8d00b4c6a9e5016",
            "max": 462,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4432c69129644a859e414b63d0439e1f",
            "value": 462
          }
        },
        "ccb9867b625c466fa7b7ab86e2232e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b7fdcc242d646df99fc88bc82c48a74",
            "placeholder": "​",
            "style": "IPY_MODEL_a8939a894b7348ecbdd239f3084f1ea2",
            "value": " 49.0/49.0 [00:00&lt;00:00, 5.08kB/s]"
          }
        },
        "cf039c1cc03b4a0db3896df0c5db3020": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d792fe3d56e04a609cca2814cd4af95b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9f2fdcc3825498cab8e69604f842f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e82cedbbda104e4c83c438d01982c93e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecf4f83dcda949a8a8d7d49f5d7f4cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f767103326594cd3a4bf5a7413dff1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fb30998687947429910cc787a81ddb6",
            "placeholder": "​",
            "style": "IPY_MODEL_d9f2fdcc3825498cab8e69604f842f1c",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "f8d8fc86d75a4280b31f45f2c2be0096": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_339d98fbafc1493aa7e51d21570f536a",
            "placeholder": "​",
            "style": "IPY_MODEL_14ccdff704bd4f9f840260f52fc2ccac",
            "value": "vocab.txt: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}